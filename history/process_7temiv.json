[{
  "history_id" : "tygv5u2msdy",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667434821990,
  "history_end_time" : 1667434821990,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "xviph7ro7uz",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667420912880,
  "history_end_time" : 1667420912880,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "30jhjwckx19",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667420799801,
  "history_end_time" : 1667420799801,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "shu3k4t00km",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667412122213,
  "history_end_time" : 1667412122213,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "etc80fb8tx1",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667411534153,
  "history_end_time" : 1667411534153,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "t36nag5rg4y",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667411146174,
  "history_end_time" : 1667411146174,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "4elxdpr32kw",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667410736794,
  "history_end_time" : 1667410736794,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "mebw2tf0vm8",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667410696436,
  "history_end_time" : 1667410696436,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Skipped"
},{
  "history_id" : "bdjqfhab8bz",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667410660496,
  "history_end_time" : 1667410690575,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "bh6y4j5i040",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667410652219,
  "history_end_time" : 1667410704833,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "o2tpnnd7rro",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667410575672,
  "history_end_time" : 1667410651124,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "m1dcm7hjjlg",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667410544323,
  "history_end_time" : 1667410624012,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "v5slchdl4je",
  "history_input" : "No code saved",
  "history_output" : "Skipped",
  "history_begin_time" : 1667410384355,
  "history_end_time" : 1667410556068,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "lndi74gby1d",
  "history_input" : null,
  "history_output" : "Authentication Failed. Wrong Password.",
  "history_begin_time" : 1667409180917,
  "history_end_time" : 1667409180948,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "svdgyo0vsmc",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\nexit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31').filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "",
  "history_begin_time" : 1657574456310,
  "history_end_time" : 1657574458872,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "74yd0s97tka",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\nexit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31').filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "",
  "history_begin_time" : 1657137853699,
  "history_end_time" : 1657137855941,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "0grjb9u5taf",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\nexit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31').filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "",
  "history_begin_time" : 1656529476236,
  "history_end_time" : 1656529478071,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "eyy5eo36k5j",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\nexit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31').filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "",
  "history_begin_time" : 1656523440057,
  "history_end_time" : 1656523442363,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "t03bliifnue",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\nexit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31').filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "",
  "history_begin_time" : 1656443567360,
  "history_end_time" : 1656443569590,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "srx6dimd1z9",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\nexit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31').filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "",
  "history_begin_time" : 1656443334316,
  "history_end_time" : 1656443336714,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "ys81h1g6ni8",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\nexit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31').filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "",
  "history_begin_time" : 1656439597299,
  "history_end_time" : 1656439599383,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "2mjv8v4yab4",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\nexit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31').filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "",
  "history_begin_time" : 1656439448369,
  "history_end_time" : 1656439450589,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "lnbvgkrzw9j",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\nexit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31').filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "",
  "history_begin_time" : 1656439257041,
  "history_end_time" : 1656439259225,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "eoopstujhv3",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\nexit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31').filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "",
  "history_begin_time" : 1656439116824,
  "history_end_time" : 1656439119018,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "x4yjhkoksq7",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\nexit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31').filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "",
  "history_begin_time" : 1656438437048,
  "history_end_time" : 1656438437141,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "coapdh8gizm",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\nexit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31').filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "",
  "history_begin_time" : 1656438197344,
  "history_end_time" : 1656438198990,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "xso2mp9ajro",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\nexit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31').filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "",
  "history_begin_time" : 1656437723271,
  "history_end_time" : 1656437724010,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "oqzovnmdd08",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\nexit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31').filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "",
  "history_begin_time" : 1656362531026,
  "history_end_time" : 1656362533353,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "gb5oh3d0dhi",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\nexit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31').filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "",
  "history_begin_time" : 1656361466137,
  "history_end_time" : 1656361466441,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "7bk8zjjtpgp",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\nexit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31').filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "",
  "history_begin_time" : 1656361420833,
  "history_end_time" : 1656361423100,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "ejxtqcg62n5",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\nexit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31').filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "",
  "history_begin_time" : 1656361410654,
  "history_end_time" : 1656361412784,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "11zzvz8kamd",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\nexit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31').filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "",
  "history_begin_time" : 1656361173265,
  "history_end_time" : 1656361173419,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "np9iy92oryg",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\nexit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31').filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "Traceback (most recent call last):\n  File \"C:\\Users\\BLi\\gw-workspace\\np9iy92oryg\\data_gee_sentinel1_station_only.py\", line 12, in <module>\n    import geojson\nModuleNotFoundError: No module named 'geojson'\n",
  "history_begin_time" : 1656360846232,
  "history_end_time" : 1656360848357,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "4yur3344sso",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\nexit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31').filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "",
  "history_begin_time" : 1656360788341,
  "history_end_time" : 1656360788454,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "uiyytx94197",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\nexit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31').filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "",
  "history_begin_time" : 1656360760232,
  "history_end_time" : 1656360760738,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "xdufnkp4ktw",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\nexit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31').filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "Traceback (most recent call last):\n  File \"C:\\Users\\BLi\\gw-workspace\\xdufnkp4ktw\\data_gee_sentinel1_station_only.py\", line 8, in <module>\n    import seaborn as sns\nModuleNotFoundError: No module named 'seaborn'\n",
  "history_begin_time" : 1656360655365,
  "history_end_time" : 1656360656320,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "zdp03z1ri4t",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\nexit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31').filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "C:\\Users\\BLi\\anaconda3\\envs\\snowcast\\lib\\site-packages\\numpy\\__init__.py:142: UserWarning: mkl-service package failed to import, therefore Intel(R) MKL initialization ensuring its correct out-of-the box operation under condition when Gnu OpenMP had already been loaded by Python process is not assured. Please install mkl-service package, see http://github.com/IntelPython/mkl-service\n  from . import _distributor_init\nTraceback (most recent call last):\n  File \"C:\\Users\\BLi\\gw-workspace\\zdp03z1ri4t\\data_gee_sentinel1_station_only.py\", line 6, in <module>\n    import pandas as pd\n  File \"C:\\Users\\BLi\\anaconda3\\envs\\snowcast\\lib\\site-packages\\pandas\\__init__.py\", line 16, in <module>\n    raise ImportError(\nImportError: Unable to import required dependencies:\nnumpy: \nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\nWe have compiled some common reasons and troubleshooting tips at:\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\nPlease note and check the following:\n  * The Python version is: Python3.9 from \"C:\\Users\\BLi\\anaconda3\\envs\\snowcast\\python.exe\"\n  * The NumPy version is: \"1.22.3\"\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\nOriginal error was: DLL load failed while importing _multiarray_umath: The specified module could not be found.\n",
  "history_begin_time" : 1656360396331,
  "history_end_time" : 1656360396480,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "nk5sqt4hlqz",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\nexit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31').filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "C:\\Users\\BLi\\anaconda3\\envs\\snowcast\\lib\\site-packages\\numpy\\__init__.py:142: UserWarning: mkl-service package failed to import, therefore Intel(R) MKL initialization ensuring its correct out-of-the box operation under condition when Gnu OpenMP had already been loaded by Python process is not assured. Please install mkl-service package, see http://github.com/IntelPython/mkl-service\n  from . import _distributor_init\nTraceback (most recent call last):\n  File \"C:\\Users\\BLi\\gw-workspace\\nk5sqt4hlqz\\data_gee_sentinel1_station_only.py\", line 6, in <module>\n    import pandas as pd\n  File \"C:\\Users\\BLi\\anaconda3\\envs\\snowcast\\lib\\site-packages\\pandas\\__init__.py\", line 16, in <module>\n    raise ImportError(\nImportError: Unable to import required dependencies:\nnumpy: \nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\nWe have compiled some common reasons and troubleshooting tips at:\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\nPlease note and check the following:\n  * The Python version is: Python3.9 from \"C:\\Users\\BLi\\anaconda3\\envs\\snowcast\\python.exe\"\n  * The NumPy version is: \"1.22.3\"\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\nOriginal error was: DLL load failed while importing _multiarray_umath: The specified module could not be found.\n",
  "history_begin_time" : 1656360356045,
  "history_end_time" : 1656360356182,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "vm7pkwl1lti",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\nexit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31').filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "C:\\Users\\BLi\\anaconda3\\envs\\snowcast\\lib\\site-packages\\numpy\\__init__.py:142: UserWarning: mkl-service package failed to import, therefore Intel(R) MKL initialization ensuring its correct out-of-the box operation under condition when Gnu OpenMP had already been loaded by Python process is not assured. Please install mkl-service package, see http://github.com/IntelPython/mkl-service\n  from . import _distributor_init\nTraceback (most recent call last):\n  File \"C:\\Users\\BLi\\gw-workspace\\vm7pkwl1lti\\data_gee_sentinel1_station_only.py\", line 6, in <module>\n    import pandas as pd\n  File \"C:\\Users\\BLi\\anaconda3\\envs\\snowcast\\lib\\site-packages\\pandas\\__init__.py\", line 16, in <module>\n    raise ImportError(\nImportError: Unable to import required dependencies:\nnumpy: \nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\nWe have compiled some common reasons and troubleshooting tips at:\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\nPlease note and check the following:\n  * The Python version is: Python3.9 from \"C:\\Users\\BLi\\anaconda3\\envs\\snowcast\\python.exe\"\n  * The NumPy version is: \"1.22.3\"\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\nOriginal error was: DLL load failed while importing _multiarray_umath: The specified module could not be found.\n",
  "history_begin_time" : 1656360285838,
  "history_end_time" : 1656360285972,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "1p7qihw7l4c",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\nexit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31').filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "",
  "history_begin_time" : 1656360134387,
  "history_end_time" : 1656360134471,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "ln7d4x5fguy",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\nexit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31').filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "Traceback (most recent call last):\n  File \"C:\\Users\\BLi\\gw-workspace\\ln7d4x5fguy\\data_gee_sentinel1_station_only.py\", line 6, in <module>\n    import pandas as pd\nModuleNotFoundError: No module named 'pandas'\n",
  "history_begin_time" : 1656349574776,
  "history_end_time" : 1656349574831,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "ldhpsfm6ng2",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\nexit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31').filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "",
  "history_begin_time" : 1656348499662,
  "history_end_time" : 1656348499768,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "oktbdjf5hsg",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\nexit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31').filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "",
  "history_begin_time" : 1655310354414,
  "history_end_time" : 1655310354532,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "4rfhg0ml9gf",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\nexit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31').filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "",
  "history_begin_time" : 1654519490472,
  "history_end_time" : 1654519492571,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "0wo21gf5czt",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\nexit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31').filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "",
  "history_begin_time" : 1647826066768,
  "history_end_time" : 1647826067711,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "pzo6u7jmcva",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\nexit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31').filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "",
  "history_begin_time" : 1647225909399,
  "history_end_time" : 1647225910133,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "d5jochttbdc",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\nexit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31').filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "",
  "history_begin_time" : 1646692939204,
  "history_end_time" : 1646692940751,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "z1e8pbsgf4o",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\nexit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31').filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "",
  "history_begin_time" : 1646604601010,
  "history_end_time" : 1646604602553,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "3q5a4cvd96h",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\nexit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31').filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "",
  "history_begin_time" : 1646269662839,
  "history_end_time" : 1646269664355,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "Sr7nyRTbFarj",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\nexit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31').filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "",
  "history_begin_time" : 1646269494589,
  "history_end_time" : 1646269495975,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "8xsAHFyHya62",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31').filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "Traceback (most recent call last):\n  File \"data_gee_sentinel1_station_only.py\", line 6, in <module>\n    import pandas as pd\nModuleNotFoundError: No module named 'pandas'\n",
  "history_begin_time" : 1645978261619,
  "history_end_time" : null,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "kZneQcbpvwU2",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31') /\n          .filterBounds(poi) /\n          .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')) /\n          .select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "  File \"data_gee_sentinel1_station_only.py\", line 60\n    viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31') /\n                                                                                   ^\nSyntaxError: invalid syntax\n",
  "history_begin_time" : 1645978242109,
  "history_end_time" : null,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "jOAnguArBB5h",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31') \\\n          .filterBounds(poi) \\\n          .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')) \\\n          .select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "  File \"data_gee_sentinel1_station_only.py\", line 61\n    .filterBounds(poi) \n    ^\nIndentationError: unexpected indent\n",
  "history_begin_time" : 1645978214178,
  "history_end_time" : null,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "shKQddToXyqY",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31') \\\n          .filterBounds(poi) \\\n          .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')) \\\n          .select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "  File \"data_gee_sentinel1_station_only.py\", line 61\n    .filterBounds(poi) \n    ^\nIndentationError: unexpected indent\n",
  "history_begin_time" : 1645978161503,
  "history_end_time" : null,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "YJAPjMeYbfd4",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n\n      viirs = ee.ImageCollection(product_name)\n          .filterDate('2013-01-01','2021-12-31') \\\n          .filterBounds(poi) \\\n        .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')) \\\n          .select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "  File \"data_gee_sentinel1_station_only.py\", line 62\n    .filterDate('2013-01-01','2021-12-31') \n    ^\nIndentationError: unexpected indent\n",
  "history_begin_time" : 1645978116693,
  "history_end_time" : null,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "ilxXqgxuFXGz",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31') \\\n            .filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')) \\\n      \t\t.select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "  File \"data_gee_sentinel1_station_only.py\", line 62\n    .filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')) \n    ^\nIndentationError: unexpected indent\n",
  "history_begin_time" : 1645978051647,
  "history_end_time" : null,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "7g34MytYmRqo",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n\n      viirs = ee.ImageCollection(product_name) \\\n          \t.filterDate('2013-01-01','2021-12-31') \\\n            .filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')) \\\n      \t\t.select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "  File \"data_gee_sentinel1_station_only.py\", line 62\n    .filterDate('2013-01-01','2021-12-31') \n    ^\nIndentationError: unexpected indent\n",
  "history_begin_time" : 1645978036370,
  "history_end_time" : null,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "oyfPicZXAwdt",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n\n      viirs = ee.ImageCollection(product_name) \\\n          \t.filterDate('2013-01-01','2021-12-31') \\\n            .filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')) \\\n      \t\t.select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "  File \"data_gee_sentinel1_station_only.py\", line 62\n    .filterDate('2013-01-01','2021-12-31') \n    ^\nIndentationError: unexpected indent\n",
  "history_begin_time" : 1645977983344,
  "history_end_time" : null,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "lqfbo95wcru",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n\n      viirs = ee.ImageCollection(product_name) \\\n          \t.filterDate('2013-01-01','2021-12-31') \\\n            .filterBounds(poi) \\\n          \t.filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')) \\\n      \t\t.select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "  File \"data_gee_sentinel1_station_only.py\", line 62\n    .filterDate('2013-01-01','2021-12-31') \n    ^\nIndentationError: unexpected indent\n",
  "history_begin_time" : 1645977642650,
  "history_end_time" : 1645977643960,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "je29f6",
  "indicator" : "Done"
},{
  "history_id" : "tyjvk2sqzpx",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n\n      viirs = ee.ImageCollection(product_name) \\\n          \t.filterDate('2013-01-01','2021-12-31') \\\n            .filterBounds(poi) \\\n          \t.filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')) \\\n      \t\t.select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "  File \"data_gee_sentinel1_station_only.py\", line 62\n    .filterDate('2013-01-01','2021-12-31') \n    ^\nIndentationError: unexpected indent\n",
  "history_begin_time" : 1645977435540,
  "history_end_time" : 1645977436722,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "je29f6",
  "indicator" : "Done"
},{
  "history_id" : "rSEuzQNreO3v",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n\n      viirs = ee.ImageCollection(product_name) \\\n          \t.filterDate('2013-01-01','2021-12-31') \\\n            .filterBounds(poi) \\\n          \t.filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')) \\\n      \t\t.select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "/Users/joe\ncollecting  76b55900-eb3d-4d25-a538-f74302ffe72d\nexists skipping..\ncollecting  f191fe19-0e81-4bc9-9980-29738a05a49b\nexists skipping..\ncollecting  f6106ef5-e6fd-423b-9034-59bce18319da\nexists skipping..\ncollecting  0a54de9c-d804-4681-9f7f-9f770a0f6d2e\nexists skipping..\ncollecting  4f383fb2-6cc7-48a8-9bdb-9c5d150e6eae\nexists skipping..\ncollecting  7cf8af73-1abf-40ad-9788-0d757201eeb0\nexists skipping..\ncollecting  30641173-db10-4320-ab1e-c46e765a9011\nexists skipping..\ncollecting  30ab5128-9a8f-4446-b781-faf8bafb677f\nexists skipping..\ncollecting  df01bf44-46b8-4541-b0a4-ed1fae16ac38\nexists skipping..\ncollecting  6dd37e24-0a9c-4749-8ab6-7e26d42925d6\nexists skipping..\ncollecting  018cf1a1-f945-4097-9c47-0c4690538bb5\nexists skipping..\ncollecting  962f6718-ce02-4d13-b28c-e159d1adc2d4\nexists skipping..\ncollecting  c89dc6ca-6d69-41ce-954d-b51f64aaacb1\nexists skipping..\ncollecting  4bb8fe22-653c-4611-a3d8-de5b2c62d13d\nexists skipping..\ncollecting  d674ee8e-49f1-44c9-890d-4e04997522a1\nexists skipping..\ncollecting  65565709-caca-4ed5-a8b6-2794da371708\nexists skipping..\ncollecting  c89dc6ca-6d69-41ce-954d-b51f64aaacb1\nexists skipping..\ncollecting  76b55900-eb3d-4d25-a538-f74302ffe72d\nexists skipping..\ncollecting  f11515e9-f2a0-4f8c-9f2d-12b9e2dc8569\nexists skipping..\ncollecting  cc66f524-dd2b-4d3f-bf96-4941edca2879\nexists skipping..\ncollecting  09288a61-d120-4cee-ac46-5a275a8f005c\nexists skipping..\ncollecting  51ebe834-adf4-474e-871e-28ebca2bd0cc\nexists skipping..\ncollecting  4f383fb2-6cc7-48a8-9bdb-9c5d150e6eae\nexists skipping..\ncollecting  4f383fb2-6cc7-48a8-9bdb-9c5d150e6eae\nexists skipping..\ncollecting  76b55900-eb3d-4d25-a538-f74302ffe72d\nexists skipping..\ncollecting  c89dc6ca-6d69-41ce-954d-b51f64aaacb1\nexists skipping..\ncollecting  70bfdc00-dbd2-4c44-8039-04a547f91f76\nexists skipping..\ncollecting  01be2cc7-ef77-4e4d-80ed-c4f8139162c3\nexists skipping..\ncollecting  9023330c-2766-4585-b6fe-63593c519e03\nexists skipping..\ncollecting  76b55900-eb3d-4d25-a538-f74302ffe72d\nexists skipping..\ncollecting  962f6718-ce02-4d13-b28c-e159d1adc2d4\nexists skipping..\ncollecting  f6106ef5-e6fd-423b-9034-59bce18319da\nexists skipping..\ncollecting  c89dc6ca-6d69-41ce-954d-b51f64aaacb1\nexists skipping..\ncollecting  d674ee8e-49f1-44c9-890d-4e04997522a1\nexists skipping..\ncollecting  f6106ef5-e6fd-423b-9034-59bce18319da\nexists skipping..\ncollecting  ddc760c7-dc6e-4fd4-ac1a-987ba3f79748\nexists skipping..\ncollecting  690ae8d4-c0d0-4dad-a7c4-67f3df07cc78\nexists skipping..\ncollecting  dbf421d4-0295-4a9f-9e20-88ac299360b1\nexists skipping..\ncollecting  51ebe834-adf4-474e-871e-28ebca2bd0cc\nexists skipping..\ncollecting  5ec8a57d-8d5f-4331-b1fb-9d766f42991a\nexists skipping..\ncollecting  403090bc-fc9e-44fb-921b-f7eea63e9740\nexists skipping..\ncollecting  232ef8b4-938f-42d7-a6e4-647d5280edd2\nexists skipping..\ncollecting  cc8b7ef5-1c86-4bd2-8cb9-969c7df1884e\nexists skipping..\ncollecting  018cf1a1-f945-4097-9c47-0c4690538bb5\nexists skipping..\ncollecting  d674ee8e-49f1-44c9-890d-4e04997522a1\nexists skipping..\ncollecting  65565709-caca-4ed5-a8b6-2794da371708\nexists skipping..\ncollecting  df01bf44-46b8-4541-b0a4-ed1fae16ac38\nexists skipping..\ncollecting  39dd8dce-b4a1-4db5-bc31-fba72181cf5e\nexists skipping..\ncollecting  d674ee8e-49f1-44c9-890d-4e04997522a1\nexists skipping..\ncollecting  df01bf44-46b8-4541-b0a4-ed1fae16ac38\nexists skipping..\ncollecting  49b01e43-f719-450f-b7c6-556b08e9ef4d\nexists skipping..\ncollecting  d674ee8e-49f1-44c9-890d-4e04997522a1\nexists skipping..\ncollecting  51ebe834-adf4-474e-871e-28ebca2bd0cc\nexists skipping..\ncollecting  018cf1a1-f945-4097-9c47-0c4690538bb5\nexists skipping..\ncollecting  018cf1a1-f945-4097-9c47-0c4690538bb5\nexists skipping..\ncollecting  018cf1a1-f945-4097-9c47-0c4690538bb5\nexists skipping..\ncollecting  147d5eb4-e574-47e4-994a-8a2908c06050\nexists skipping..\ncollecting  74f8c8bc-2f60-4232-b447-43459d5d22f0\nexists skipping..\ncollecting  6dd37e24-0a9c-4749-8ab6-7e26d42925d6\nexists skipping..\ncollecting  01be2cc7-ef77-4e4d-80ed-c4f8139162c3\nexists skipping..\ncollecting  01be2cc7-ef77-4e4d-80ed-c4f8139162c3\nexists skipping..\ncollecting  018cf1a1-f945-4097-9c47-0c4690538bb5\nexists skipping..\ncollecting  00c4db22-a423-41a4-ada6-a8b1b04153a4\nexists skipping..\ncollecting  ec0952b6-f119-4f40-bf47-343d71245ddc\nexists skipping..\ncollecting  74f8c8bc-2f60-4232-b447-43459d5d22f0\nexists skipping..\ncollecting  d674ee8e-49f1-44c9-890d-4e04997522a1\nexists skipping..\ncollecting  d674ee8e-49f1-44c9-890d-4e04997522a1\nexists skipping..\ncollecting  b5c7343d-a4a9-4da9-aee3-36539a545af6\nexists skipping..\ncollecting  17da8ab4-6dd8-481e-a025-7574765ef9b1\nexists skipping..\ncollecting  65565709-caca-4ed5-a8b6-2794da371708\nexists skipping..\ncollecting  4f383fb2-6cc7-48a8-9bdb-9c5d150e6eae\nexists skipping..\ncollecting  74f8c8bc-2f60-4232-b447-43459d5d22f0\nexists skipping..\ncollecting  d563ff8c-31c3-44a9-8fd3-2f8bc68b21b4\nexists skipping..\ncollecting  51ebe834-adf4-474e-871e-28ebca2bd0cc\nexists skipping..\ncollecting  018cf1a1-f945-4097-9c47-0c4690538bb5\nexists skipping..\ncollecting  cbe04952-a2ae-4525-98c5-a644c9a5ddc5\nexists skipping..\ncollecting  f6106ef5-e6fd-423b-9034-59bce18319da\nexists skipping..\ncollecting  7cf8af73-1abf-40ad-9788-0d757201eeb0\nexists skipping..\ncollecting  147d5eb4-e574-47e4-994a-8a2908c06050\nexists skipping..\ncollecting  c89dc6ca-6d69-41ce-954d-b51f64aaacb1\nexists skipping..\ncollecting  7cf8af73-1abf-40ad-9788-0d757201eeb0\nexists skipping..\ncollecting  65565709-caca-4ed5-a8b6-2794da371708\nexists skipping..\ncollecting  74f8c8bc-2f60-4232-b447-43459d5d22f0\nexists skipping..\ncollecting  7cf8af73-1abf-40ad-9788-0d757201eeb0\nexists skipping..\ncollecting  c89dc6ca-6d69-41ce-954d-b51f64aaacb1\nexists skipping..\ncollecting  962f6718-ce02-4d13-b28c-e159d1adc2d4\nexists skipping..\ncollecting  65565709-caca-4ed5-a8b6-2794da371708\nexists skipping..\ncollecting  01be2cc7-ef77-4e4d-80ed-c4f8139162c3\nexists skipping..\ncollecting  962f6718-ce02-4d13-b28c-e159d1adc2d4\nexists skipping..\ncollecting  f6106ef5-e6fd-423b-9034-59bce18319da\nexists skipping..\ncollecting  147d5eb4-e574-47e4-994a-8a2908c06050\nexists skipping..\ncollecting  6e96bf06-cbc5-45b5-a36b-e37864226099\nexists skipping..\ncollecting  f6106ef5-e6fd-423b-9034-59bce18319da\nexists skipping..\ncollecting  f6106ef5-e6fd-423b-9034-59bce18319da\nexists skipping..\ncollecting  c7e3f62c-a812-4342-8e4c-3a6a5dd96255\nexists skipping..\ncollecting  a8e91cfa-724a-4114-a9d4-291785ff31f8\nexists skipping..\ncollecting  2dde4be2-b6fd-47e8-b53d-88b59d74fde1\nexists skipping..\ncollecting  b2e9cb6b-b45a-4cab-8333-247cb4c0b51b\nexists skipping..\ncollecting  46f21569-8ecf-4c46-b65b-d80fa83a20d5\nexists skipping..\ncollecting  643c05b6-03bc-4024-8000-2228f4b5a7ad\nexists skipping..\ncollecting  fb078c7e-4975-4c7f-8f42-180386ac8c3c\nexists skipping..\ncollecting  51ebe834-adf4-474e-871e-28ebca2bd0cc\nexists skipping..\ncollecting  f6106ef5-e6fd-423b-9034-59bce18319da\nexists skipping..\ncollecting  dba335b6-9d97-4a89-9ff3-888a8a45575f\nexists skipping..\ncollecting  057fb61e-ce45-4423-9ef2-b52d8c1237e9\nexists skipping..\ncollecting  50f7b567-4066-4437-a335-71aff4c94a2c\nexists skipping..\ncollecting  5e252b65-58dd-421f-a0db-3d4669bfb235\nexists skipping..\ncollecting  efada0af-09bf-4013-a1c6-0837f8ff59c5\nexists skipping..\ncollecting  517aefce-a617-4251-acb9-c5faf0b7fdf3\nexists skipping..\ncollecting  0a0ea690-5b73-4459-91d5-a6948d132a48\nexists skipping..\ncollecting  e6d48180-814d-494b-99cc-0be5cd1a0eaf\nexists skipping..\ncollecting  cdfc27f0-b990-45f7-bac6-7c674cd157ac\nexists skipping..\ncollecting  2222b7b3-f48b-4cea-90bf-8e7245d002ea\nexists skipping..\ncollecting  cad51334-b3af-4c23-85c3-451c3447560a\nexists skipping..\ncollecting  8116acfb-8035-4d34-b9b9-b0af2c5697df\nexists skipping..\ncollecting  c66f40ed-f72e-4012-991c-1f3726e5c8ad\nexists skipping..\ncollecting  6afdc499-9686-4451-b207-13df777df662\nexists skipping..\ncollecting  02cf33c2-c8e2-48b9-bf72-92506e97e251\nexists skipping..\ncollecting  8c45801f-6377-42e1-ae0a-9b53593ff843\nexists skipping..\ncollecting  9f0599d8-81f3-4ab5-b275-48a6ddaaae5b\nexists skipping..\ncollecting  86257c69-a8f1-43b1-9e07-73129e2c3fbc\nexists skipping..\ncollecting  43be1328-02b0-4cc1-8e9b-75842908cee3\nexists skipping..\ncollecting  eeb0a123-9482-4946-ab3f-9e63541cb655\nexists skipping..\ncollecting  f62e6b4d-7f9d-4139-bac4-59f084fb09cd\nexists skipping..\ncollecting  c59f438c-f00a-476a-938e-efd828e0d083\nexists skipping..\ncollecting  7acd0d51-ff30-42a3-9338-590432bd0e43\nexists skipping..\ncollecting  3b5bfd37-070c-4ee9-a470-c9338851e270\nexists skipping..\ncollecting  3b5bfd37-070c-4ee9-a470-c9338851e270\nexists skipping..\ncollecting  43be1328-02b0-4cc1-8e9b-75842908cee3\nexists skipping..\ncollecting  d674ee8e-49f1-44c9-890d-4e04997522a1\nexists skipping..\ncollecting  c89dc6ca-6d69-41ce-954d-b51f64aaacb1\nexists skipping..\ncollecting  74f8c8bc-2f60-4232-b447-43459d5d22f0\nexists skipping..\ncollecting  2f5c1968-2c34-4539-a9f4-38298d0de925\nexists skipping..\ncollecting  10162c55-772d-49d2-8b1b-b1f9c86254b2\nexists skipping..\ncollecting  c340219b-307b-412b-9368-b50639bd372d\nexists skipping..\ncollecting  02cf33c2-c8e2-48b9-bf72-92506e97e251\nexists skipping..\ncollecting  24cd85fa-6aee-4556-bb8a-b6696eb72a19\nexists skipping..\ncollecting  24cd85fa-6aee-4556-bb8a-b6696eb72a19\nexists skipping..\ncollecting  c89dc6ca-6d69-41ce-954d-b51f64aaacb1\nexists skipping..\ncollecting  bfda850c-3027-4e91-afcb-cca5e73e4a03\nexists skipping..\ncollecting  5e252b65-58dd-421f-a0db-3d4669bfb235\nexists skipping..\ncollecting  f78ea076-10a1-45dc-a848-c08e129c6a28\nexists skipping..\ncollecting  ce76ce00-c8b5-4597-8ca3-1ec9db795b50\nexists skipping..\ncollecting  a6861fc3-2315-451b-9b95-c06d1ea96b4b\nexists skipping..\ncollecting  9474e816-b673-4e6d-83e0-28c274945bef\nexists skipping..\ncollecting  2222b7b3-f48b-4cea-90bf-8e7245d002ea\nexists skipping..\ncollecting  ad44deb7-e56d-47bd-8d64-7147493e0aee\nexists skipping..\ncollecting  b99b0ffd-6fa9-482c-8511-f7b87e705d35\nexists skipping..\ncollecting  e833aad1-6da3-4413-b25e-b2ab5b2029c0\nexists skipping..\ncollecting  cdfc27f0-b990-45f7-bac6-7c674cd157ac\nexists skipping..\ncollecting  f46e7d90-a754-44a8-b262-63f5c401a0ab\nexists skipping..\ncollecting  0f46ad2b-4b1f-4232-8e46-be7122d53b86\nexists skipping..\ncollecting  cdfc27f0-b990-45f7-bac6-7c674cd157ac\nexists skipping..\ncollecting  8ca1aaab-07de-4532-a99f-4ab8bce2f862\nexists skipping..\ncollecting  8ca1aaab-07de-4532-a99f-4ab8bce2f862\nexists skipping..\ncollecting  2222b7b3-f48b-4cea-90bf-8e7245d002ea\nexists skipping..\ncollecting  2222b7b3-f48b-4cea-90bf-8e7245d002ea\nexists skipping..\ncollecting  2222b7b3-f48b-4cea-90bf-8e7245d002ea\nexists skipping..\ncollecting  8116acfb-8035-4d34-b9b9-b0af2c5697df\nexists skipping..\ncollecting  f62e6b4d-7f9d-4139-bac4-59f084fb09cd\nexists skipping..\ncollecting  c0e85162-6ff4-401b-b01e-cc6d7a51eac0\nexists skipping..\ncollecting  e4473542-1804-41c0-82b2-eaddc245845d\nexists skipping..\ncollecting  e4473542-1804-41c0-82b2-eaddc245845d\nexists skipping..\ncollecting  aa0d6340-c817-48c9-8727-8d3457606381\nexists skipping..\ncollecting  1135e377-22e6-4290-b4cd-e6739de7fd8a\nexists skipping..\ncollecting  f25cdbec-2f14-42c5-a6ef-a60f3a90caff\nexists skipping..\ncollecting  06ec1554-a0ea-41cf-85f8-43f4b48c7599\nexists skipping..\ncollecting  02c3ec4a-8de4-4284-9ec1-5a942d3d098e\nexists skipping..\ncollecting  c5a82752-3e4b-43ec-8011-9111b9bfcb89\nexists skipping..\ncollecting  679fe096-5475-4d4d-b0f8-81e32de889aa\nexists skipping..\ncollecting  990e5974-9c60-4c9a-ba23-ddce13971178\nexists skipping..\ncollecting  064d7f3e-8bbd-49cd-b360-5c4590a19b9e\nexists skipping..\ncollecting  875622b7-5253-43d2-8e0f-348767860eb9\nexists skipping..\ncollecting  eb1d889a-c427-49e1-95a1-fa6577002c9b\nexists skipping..\ncollecting  a2588440-600e-41da-b2b9-1f5632ecdef6\nexists skipping..\ncollecting  972ab3b1-7445-4f57-a1a1-c3be4c257869\nexists skipping..\ncollecting  09f879b9-4378-479e-949b-cdc3bec8f59f\nexists skipping..\ncollecting  e925f8e6-6eee-4fa7-9034-41eb9917df5e\nexists skipping..\ncollecting  d37ccc2e-7127-48ec-9425-2e77681c3635\nexists skipping..\ncollecting  ba4b2f3f-c8e3-4535-9781-426e4f77ba4c\nexists skipping..\ncollecting  38793f95-324b-4f01-b1a7-45e1c9353bc1\nexists skipping..\ncollecting  55d3e9a6-e153-43c3-a66c-cd60711ff4a9\nexists skipping..\ncollecting  ad44deb7-e56d-47bd-8d64-7147493e0aee\nexists skipping..\ncollecting  38793f95-324b-4f01-b1a7-45e1c9353bc1\nexists skipping..\ncollecting  38793f95-324b-4f01-b1a7-45e1c9353bc1\nexists skipping..\ncollecting  55d3e9a6-e153-43c3-a66c-cd60711ff4a9\nexists skipping..\ncollecting  38793f95-324b-4f01-b1a7-45e1c9353bc1\nexists skipping..\ncollecting  7b636fe2-1760-45c5-afce-505f2e927163\nexists skipping..\ncollecting  dc31c331-837b-4b59-b184-051321e9489c\nexists skipping..\ncollecting  12bde9ee-0e0a-49ac-ab19-b410adb61b3c\nexists skipping..\ncollecting  9f0599d8-81f3-4ab5-b275-48a6ddaaae5b\nexists skipping..\ncollecting  c0568d62-49c7-4d9f-beba-ac0fb3e064c5\nexists skipping..\ncollecting  a6861fc3-2315-451b-9b95-c06d1ea96b4b\nexists skipping..\ncollecting  a6861fc3-2315-451b-9b95-c06d1ea96b4b\nexists skipping..\ncollecting  e3473791-6153-49bc-a2ed-0b1e3e243942\nexists skipping..\ncollecting  e3473791-6153-49bc-a2ed-0b1e3e243942\nexists skipping..\ncollecting  e3473791-6153-49bc-a2ed-0b1e3e243942\nexists skipping..\ncollecting  47e625fa-e2df-43ce-84dd-8ac21fdda75a\nexists skipping..\ncollecting  674e34ce-8b77-422b-ab14-c6c3a0183e39\nexists skipping..\ncollecting  9813294e-a28e-45c0-976d-a6fa65d87927\nexists skipping..\ncollecting  548ff935-a421-4f4c-8eef-0bb19ed6c5f8\nexists skipping..\ncollecting  cad51334-b3af-4c23-85c3-451c3447560a\nexists skipping..\ncollecting  f9f7132d-56a2-43e2-baba-312f34dbaeed\nexists skipping..\ncollecting  a28a3caf-eea2-414f-8003-62ac82daaafa\nexists skipping..\ncollecting  f1f17cee-3fca-44bc-8974-b72d5f995a4a\nexists skipping..\ncollecting  14c19b34-6359-4d3f-865e-0b9852a0e958\nexists skipping..\ncollecting  55d3e9a6-e153-43c3-a66c-cd60711ff4a9\nexists skipping..\ncollecting  93b8483d-a510-42ff-865e-33d5a8784dc4\nexists skipping..\ncollecting  20b97bae-60d6-466d-aca9-334d9b2d63b6\nexists skipping..\ncollecting  0a820e12-033b-45d6-9ef9-d70f4c5e5b63\nexists skipping..\ncollecting  ad9f3d28-ef5a-4851-a5e4-5e2f7b63d17b\nexists skipping..\ncollecting  cfe58efd-ce2a-495a-90cd-6826f704ebee\nexists skipping..\ncollecting  9813294e-a28e-45c0-976d-a6fa65d87927\nexists skipping..\ncollecting  7bc3c413-4709-4ddd-a2ad-99f6cad9436c\nexists skipping..\ncollecting  ad9f3d28-ef5a-4851-a5e4-5e2f7b63d17b\nexists skipping..\ncollecting  ad9f3d28-ef5a-4851-a5e4-5e2f7b63d17b\nexists skipping..\ncollecting  9813294e-a28e-45c0-976d-a6fa65d87927\nexists skipping..\ncollecting  06ec1554-a0ea-41cf-85f8-43f4b48c7599\nexists skipping..\ncollecting  19b5e6ce-c1a0-4cce-85f5-248c9f1abb6e\nexists skipping..\ncollecting  d674ee8e-49f1-44c9-890d-4e04997522a1\nexists skipping..\ncollecting  a5080351-033f-4cfa-ad27-019fc84e052c\nexists skipping..\ncollecting  0efc68ba-5786-4c54-8028-e6f92efa6757\nexists skipping..\ncollecting  93b8483d-a510-42ff-865e-33d5a8784dc4\nexists skipping..\ncollecting  55d3e9a6-e153-43c3-a66c-cd60711ff4a9\nexists skipping..\ncollecting  ad44deb7-e56d-47bd-8d64-7147493e0aee\nexists skipping..\ncollecting  f9f7132d-56a2-43e2-baba-312f34dbaeed\nexists skipping..\ncollecting  8116acfb-8035-4d34-b9b9-b0af2c5697df\nexists skipping..\ncollecting  9c43edf0-541f-4dbb-9fe1-42cc83d453bd\nexists skipping..\ncollecting  c59f438c-f00a-476a-938e-efd828e0d083\nexists skipping..\ncollecting  2f266b81-aad3-4c26-ac69-1bd04a208bf7\nexists skipping..\ncollecting  76b55900-eb3d-4d25-a538-f74302ffe72d\nexists skipping..\ncollecting  dc31c331-837b-4b59-b184-051321e9489c\nexists skipping..\ncollecting  ad44deb7-e56d-47bd-8d64-7147493e0aee\nexists skipping..\ncollecting  875622b7-5253-43d2-8e0f-348767860eb9\nexists skipping..\ncollecting  cdfc27f0-b990-45f7-bac6-7c674cd157ac\nexists skipping..\ncollecting  ad44deb7-e56d-47bd-8d64-7147493e0aee\nexists skipping..\ncollecting  f6a782f0-4b17-4989-815c-2398b77b09dd\nexists skipping..\ncollecting  5308a803-69e6-43cd-89db-66e93f9f83af\nexists skipping..\ncollecting  147d5eb4-e574-47e4-994a-8a2908c06050\nexists skipping..\ncollecting  7b636fe2-1760-45c5-afce-505f2e927163\nexists skipping..\ncollecting  ba4b2f3f-c8e3-4535-9781-426e4f77ba4c\nexists skipping..\ncollecting  cacaa17b-0b1b-4fe2-a4c1-7728e6c154c1\nexists skipping..\ncollecting  e9759e79-461c-425e-af17-0a88be1a441f\nexists skipping..\ncollecting  0cda0c4a-405b-4e16-8922-964190929d80\nexists skipping..\ncollecting  76b55900-eb3d-4d25-a538-f74302ffe72d\nexists skipping..\ncollecting  c07ab5f6-14a9-4b0b-a9af-9f7db6e8c220\nexists skipping..\ncollecting  2ca6a37f-67f5-4905-864b-ddf98d956ebb\nexists skipping..\ncollecting  78ccacb3-4eb9-4d95-b244-f3a709e39fd1\nexists skipping..\ncollecting  cad51334-b3af-4c23-85c3-451c3447560a\nexists skipping..\ncollecting  36b98590-a7e6-4e00-8c7d-f0f3d25bafec\nexists skipping..\ncollecting  972ab3b1-7445-4f57-a1a1-c3be4c257869\nexists skipping..\ncollecting  0b9543d3-3cf9-4f28-b8eb-fd22c1956153\nexists skipping..\ncollecting  36b98590-a7e6-4e00-8c7d-f0f3d25bafec\nexists skipping..\ncollecting  4f13c5e6-14c0-44cf-a2b0-4ef9bb3704fd\nexists skipping..\ncollecting  674e34ce-8b77-422b-ab14-c6c3a0183e39\nexists skipping..\ncollecting  8116acfb-8035-4d34-b9b9-b0af2c5697df\nexists skipping..\ncollecting  c66f40ed-f72e-4012-991c-1f3726e5c8ad\nexists skipping..\ncollecting  af0463d4-f20f-4d13-bd0f-5834e2e8717b\nexists skipping..\ncollecting  5308a803-69e6-43cd-89db-66e93f9f83af\nexists skipping..\ncollecting  f9f7132d-56a2-43e2-baba-312f34dbaeed\nexists skipping..\ncollecting  c07ab5f6-14a9-4b0b-a9af-9f7db6e8c220\nexists skipping..\ncollecting  c5a82752-3e4b-43ec-8011-9111b9bfcb89\nexists skipping..\ncollecting  e776d9b6-2180-4f50-90bf-77f7b920fc3b\nexists skipping..\ncollecting  69d48a07-3007-4b3f-bec6-c097509a56d9\nexists skipping..\ncollecting  10a46ea0-13da-4cef-9aa6-ff48aa46881c\nexists skipping..\ncollecting  9813294e-a28e-45c0-976d-a6fa65d87927\nexists skipping..\ncollecting  7bc3c413-4709-4ddd-a2ad-99f6cad9436c\nexists skipping..\ncollecting  631ed3c9-7863-4e7c-86fa-4bfb043f2851\nexists skipping..\ncollecting  b59438b9-aadc-4899-9afb-fe71974c5c3a\nexists skipping..\ncollecting  b59438b9-aadc-4899-9afb-fe71974c5c3a\nexists skipping..\ncollecting  38793f95-324b-4f01-b1a7-45e1c9353bc1\nexists skipping..\ncollecting  cad51334-b3af-4c23-85c3-451c3447560a\nexists skipping..\ncollecting  03428fd9-01cc-4a57-ab6e-f4e8f265c094\nexists skipping..\ncollecting  f1f17cee-3fca-44bc-8974-b72d5f995a4a\nexists skipping..\ncollecting  c66f40ed-f72e-4012-991c-1f3726e5c8ad\nexists skipping..\ncollecting  7b636fe2-1760-45c5-afce-505f2e927163\nexists skipping..\ncollecting  d674ee8e-49f1-44c9-890d-4e04997522a1\nexists skipping..\ncollecting  dd7f64aa-3556-409b-bc86-71dc28b6fd45\nexists skipping..\ncollecting  990e5974-9c60-4c9a-ba23-ddce13971178\nexists skipping..\ncollecting  71f41513-6ac9-4d2e-97eb-6cd3b84f7043\nexists skipping..\ncollecting  d64197fc-0723-4c61-9ce8-ff2554e24154\nexists skipping..\ncollecting  89a7b0ef-1ec8-490f-9207-c93aa57a147f\nexists skipping..\ncollecting  b1936012-0d31-4b92-8d60-c24903b2e569\nexists skipping..\ncollecting  9813294e-a28e-45c0-976d-a6fa65d87927\nexists skipping..\ncollecting  4f13c5e6-14c0-44cf-a2b0-4ef9bb3704fd\nexists skipping..\ncollecting  333458b2-c1a9-47a3-8ae0-92053ad28ae3\nexists skipping..\ncollecting  ab89875f-3b86-4c6a-8d66-767017570dfc\nexists skipping..\ncollecting  6de38d5b-ccce-4ff2-90ed-1c7035491518\nexists skipping..\ncollecting  c89dc6ca-6d69-41ce-954d-b51f64aaacb1\nexists skipping..\ncollecting  6bc3e088-5139-43f2-9b2a-ade1cedeae47\nexists skipping..\ncollecting  517aefce-a617-4251-acb9-c5faf0b7fdf3\nexists skipping..\ncollecting  f46e7d90-a754-44a8-b262-63f5c401a0ab\nexists skipping..\ncollecting  7b636fe2-1760-45c5-afce-505f2e927163\nexists skipping..\ncollecting  e467a17f-a729-4938-87a1-ac25157eed63\nexists skipping..\ncollecting  eeb0a123-9482-4946-ab3f-9e63541cb655\nexists skipping..\ncollecting  a28a3caf-eea2-414f-8003-62ac82daaafa\nexists skipping..\ncollecting  c66f40ed-f72e-4012-991c-1f3726e5c8ad\nexists skipping..\ncollecting  42a21eb9-10fd-4986-825b-9ea55ce13935\nexists skipping..\ncollecting  bb65d7a1-a5d5-4c89-9ef9-f0f1db06cc58\nexists skipping..\ncollecting  c59f438c-f00a-476a-938e-efd828e0d083\nexists skipping..\ncollecting  6bc3e088-5139-43f2-9b2a-ade1cedeae47\nexists skipping..\ncollecting  692c41af-2210-4dd6-916d-c99e76807447\nexists skipping..\ncollecting  6662f7d0-4afc-4fed-b930-e0408ee10bc7\nexists skipping..\ncollecting  4f13c5e6-14c0-44cf-a2b0-4ef9bb3704fd\nexists skipping..\ncollecting  b1936012-0d31-4b92-8d60-c24903b2e569\nexists skipping..\ncollecting  fb32a838-cf3b-47a2-9e22-395a730f4f4f\nexists skipping..\ncollecting  fb32a838-cf3b-47a2-9e22-395a730f4f4f\nexists skipping..\ncollecting  ea185683-4427-44c3-84e1-706cf16781ce\nexists skipping..\ncollecting  ab89875f-3b86-4c6a-8d66-767017570dfc\nexists skipping..\ncollecting  55d3e9a6-e153-43c3-a66c-cd60711ff4a9\nexists skipping..\ncollecting  064d7f3e-8bbd-49cd-b360-5c4590a19b9e\nexists skipping..\ncollecting  064d7f3e-8bbd-49cd-b360-5c4590a19b9e\nexists skipping..\ncollecting  50d7ad3f-57f0-45e1-911d-b0efff9deb8f\nexists skipping..\ncollecting  8edd6091-10fa-4617-8dc8-e0ce1d5b84f7\nexists skipping..\ncollecting  0a820e12-033b-45d6-9ef9-d70f4c5e5b63\nexists skipping..\ncollecting  8edd6091-10fa-4617-8dc8-e0ce1d5b84f7\nexists skipping..\ncollecting  02c3ec4a-8de4-4284-9ec1-5a942d3d098e\nexists skipping..\ncollecting  05938de0-622b-4e0a-a82b-2a128e5be0b0\nexists skipping..\ncollecting  71f41513-6ac9-4d2e-97eb-6cd3b84f7043\nexists skipping..\ncollecting  e776d9b6-2180-4f50-90bf-77f7b920fc3b\nexists skipping..\ncollecting  a4339b9a-871e-44c2-9bb4-bcbfe9d590d7\nexists skipping..\ncollecting  4f13c5e6-14c0-44cf-a2b0-4ef9bb3704fd\nexists skipping..\ncollecting  440d7558-67fd-43b4-826b-26d02663f871\nexists skipping..\ncollecting  f9f7132d-56a2-43e2-baba-312f34dbaeed\nexists skipping..\ncollecting  99a2d4a9-63a0-43a7-976d-2a1ed822186d\nexists skipping..\ncollecting  99a2d4a9-63a0-43a7-976d-2a1ed822186d\nexists skipping..\ncollecting  be57eab6-a495-427f-8a36-9d118c03e7d8\nexists skipping..\ncollecting  1135e377-22e6-4290-b4cd-e6739de7fd8a\nexists skipping..\ncollecting  a5080351-033f-4cfa-ad27-019fc84e052c\nexists skipping..\ncollecting  9474e816-b673-4e6d-83e0-28c274945bef\nexists skipping..\ncollecting  df7e906a-07f3-4a46-b9a5-0200427c26f7\nexists skipping..\ncollecting  360f1bcc-aa60-4052-a18a-b33da5745ff4\nexists skipping..\ncollecting  e27143af-fdc0-4f6f-8a28-f57b78da75dc\nexists skipping..\ncollecting  36b98590-a7e6-4e00-8c7d-f0f3d25bafec\nexists skipping..\ncollecting  10a46ea0-13da-4cef-9aa6-ff48aa46881c\nexists skipping..\ncollecting  02cf33c2-c8e2-48b9-bf72-92506e97e251\nexists skipping..\ncollecting  51ebe834-adf4-474e-871e-28ebca2bd0cc\nexists skipping..\ncollecting  2ca6a37f-67f5-4905-864b-ddf98d956ebb\nexists skipping..\ncollecting  0623939d-b33f-41cb-ade2-3c4a776de49a\nexists skipping..\ncollecting  cfe58efd-ce2a-495a-90cd-6826f704ebee\nexists skipping..\ncollecting  4f13c5e6-14c0-44cf-a2b0-4ef9bb3704fd\nexists skipping..\ncollecting  a6861fc3-2315-451b-9b95-c06d1ea96b4b\nexists skipping..\ncollecting  cacaa17b-0b1b-4fe2-a4c1-7728e6c154c1\nexists skipping..\ncollecting  517aefce-a617-4251-acb9-c5faf0b7fdf3\nexists skipping..\ncollecting  9f0599d8-81f3-4ab5-b275-48a6ddaaae5b\nexists skipping..\ncollecting  36b98590-a7e6-4e00-8c7d-f0f3d25bafec\nexists skipping..\ncollecting  9813294e-a28e-45c0-976d-a6fa65d87927\nexists skipping..\ncollecting  05938de0-622b-4e0a-a82b-2a128e5be0b0\nexists skipping..\ncollecting  8116acfb-8035-4d34-b9b9-b0af2c5697df\nexists skipping..\ncollecting  695c7749-a3b8-4158-bd14-59d1f2c3e736\nexists skipping..\ncollecting  02c3ec4a-8de4-4284-9ec1-5a942d3d098e\nexists skipping..\ncollecting  ad44deb7-e56d-47bd-8d64-7147493e0aee\nexists skipping..\ncollecting  b59438b9-aadc-4899-9afb-fe71974c5c3a\nexists skipping..\ncollecting  02cf33c2-c8e2-48b9-bf72-92506e97e251\nexists skipping..\ncollecting  dca30f20-582e-40ef-be6d-aa7858be4baa\nexists skipping..\ncollecting  695bed09-0ad9-406e-b489-69408adeea06\nexists skipping..\ncollecting  962f6718-ce02-4d13-b28c-e159d1adc2d4\nexists skipping..\ncollecting  f6106ef5-e6fd-423b-9034-59bce18319da\nexists skipping..\ncollecting  631ed3c9-7863-4e7c-86fa-4bfb043f2851\nexists skipping..\ncollecting  d10a90c7-3db0-43c6-b04b-fe8b4c3f206e\nexists skipping..\ncollecting  b1077b69-4b02-458e-8a4b-e68695ac534f\nexists skipping..\ncollecting  86257c69-a8f1-43b1-9e07-73129e2c3fbc\nexists skipping..\ncollecting  e27143af-fdc0-4f6f-8a28-f57b78da75dc\nexists skipping..\ncollecting  e776d9b6-2180-4f50-90bf-77f7b920fc3b\nexists skipping..\ncollecting  10162c55-772d-49d2-8b1b-b1f9c86254b2\nexists skipping..\ncollecting  9813294e-a28e-45c0-976d-a6fa65d87927\nexists skipping..\ncollecting  875622b7-5253-43d2-8e0f-348767860eb9\nexists skipping..\ncollecting  65894307-d4eb-4b2e-a0fa-bd83a102dc30\nexists skipping..\ncollecting  bfda850c-3027-4e91-afcb-cca5e73e4a03\nexists skipping..\ncollecting  f46e7d90-a754-44a8-b262-63f5c401a0ab\nexists skipping..\ncollecting  a28a3caf-eea2-414f-8003-62ac82daaafa\nexists skipping..\ncollecting  d37ccc2e-7127-48ec-9425-2e77681c3635\nexists skipping..\ncollecting  71f41513-6ac9-4d2e-97eb-6cd3b84f7043\nexists skipping..\ncollecting  6bf06917-011b-4029-8fbe-a8dfea3bc598\nexists skipping..\ncollecting  75ced1b1-1fc2-42d3-a4f8-44aa1978c8ef\nexists skipping..\ncollecting  1135e377-22e6-4290-b4cd-e6739de7fd8a\nexists skipping..\ncollecting  f3e36cea-5eb2-495a-87f4-947395f325b0\nexists skipping..\ncollecting  a2588440-600e-41da-b2b9-1f5632ecdef6\nexists skipping..\ncollecting  f3332d55-ecc8-4644-9deb-180e42abb2eb\nexists skipping..\ncollecting  695c7749-a3b8-4158-bd14-59d1f2c3e736\nexists skipping..\ncollecting  9c43edf0-541f-4dbb-9fe1-42cc83d453bd\nexists skipping..\ncollecting  6bf06917-011b-4029-8fbe-a8dfea3bc598\nexists skipping..\ncollecting  631ed3c9-7863-4e7c-86fa-4bfb043f2851\nexists skipping..\ncollecting  9813294e-a28e-45c0-976d-a6fa65d87927\nexists skipping..\ncollecting  695bed09-0ad9-406e-b489-69408adeea06\nexists skipping..\ncollecting  42a21eb9-10fd-4986-825b-9ea55ce13935\nexists skipping..\ncollecting  491846d3-f81a-4777-b49f-0a0c74168395\nexists skipping..\ncollecting  d37ccc2e-7127-48ec-9425-2e77681c3635\nexists skipping..\ncollecting  a5080351-033f-4cfa-ad27-019fc84e052c\nexists skipping..\ncollecting  552a5638-8fd2-46de-8569-5f5512102264\nexists skipping..\ncollecting  6d0ff6eb-0411-4863-b4e7-90958db98115\nexists skipping..\ncollecting  d674ee8e-49f1-44c9-890d-4e04997522a1\nexists skipping..\ncollecting  df7e906a-07f3-4a46-b9a5-0200427c26f7\nexists skipping..\ncollecting  0b9543d3-3cf9-4f28-b8eb-fd22c1956153\nexists skipping..\ncollecting  c5a82752-3e4b-43ec-8011-9111b9bfcb89\nexists skipping..\ncollecting  55d3e9a6-e153-43c3-a66c-cd60711ff4a9\nexists skipping..\ncollecting  0aeaffd7-9089-49e7-85ad-2314f32cbf7c\nexists skipping..\ncollecting  b1077b69-4b02-458e-8a4b-e68695ac534f\nexists skipping..\ncollecting  c0568d62-49c7-4d9f-beba-ac0fb3e064c5\nexists skipping..\ncollecting  50d7ad3f-57f0-45e1-911d-b0efff9deb8f\nexists skipping..\ncollecting  e27143af-fdc0-4f6f-8a28-f57b78da75dc\nexists skipping..\ncollecting  3330a979-98df-4a38-ac3f-0b45374f8e3d\nexists skipping..\ncollecting  990e5974-9c60-4c9a-ba23-ddce13971178\nexists skipping..\ncollecting  a6861fc3-2315-451b-9b95-c06d1ea96b4b\nexists skipping..\ncollecting  50d7ad3f-57f0-45e1-911d-b0efff9deb8f\nexists skipping..\ncollecting  fe33672e-7ea7-4c5d-8639-96b2cc7edb0c\nexists skipping..\ncollecting  440d7558-67fd-43b4-826b-26d02663f871\nexists skipping..\ncollecting  59ac7ee6-8fa8-4888-bb77-2be6781dddaf\nexists skipping..\ncollecting  674e34ce-8b77-422b-ab14-c6c3a0183e39\nexists skipping..\ncollecting  dc237027-8dae-4da7-91ec-501701ecd943\nexists skipping..\ncollecting  b5d7b6b8-4e5d-4b5e-8976-c72e99f57769\nexists skipping..\ncollecting  018cf1a1-f945-4097-9c47-0c4690538bb5\nexists skipping..\ncollecting  018cf1a1-f945-4097-9c47-0c4690538bb5\nexists skipping..\ncollecting  a0c947fb-f00e-4331-ad3a-402908e08b57\nexists skipping..\ncollecting  19b5e6ce-c1a0-4cce-85f5-248c9f1abb6e\nexists skipping..\ncollecting  875622b7-5253-43d2-8e0f-348767860eb9\nexists skipping..\ncollecting  875622b7-5253-43d2-8e0f-348767860eb9\nexists skipping..\ncollecting  36b98590-a7e6-4e00-8c7d-f0f3d25bafec\nexists skipping..\ncollecting  a6861fc3-2315-451b-9b95-c06d1ea96b4b\nexists skipping..\ncollecting  cdfc27f0-b990-45f7-bac6-7c674cd157ac\nexists skipping..\ncollecting  df7e906a-07f3-4a46-b9a5-0200427c26f7\nexists skipping..\ncollecting  695bed09-0ad9-406e-b489-69408adeea06\nexists skipping..\ncollecting  e833aad1-6da3-4413-b25e-b2ab5b2029c0\nexists skipping..\ncollecting  dd7f64aa-3556-409b-bc86-71dc28b6fd45\nexists skipping..\ncollecting  50d7ad3f-57f0-45e1-911d-b0efff9deb8f\nexists skipping..\ncollecting  692c41af-2210-4dd6-916d-c99e76807447\nexists skipping..\ncollecting  89a7b0ef-1ec8-490f-9207-c93aa57a147f\nexists skipping..\ncollecting  408b4482-ff63-4a1f-9cf9-ca820cd51b39\nexists skipping..\ncollecting  f9f7132d-56a2-43e2-baba-312f34dbaeed\nexists skipping..\ncollecting  8c45801f-6377-42e1-ae0a-9b53593ff843\nexists skipping..\ncollecting  c7f13d88-b4af-4484-9547-52197f778c08\nexists skipping..\ncollecting  10a46ea0-13da-4cef-9aa6-ff48aa46881c\nexists skipping..\ncollecting  42a21eb9-10fd-4986-825b-9ea55ce13935\nexists skipping..\ncollecting  a5080351-033f-4cfa-ad27-019fc84e052c\nexists skipping..\ncollecting  ab89875f-3b86-4c6a-8d66-767017570dfc\nexists skipping..\ncollecting  20b97bae-60d6-466d-aca9-334d9b2d63b6\nexists skipping..\ncollecting  01be2cc7-ef77-4e4d-80ed-c4f8139162c3\nexists skipping..\ncollecting  3330a979-98df-4a38-ac3f-0b45374f8e3d\nexists skipping..\ncollecting  491846d3-f81a-4777-b49f-0a0c74168395\nexists skipping..\ncollecting  064d7f3e-8bbd-49cd-b360-5c4590a19b9e\nexists skipping..\ncollecting  4ddee9a9-feaf-4daa-9100-0d4188f7b827\nexists skipping..\ncollecting  b59438b9-aadc-4899-9afb-fe71974c5c3a\nexists skipping..\ncollecting  24cd85fa-6aee-4556-bb8a-b6696eb72a19\nexists skipping..\ncollecting  0adbba56-85f8-49e0-9b11-000622238d91\nexists skipping..\ncollecting  74f8c8bc-2f60-4232-b447-43459d5d22f0\nexists skipping..\ncollecting  cfd2c7fc-c29a-4a32-a11d-d04fa2dd660d\nexists skipping..\ncollecting  57e18a9f-8327-4d6c-b2b4-c2b337341e86\nexists skipping..\ncollecting  e467a17f-a729-4938-87a1-ac25157eed63\nexists skipping..\ncollecting  cdfc27f0-b990-45f7-bac6-7c674cd157ac\nexists skipping..\ncollecting  24cd85fa-6aee-4556-bb8a-b6696eb72a19\nexists skipping..\ncollecting  55d3e9a6-e153-43c3-a66c-cd60711ff4a9\nexists skipping..\ncollecting  10162c55-772d-49d2-8b1b-b1f9c86254b2\nexists skipping..\ncollecting  695bed09-0ad9-406e-b489-69408adeea06\nexists skipping..\ncollecting  b5d7b6b8-4e5d-4b5e-8976-c72e99f57769\nexists skipping..\ncollecting  678f1920-0bc3-4687-af71-35d61030b1a0\nexists skipping..\ncollecting  4f13c5e6-14c0-44cf-a2b0-4ef9bb3704fd\nexists skipping..\ncollecting  e27143af-fdc0-4f6f-8a28-f57b78da75dc\nexists skipping..\ncollecting  47e625fa-e2df-43ce-84dd-8ac21fdda75a\nexists skipping..\ncollecting  02cf33c2-c8e2-48b9-bf72-92506e97e251\nexists skipping..\ncollecting  d17b55c5-7848-4b79-a735-983aec995c52\nexists skipping..\ncollecting  0a820e12-033b-45d6-9ef9-d70f4c5e5b63\nexists skipping..\ncollecting  d37ccc2e-7127-48ec-9425-2e77681c3635\nexists skipping..\ncollecting  a6861fc3-2315-451b-9b95-c06d1ea96b4b\nexists skipping..\ncollecting  d674ee8e-49f1-44c9-890d-4e04997522a1\nexists skipping..\ncollecting  692c41af-2210-4dd6-916d-c99e76807447\nexists skipping..\ncollecting  f6a782f0-4b17-4989-815c-2398b77b09dd\nexists skipping..\ncollecting  fe33672e-7ea7-4c5d-8639-96b2cc7edb0c\nexists skipping..\ncollecting  3330a979-98df-4a38-ac3f-0b45374f8e3d\nexists skipping..\ncollecting  7b636fe2-1760-45c5-afce-505f2e927163\nexists skipping..\ncollecting  87d6c782-c43b-473f-84da-d2a519d8f1fc\nexists skipping..\ncollecting  b5d7b6b8-4e5d-4b5e-8976-c72e99f57769\nexists skipping..\ncollecting  253c2443-b820-4c13-bf6d-ba7a5426f52d\nexists skipping..\ncollecting  55d3e9a6-e153-43c3-a66c-cd60711ff4a9\nexists skipping..\ncollecting  830bc2b9-592d-4334-842a-213ba4c0a347\nexists skipping..\ncollecting  eeb0a123-9482-4946-ab3f-9e63541cb655\nexists skipping..\ncollecting  5c4dff48-4afa-4922-949e-f64db583f392\nexists skipping..\ncollecting  74f8c8bc-2f60-4232-b447-43459d5d22f0\nexists skipping..\ncollecting  36b98590-a7e6-4e00-8c7d-f0f3d25bafec\nexists skipping..\ncollecting  c0e85162-6ff4-401b-b01e-cc6d7a51eac0\nexists skipping..\ncollecting  9474e816-b673-4e6d-83e0-28c274945bef\nexists skipping..\ncollecting  50d7ad3f-57f0-45e1-911d-b0efff9deb8f\nexists skipping..\ncollecting  dc31c331-837b-4b59-b184-051321e9489c\nexists skipping..\ncollecting  0d0b742e-c324-4140-8f62-746210d79080\nexists skipping..\ncollecting  89a7b0ef-1ec8-490f-9207-c93aa57a147f\nexists skipping..\ncollecting  c07ab5f6-14a9-4b0b-a9af-9f7db6e8c220\nexists skipping..\ncollecting  6c94136d-5040-4c09-b1fd-c02dbff210e6\nexists skipping..\ncollecting  dca30f20-582e-40ef-be6d-aa7858be4baa\nexists skipping..\ncollecting  cfd2c7fc-c29a-4a32-a11d-d04fa2dd660d\nexists skipping..\ncollecting  e13f9c1b-dca0-4c63-a64c-76f6bc725156\nexists skipping..\ncollecting  d674ee8e-49f1-44c9-890d-4e04997522a1\nexists skipping..\ncollecting  0cda0c4a-405b-4e16-8922-964190929d80\nexists skipping..\ncollecting  e13f9c1b-dca0-4c63-a64c-76f6bc725156\nexists skipping..\ncollecting  99a2d4a9-63a0-43a7-976d-2a1ed822186d\nexists skipping..\ncollecting  e833aad1-6da3-4413-b25e-b2ab5b2029c0\nexists skipping..\ncollecting  679fe096-5475-4d4d-b0f8-81e32de889aa\nexists skipping..\ncollecting  cfd2c7fc-c29a-4a32-a11d-d04fa2dd660d\nexists skipping..\ncollecting  f9f7132d-56a2-43e2-baba-312f34dbaeed\nexists skipping..\ncollecting  d37ccc2e-7127-48ec-9425-2e77681c3635\nexists skipping..\ncollecting  2ca6a37f-67f5-4905-864b-ddf98d956ebb\nexists skipping..\ncollecting  e13f9c1b-dca0-4c63-a64c-76f6bc725156\nexists skipping..\ncollecting  89a7b0ef-1ec8-490f-9207-c93aa57a147f\nexists skipping..\ncollecting  3527e00e-1aee-46ce-ad9d-8122cff4c202\nexists skipping..\ncollecting  f46e7d90-a754-44a8-b262-63f5c401a0ab\nexists skipping..\ncollecting  c64f2bf3-90f0-4a96-b3a8-9f8db46dce92\nexists skipping..\ncollecting  360f1bcc-aa60-4052-a18a-b33da5745ff4\nexists skipping..\ncollecting  8116acfb-8035-4d34-b9b9-b0af2c5697df\nexists skipping..\ncollecting  692c41af-2210-4dd6-916d-c99e76807447\nexists skipping..\ncollecting  6bf06917-011b-4029-8fbe-a8dfea3bc598\nexists skipping..\ncollecting  94d9d95f-32b2-470d-95f8-dbd843d6def3\nexists skipping..\ncollecting  47e625fa-e2df-43ce-84dd-8ac21fdda75a\nexists skipping..\ncollecting  35aecf7e-5f0b-4533-995c-3cb4165d44b5\nexists skipping..\ncollecting  e776d9b6-2180-4f50-90bf-77f7b920fc3b\nexists skipping..\ncollecting  eeb0a123-9482-4946-ab3f-9e63541cb655\nexists skipping..\ncollecting  0a820e12-033b-45d6-9ef9-d70f4c5e5b63\nexists skipping..\ncollecting  ce76ce00-c8b5-4597-8ca3-1ec9db795b50\nexists skipping..\ncollecting  517aefce-a617-4251-acb9-c5faf0b7fdf3\nexists skipping..\ncollecting  9813294e-a28e-45c0-976d-a6fa65d87927\nexists skipping..\ncollecting  dca30f20-582e-40ef-be6d-aa7858be4baa\nexists skipping..\ncollecting  7b636fe2-1760-45c5-afce-505f2e927163\nexists skipping..\ncollecting  f46e7d90-a754-44a8-b262-63f5c401a0ab\nexists skipping..\ncollecting  5308a803-69e6-43cd-89db-66e93f9f83af\nexists skipping..\ncollecting  47e625fa-e2df-43ce-84dd-8ac21fdda75a\nexists skipping..\ncollecting  630bae26-a6cc-4a36-bbe5-40dc15b38dea\nexists skipping..\ncollecting  bb65d7a1-a5d5-4c89-9ef9-f0f1db06cc58\nexists skipping..\ncollecting  0bd47ec1-0e3c-43bf-a491-534d06beb19f\nexists skipping..\ncollecting  0a0ea690-5b73-4459-91d5-a6948d132a48\nexists skipping..\ncollecting  6afdc499-9686-4451-b207-13df777df662\nexists skipping..\ncollecting  02cf33c2-c8e2-48b9-bf72-92506e97e251\nexists skipping..\ncollecting  ea185683-4427-44c3-84e1-706cf16781ce\nexists skipping..\ncollecting  b98777af-0c7c-44f7-9c03-85d6d412856c\nexists skipping..\ncollecting  7610b45e-5652-4604-ab5b-99344f71616b\nexists skipping..\ncollecting  ad9f3d28-ef5a-4851-a5e4-5e2f7b63d17b\nexists skipping..\ncollecting  e3473791-6153-49bc-a2ed-0b1e3e243942\nexists skipping..\ncollecting  d64197fc-0723-4c61-9ce8-ff2554e24154\nexists skipping..\ncollecting  9f0599d8-81f3-4ab5-b275-48a6ddaaae5b\nexists skipping..\ncollecting  a28a3caf-eea2-414f-8003-62ac82daaafa\nexists skipping..\ncollecting  93b8483d-a510-42ff-865e-33d5a8784dc4\nexists skipping..\ncollecting  f6106ef5-e6fd-423b-9034-59bce18319da\nexists skipping..\ncollecting  a6861fc3-2315-451b-9b95-c06d1ea96b4b\nexists skipping..\ncollecting  cacaa17b-0b1b-4fe2-a4c1-7728e6c154c1\nexists skipping..\ncollecting  dc31c331-837b-4b59-b184-051321e9489c\nexists skipping..\ncollecting  ea185683-4427-44c3-84e1-706cf16781ce\nexists skipping..\ncollecting  df7e906a-07f3-4a46-b9a5-0200427c26f7\nexists skipping..\ncollecting  3b5bfd37-070c-4ee9-a470-c9338851e270\nexists skipping..\ncollecting  8116acfb-8035-4d34-b9b9-b0af2c5697df\nexists skipping..\ncollecting  a6861fc3-2315-451b-9b95-c06d1ea96b4b\nexists skipping..\ncollecting  bfda850c-3027-4e91-afcb-cca5e73e4a03\nexists skipping..\ncollecting  cfd2c7fc-c29a-4a32-a11d-d04fa2dd660d\nexists skipping..\ncollecting  c07ab5f6-14a9-4b0b-a9af-9f7db6e8c220\nexists skipping..\ncollecting  0d0b742e-c324-4140-8f62-746210d79080\nexists skipping..\ncollecting  35eee1cd-f92a-4ba5-af03-fb5347490f41\nexists skipping..\ncollecting  6bf06917-011b-4029-8fbe-a8dfea3bc598\nexists skipping..\ncollecting  ad9f3d28-ef5a-4851-a5e4-5e2f7b63d17b\nexists skipping..\ncollecting  a6861fc3-2315-451b-9b95-c06d1ea96b4b\nexists skipping..\ncollecting  6afdc499-9686-4451-b207-13df777df662\nexists skipping..\ncollecting  5e252b65-58dd-421f-a0db-3d4669bfb235\nexists skipping..\ncollecting  5308a803-69e6-43cd-89db-66e93f9f83af\nexists skipping..\ncollecting  b1077b69-4b02-458e-8a4b-e68695ac534f\nexists skipping..\ncollecting  cdfc27f0-b990-45f7-bac6-7c674cd157ac\nexists skipping..\ncollecting  ce76ce00-c8b5-4597-8ca3-1ec9db795b50\nexists skipping..\ncollecting  02c3ec4a-8de4-4284-9ec1-5a942d3d098e\nexists skipping..\ncollecting  b1077b69-4b02-458e-8a4b-e68695ac534f\nexists skipping..\ncollecting  e467a17f-a729-4938-87a1-ac25157eed63\nexists skipping..\ncollecting  43be1328-02b0-4cc1-8e9b-75842908cee3\nexists skipping..\ncollecting  0a0ea690-5b73-4459-91d5-a6948d132a48\nexists skipping..\ncollecting  1135e377-22e6-4290-b4cd-e6739de7fd8a\nexists skipping..\ncollecting  6bf06917-011b-4029-8fbe-a8dfea3bc598\nexists skipping..\ncollecting  85f0acd8-4008-472d-bf40-e35e0e2934e4\nexists skipping..\ncollecting  7bc3c413-4709-4ddd-a2ad-99f6cad9436c\nexists skipping..\ncollecting  491846d3-f81a-4777-b49f-0a0c74168395\nexists skipping..\ncollecting  df7e906a-07f3-4a46-b9a5-0200427c26f7\nexists skipping..\ncollecting  a6a9febf-ea16-4223-83d4-8e459e2af85a\nexists skipping..\ncollecting  6bf06917-011b-4029-8fbe-a8dfea3bc598\nexists skipping..\ncollecting  01be2cc7-ef77-4e4d-80ed-c4f8139162c3\nexists skipping..\ncollecting  efada0af-09bf-4013-a1c6-0837f8ff59c5\nexists skipping..\ncollecting  cdfc27f0-b990-45f7-bac6-7c674cd157ac\nexists skipping..\ncollecting  962f6718-ce02-4d13-b28c-e159d1adc2d4\nexists skipping..\ncollecting  df7e906a-07f3-4a46-b9a5-0200427c26f7\nexists skipping..\ncollecting  ce9da6bf-cf6e-4edb-b579-5a0853b2ed17\nexists skipping..\ncollecting  517aefce-a617-4251-acb9-c5faf0b7fdf3\nexists skipping..\ncollecting  da6ce150-5daf-4a91-9fdd-a85854462b08\nexists skipping..\ncollecting  f6106ef5-e6fd-423b-9034-59bce18319da\nexists skipping..\ncollecting  de9c541b-ce5e-4cc6-9ddd-03f85dc5b3d5\nexists skipping..\ncollecting  d37ccc2e-7127-48ec-9425-2e77681c3635\nexists skipping..\ncollecting  c0568d62-49c7-4d9f-beba-ac0fb3e064c5\nexists skipping..\ncollecting  bfda850c-3027-4e91-afcb-cca5e73e4a03\nexists skipping..\ncollecting  f3332d55-ecc8-4644-9deb-180e42abb2eb\nexists skipping..\ncollecting  8c45801f-6377-42e1-ae0a-9b53593ff843\nexists skipping..\ncollecting  0a0ea690-5b73-4459-91d5-a6948d132a48\nexists skipping..\ncollecting  cfe58efd-ce2a-495a-90cd-6826f704ebee\nexists skipping..\ncollecting  003fdfbd-c766-4312-b029-bd4cfba6ebef\nexists skipping..\ncollecting  02c3ec4a-8de4-4284-9ec1-5a942d3d098e\nexists skipping..\ncollecting  ea185683-4427-44c3-84e1-706cf16781ce\nexists skipping..\ncollecting  b5d7b6b8-4e5d-4b5e-8976-c72e99f57769\nexists skipping..\ncollecting  cdfc27f0-b990-45f7-bac6-7c674cd157ac\nexists skipping..\ncollecting  af0463d4-f20f-4d13-bd0f-5834e2e8717b\nexists skipping..\ncollecting  333458b2-c1a9-47a3-8ae0-92053ad28ae3\nexists skipping..\ncollecting  f6106ef5-e6fd-423b-9034-59bce18319da\nexists skipping..\ncollecting  5e252b65-58dd-421f-a0db-3d4669bfb235\nexists skipping..\ncollecting  875622b7-5253-43d2-8e0f-348767860eb9\nexists skipping..\ncollecting  c07ab5f6-14a9-4b0b-a9af-9f7db6e8c220\nexists skipping..\ncollecting  eeb0a123-9482-4946-ab3f-9e63541cb655\nexists skipping..\ncollecting  fe33672e-7ea7-4c5d-8639-96b2cc7edb0c\nexists skipping..\ncollecting  40c4f8cd-b0ca-4d37-b91e-b69e5dff7f9a\nexists skipping..\ncollecting  47e625fa-e2df-43ce-84dd-8ac21fdda75a\nexists skipping..\ncollecting  02c3ec4a-8de4-4284-9ec1-5a942d3d098e\nexists skipping..\ncollecting  692c41af-2210-4dd6-916d-c99e76807447\nexists skipping..\ncollecting  eeb0a123-9482-4946-ab3f-9e63541cb655\nexists skipping..\ncollecting  695bed09-0ad9-406e-b489-69408adeea06\nexists skipping..\ncollecting  2222b7b3-f48b-4cea-90bf-8e7245d002ea\nexists skipping..\ncollecting  f78ea076-10a1-45dc-a848-c08e129c6a28\nexists skipping..\ncollecting  02cf33c2-c8e2-48b9-bf72-92506e97e251\nexists skipping..\ncollecting  990e5974-9c60-4c9a-ba23-ddce13971178\nexists skipping..\ncollecting  d64197fc-0723-4c61-9ce8-ff2554e24154\nexists skipping..\ncollecting  36b98590-a7e6-4e00-8c7d-f0f3d25bafec\nexists skipping..\ncollecting  551e2612-8a22-4c44-8290-78dc0e4af85d\nexists skipping..\ncollecting  6d0ff6eb-0411-4863-b4e7-90958db98115\nexists skipping..\ncollecting  50d7ad3f-57f0-45e1-911d-b0efff9deb8f\nexists skipping..\ncollecting  f6106ef5-e6fd-423b-9034-59bce18319da\nexists skipping..\ncollecting  cfd2c7fc-c29a-4a32-a11d-d04fa2dd660d\nexists skipping..\ncollecting  491846d3-f81a-4777-b49f-0a0c74168395\nexists skipping..\ncollecting  f9f7132d-56a2-43e2-baba-312f34dbaeed\nexists skipping..\ncollecting  0c31f316-6718-4a43-a9f1-ed552e45bd0f\nexists skipping..\ncollecting  3789f7a5-5743-4005-844d-602dadb33030\nexists skipping..\ncollecting  6d0ff6eb-0411-4863-b4e7-90958db98115\nexists skipping..\ncollecting  f62e6b4d-7f9d-4139-bac4-59f084fb09cd\nexists skipping..\ncollecting  93b8483d-a510-42ff-865e-33d5a8784dc4\nexists skipping..\ncollecting  695c7749-a3b8-4158-bd14-59d1f2c3e736\nexists skipping..\ncollecting  dca30f20-582e-40ef-be6d-aa7858be4baa\nexists skipping..\ncollecting  f6106ef5-e6fd-423b-9034-59bce18319da\nexists skipping..\ncollecting  38793f95-324b-4f01-b1a7-45e1c9353bc1\nexists skipping..\ncollecting  4f13c5e6-14c0-44cf-a2b0-4ef9bb3704fd\nexists skipping..\ncollecting  8116acfb-8035-4d34-b9b9-b0af2c5697df\nexists skipping..\ncollecting  9c43edf0-541f-4dbb-9fe1-42cc83d453bd\nexists skipping..\ncollecting  c66f40ed-f72e-4012-991c-1f3726e5c8ad\nexists skipping..\ncollecting  2ca6a37f-67f5-4905-864b-ddf98d956ebb\nexists skipping..\ncollecting  b1936012-0d31-4b92-8d60-c24903b2e569\nexists skipping..\ncollecting  8116acfb-8035-4d34-b9b9-b0af2c5697df\nexists skipping..\ncollecting  a2588440-600e-41da-b2b9-1f5632ecdef6\nexists skipping..\ncollecting  e776d9b6-2180-4f50-90bf-77f7b920fc3b\nexists skipping..\ncollecting  bb65d7a1-a5d5-4c89-9ef9-f0f1db06cc58\nexists skipping..\ncollecting  0a820e12-033b-45d6-9ef9-d70f4c5e5b63\nexists skipping..\ncollecting  ad44deb7-e56d-47bd-8d64-7147493e0aee\nexists skipping..\ncollecting  551e2612-8a22-4c44-8290-78dc0e4af85d\nexists skipping..\ncollecting  8c45801f-6377-42e1-ae0a-9b53593ff843\nexists skipping..\ncollecting  5308a803-69e6-43cd-89db-66e93f9f83af\nexists skipping..\ncollecting  ab89875f-3b86-4c6a-8d66-767017570dfc\nexists skipping..\ncollecting  631ed3c9-7863-4e7c-86fa-4bfb043f2851\nexists skipping..\ncollecting  3789f7a5-5743-4005-844d-602dadb33030\nexists skipping..\ncollecting  99a2d4a9-63a0-43a7-976d-2a1ed822186d\nexists skipping..\ncollecting  0aeaffd7-9089-49e7-85ad-2314f32cbf7c\nexists skipping..\ncollecting  692c41af-2210-4dd6-916d-c99e76807447\nexists skipping..\ncollecting  f3332d55-ecc8-4644-9deb-180e42abb2eb\nexists skipping..\ncollecting  10162c55-772d-49d2-8b1b-b1f9c86254b2\nexists skipping..\ncollecting  360f1bcc-aa60-4052-a18a-b33da5745ff4\nexists skipping..\ncollecting  360f1bcc-aa60-4052-a18a-b33da5745ff4\nexists skipping..\ncollecting  89a7b0ef-1ec8-490f-9207-c93aa57a147f\nexists skipping..\ncollecting  1135e377-22e6-4290-b4cd-e6739de7fd8a\nexists skipping..\ncollecting  0d9f0708-5e8d-4eb8-b946-6441ef955516\nexists skipping..\ncollecting  9e5bc091-13c7-46ec-8c17-8e315b7e535c\nexists skipping..\ncollecting  93b8483d-a510-42ff-865e-33d5a8784dc4\nexists skipping..\ncollecting  ad44deb7-e56d-47bd-8d64-7147493e0aee\nexists skipping..\ncollecting  e6d48180-814d-494b-99cc-0be5cd1a0eaf\nexists skipping..\ncollecting  360f1bcc-aa60-4052-a18a-b33da5745ff4\nexists skipping..\ncollecting  8e7f826f-8dc9-490a-9282-98d899a07cc7\nexists skipping..\ncollecting  02cf33c2-c8e2-48b9-bf72-92506e97e251\nexists skipping..\ncollecting  830bc2b9-592d-4334-842a-213ba4c0a347\nexists skipping..\ncollecting  9ea23099-dd30-4b26-9de7-5d42d5dae87b\nexists skipping..\ncollecting  2f5c1968-2c34-4539-a9f4-38298d0de925\nexists skipping..\ncollecting  eab40c22-0c15-4291-a6ce-e085a7f0f1e4\nexists skipping..\ncollecting  ab89875f-3b86-4c6a-8d66-767017570dfc\nexists skipping..\ncollecting  9c43edf0-541f-4dbb-9fe1-42cc83d453bd\nexists skipping..\ncollecting  9c43edf0-541f-4dbb-9fe1-42cc83d453bd\nexists skipping..\ncollecting  990e5974-9c60-4c9a-ba23-ddce13971178\nexists skipping..\ncollecting  b1936012-0d31-4b92-8d60-c24903b2e569\nexists skipping..\ncollecting  e13f9c1b-dca0-4c63-a64c-76f6bc725156\nexists skipping..\ncollecting  af0463d4-f20f-4d13-bd0f-5834e2e8717b\nexists skipping..\ncollecting  c0e85162-6ff4-401b-b01e-cc6d7a51eac0\nexists skipping..\ncollecting  e467a17f-a729-4938-87a1-ac25157eed63\nexists skipping..\ncollecting  4f13c5e6-14c0-44cf-a2b0-4ef9bb3704fd\nexists skipping..\ncollecting  7f215a89-2a17-42f0-a2fb-f18fbc888cef\nexists skipping..\ncollecting  a5366d95-7b9d-4b1b-a16f-99e56fab08f5\nexists skipping..\ncollecting  7a266524-6e76-4d06-963f-6f977e356574\nexists skipping..\ncollecting  fde3221a-9ce3-45a9-857f-bd196b07aa05\nexists skipping..\ncollecting  2f266b81-aad3-4c26-ac69-1bd04a208bf7\nexists skipping..\ncollecting  cdb446bc-e801-404f-9911-9ba5c687f6af\nexists skipping..\ncollecting  0a0ea690-5b73-4459-91d5-a6948d132a48\nexists skipping..\ncollecting  10162c55-772d-49d2-8b1b-b1f9c86254b2\nexists skipping..\ncollecting  9448e70e-32ff-4c47-b6e7-ccb1df91743b\nexists skipping..\ncollecting  47e625fa-e2df-43ce-84dd-8ac21fdda75a\nexists skipping..\ncollecting  da6ce150-5daf-4a91-9fdd-a85854462b08\nexists skipping..\ncollecting  e776d9b6-2180-4f50-90bf-77f7b920fc3b\nexists skipping..\ncollecting  ab89875f-3b86-4c6a-8d66-767017570dfc\nexists skipping..\ncollecting  f78ea076-10a1-45dc-a848-c08e129c6a28\nexists skipping..\ncollecting  2f5c1968-2c34-4539-a9f4-38298d0de925\nexists skipping..\ncollecting  f78ea076-10a1-45dc-a848-c08e129c6a28\nexists skipping..\ncollecting  cde149fe-708b-4a35-bea8-959eb9da4e0b\nexists skipping..\ncollecting  064d7f3e-8bbd-49cd-b360-5c4590a19b9e\nexists skipping..\ncollecting  cde149fe-708b-4a35-bea8-959eb9da4e0b\nexists skipping..\ncollecting  e6d48180-814d-494b-99cc-0be5cd1a0eaf\nexists skipping..\n",
  "history_begin_time" : 1645392687475,
  "history_end_time" : 1645392690938,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "qAoyH0FEIe2S",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n\n      viirs = ee.ImageCollection(product_name) \\\n          \t.filterDate('2013-01-01','2021-12-31') \\\n            .filterBounds(poi) \\\n          \t.filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')) \\\n      \t\t.select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "/Users/joe\ncollecting  76b55900-eb3d-4d25-a538-f74302ffe72d\nexists skipping..\ncollecting  f191fe19-0e81-4bc9-9980-29738a05a49b\nexists skipping..\ncollecting  f6106ef5-e6fd-423b-9034-59bce18319da\nexists skipping..\ncollecting  0a54de9c-d804-4681-9f7f-9f770a0f6d2e\nexists skipping..\ncollecting  4f383fb2-6cc7-48a8-9bdb-9c5d150e6eae\nexists skipping..\ncollecting  7cf8af73-1abf-40ad-9788-0d757201eeb0\nexists skipping..\ncollecting  30641173-db10-4320-ab1e-c46e765a9011\nexists skipping..\ncollecting  30ab5128-9a8f-4446-b781-faf8bafb677f\nexists skipping..\ncollecting  df01bf44-46b8-4541-b0a4-ed1fae16ac38\nexists skipping..\ncollecting  6dd37e24-0a9c-4749-8ab6-7e26d42925d6\nexists skipping..\ncollecting  018cf1a1-f945-4097-9c47-0c4690538bb5\nexists skipping..\ncollecting  962f6718-ce02-4d13-b28c-e159d1adc2d4\nexists skipping..\ncollecting  c89dc6ca-6d69-41ce-954d-b51f64aaacb1\nexists skipping..\ncollecting  4bb8fe22-653c-4611-a3d8-de5b2c62d13d\nexists skipping..\ncollecting  d674ee8e-49f1-44c9-890d-4e04997522a1\nexists skipping..\ncollecting  65565709-caca-4ed5-a8b6-2794da371708\nexists skipping..\ncollecting  c89dc6ca-6d69-41ce-954d-b51f64aaacb1\nexists skipping..\ncollecting  76b55900-eb3d-4d25-a538-f74302ffe72d\nexists skipping..\ncollecting  f11515e9-f2a0-4f8c-9f2d-12b9e2dc8569\nexists skipping..\ncollecting  cc66f524-dd2b-4d3f-bf96-4941edca2879\nexists skipping..\ncollecting  09288a61-d120-4cee-ac46-5a275a8f005c\nexists skipping..\ncollecting  51ebe834-adf4-474e-871e-28ebca2bd0cc\nexists skipping..\ncollecting  4f383fb2-6cc7-48a8-9bdb-9c5d150e6eae\nexists skipping..\ncollecting  4f383fb2-6cc7-48a8-9bdb-9c5d150e6eae\nexists skipping..\ncollecting  76b55900-eb3d-4d25-a538-f74302ffe72d\nexists skipping..\ncollecting  c89dc6ca-6d69-41ce-954d-b51f64aaacb1\nexists skipping..\ncollecting  70bfdc00-dbd2-4c44-8039-04a547f91f76\nexists skipping..\ncollecting  01be2cc7-ef77-4e4d-80ed-c4f8139162c3\nexists skipping..\ncollecting  9023330c-2766-4585-b6fe-63593c519e03\nexists skipping..\ncollecting  76b55900-eb3d-4d25-a538-f74302ffe72d\nexists skipping..\ncollecting  962f6718-ce02-4d13-b28c-e159d1adc2d4\nexists skipping..\ncollecting  f6106ef5-e6fd-423b-9034-59bce18319da\nexists skipping..\ncollecting  c89dc6ca-6d69-41ce-954d-b51f64aaacb1\nexists skipping..\ncollecting  d674ee8e-49f1-44c9-890d-4e04997522a1\nexists skipping..\ncollecting  f6106ef5-e6fd-423b-9034-59bce18319da\nexists skipping..\ncollecting  ddc760c7-dc6e-4fd4-ac1a-987ba3f79748\nexists skipping..\ncollecting  690ae8d4-c0d0-4dad-a7c4-67f3df07cc78\nexists skipping..\ncollecting  dbf421d4-0295-4a9f-9e20-88ac299360b1\nexists skipping..\ncollecting  51ebe834-adf4-474e-871e-28ebca2bd0cc\nexists skipping..\ncollecting  5ec8a57d-8d5f-4331-b1fb-9d766f42991a\nexists skipping..\ncollecting  403090bc-fc9e-44fb-921b-f7eea63e9740\nexists skipping..\ncollecting  232ef8b4-938f-42d7-a6e4-647d5280edd2\nexists skipping..\ncollecting  cc8b7ef5-1c86-4bd2-8cb9-969c7df1884e\nexists skipping..\ncollecting  018cf1a1-f945-4097-9c47-0c4690538bb5\nexists skipping..\ncollecting  d674ee8e-49f1-44c9-890d-4e04997522a1\nexists skipping..\ncollecting  65565709-caca-4ed5-a8b6-2794da371708\nexists skipping..\ncollecting  df01bf44-46b8-4541-b0a4-ed1fae16ac38\nexists skipping..\ncollecting  39dd8dce-b4a1-4db5-bc31-fba72181cf5e\nexists skipping..\ncollecting  d674ee8e-49f1-44c9-890d-4e04997522a1\nexists skipping..\ncollecting  df01bf44-46b8-4541-b0a4-ed1fae16ac38\nexists skipping..\ncollecting  49b01e43-f719-450f-b7c6-556b08e9ef4d\nexists skipping..\ncollecting  d674ee8e-49f1-44c9-890d-4e04997522a1\nexists skipping..\ncollecting  51ebe834-adf4-474e-871e-28ebca2bd0cc\nexists skipping..\ncollecting  018cf1a1-f945-4097-9c47-0c4690538bb5\nexists skipping..\ncollecting  018cf1a1-f945-4097-9c47-0c4690538bb5\nexists skipping..\ncollecting  018cf1a1-f945-4097-9c47-0c4690538bb5\nexists skipping..\ncollecting  147d5eb4-e574-47e4-994a-8a2908c06050\nexists skipping..\ncollecting  74f8c8bc-2f60-4232-b447-43459d5d22f0\nexists skipping..\ncollecting  6dd37e24-0a9c-4749-8ab6-7e26d42925d6\nexists skipping..\ncollecting  01be2cc7-ef77-4e4d-80ed-c4f8139162c3\nexists skipping..\ncollecting  01be2cc7-ef77-4e4d-80ed-c4f8139162c3\nexists skipping..\ncollecting  018cf1a1-f945-4097-9c47-0c4690538bb5\nexists skipping..\ncollecting  00c4db22-a423-41a4-ada6-a8b1b04153a4\nexists skipping..\ncollecting  ec0952b6-f119-4f40-bf47-343d71245ddc\nexists skipping..\ncollecting  74f8c8bc-2f60-4232-b447-43459d5d22f0\nexists skipping..\ncollecting  d674ee8e-49f1-44c9-890d-4e04997522a1\nexists skipping..\ncollecting  d674ee8e-49f1-44c9-890d-4e04997522a1\nexists skipping..\ncollecting  b5c7343d-a4a9-4da9-aee3-36539a545af6\nexists skipping..\ncollecting  17da8ab4-6dd8-481e-a025-7574765ef9b1\nexists skipping..\ncollecting  65565709-caca-4ed5-a8b6-2794da371708\nexists skipping..\ncollecting  4f383fb2-6cc7-48a8-9bdb-9c5d150e6eae\nexists skipping..\ncollecting  74f8c8bc-2f60-4232-b447-43459d5d22f0\nexists skipping..\ncollecting  d563ff8c-31c3-44a9-8fd3-2f8bc68b21b4\nexists skipping..\ncollecting  51ebe834-adf4-474e-871e-28ebca2bd0cc\nexists skipping..\ncollecting  018cf1a1-f945-4097-9c47-0c4690538bb5\nexists skipping..\ncollecting  cbe04952-a2ae-4525-98c5-a644c9a5ddc5\nexists skipping..\ncollecting  f6106ef5-e6fd-423b-9034-59bce18319da\nexists skipping..\ncollecting  7cf8af73-1abf-40ad-9788-0d757201eeb0\nexists skipping..\ncollecting  147d5eb4-e574-47e4-994a-8a2908c06050\nexists skipping..\ncollecting  c89dc6ca-6d69-41ce-954d-b51f64aaacb1\nexists skipping..\ncollecting  7cf8af73-1abf-40ad-9788-0d757201eeb0\nexists skipping..\ncollecting  65565709-caca-4ed5-a8b6-2794da371708\nexists skipping..\ncollecting  74f8c8bc-2f60-4232-b447-43459d5d22f0\nexists skipping..\ncollecting  7cf8af73-1abf-40ad-9788-0d757201eeb0\nexists skipping..\ncollecting  c89dc6ca-6d69-41ce-954d-b51f64aaacb1\nexists skipping..\ncollecting  962f6718-ce02-4d13-b28c-e159d1adc2d4\nexists skipping..\ncollecting  65565709-caca-4ed5-a8b6-2794da371708\nexists skipping..\ncollecting  01be2cc7-ef77-4e4d-80ed-c4f8139162c3\nexists skipping..\ncollecting  962f6718-ce02-4d13-b28c-e159d1adc2d4\nexists skipping..\ncollecting  f6106ef5-e6fd-423b-9034-59bce18319da\nexists skipping..\ncollecting  147d5eb4-e574-47e4-994a-8a2908c06050\nexists skipping..\ncollecting  6e96bf06-cbc5-45b5-a36b-e37864226099\nexists skipping..\ncollecting  f6106ef5-e6fd-423b-9034-59bce18319da\nexists skipping..\ncollecting  f6106ef5-e6fd-423b-9034-59bce18319da\nexists skipping..\ncollecting  c7e3f62c-a812-4342-8e4c-3a6a5dd96255\nexists skipping..\ncollecting  a8e91cfa-724a-4114-a9d4-291785ff31f8\nexists skipping..\ncollecting  2dde4be2-b6fd-47e8-b53d-88b59d74fde1\nexists skipping..\ncollecting  b2e9cb6b-b45a-4cab-8333-247cb4c0b51b\nexists skipping..\ncollecting  46f21569-8ecf-4c46-b65b-d80fa83a20d5\nexists skipping..\ncollecting  643c05b6-03bc-4024-8000-2228f4b5a7ad\nexists skipping..\ncollecting  fb078c7e-4975-4c7f-8f42-180386ac8c3c\nexists skipping..\ncollecting  51ebe834-adf4-474e-871e-28ebca2bd0cc\nexists skipping..\ncollecting  f6106ef5-e6fd-423b-9034-59bce18319da\nexists skipping..\ncollecting  dba335b6-9d97-4a89-9ff3-888a8a45575f\nexists skipping..\ncollecting  057fb61e-ce45-4423-9ef2-b52d8c1237e9\nexists skipping..\ncollecting  50f7b567-4066-4437-a335-71aff4c94a2c\nexists skipping..\ncollecting  5e252b65-58dd-421f-a0db-3d4669bfb235\nexists skipping..\ncollecting  efada0af-09bf-4013-a1c6-0837f8ff59c5\nexists skipping..\ncollecting  517aefce-a617-4251-acb9-c5faf0b7fdf3\nexists skipping..\ncollecting  0a0ea690-5b73-4459-91d5-a6948d132a48\nexists skipping..\ncollecting  e6d48180-814d-494b-99cc-0be5cd1a0eaf\nexists skipping..\ncollecting  cdfc27f0-b990-45f7-bac6-7c674cd157ac\nexists skipping..\ncollecting  2222b7b3-f48b-4cea-90bf-8e7245d002ea\nexists skipping..\ncollecting  cad51334-b3af-4c23-85c3-451c3447560a\nexists skipping..\ncollecting  8116acfb-8035-4d34-b9b9-b0af2c5697df\nexists skipping..\ncollecting  c66f40ed-f72e-4012-991c-1f3726e5c8ad\nexists skipping..\ncollecting  6afdc499-9686-4451-b207-13df777df662\nexists skipping..\ncollecting  02cf33c2-c8e2-48b9-bf72-92506e97e251\nexists skipping..\ncollecting  8c45801f-6377-42e1-ae0a-9b53593ff843\nexists skipping..\ncollecting  9f0599d8-81f3-4ab5-b275-48a6ddaaae5b\nexists skipping..\ncollecting  86257c69-a8f1-43b1-9e07-73129e2c3fbc\nexists skipping..\ncollecting  43be1328-02b0-4cc1-8e9b-75842908cee3\nexists skipping..\ncollecting  eeb0a123-9482-4946-ab3f-9e63541cb655\nexists skipping..\ncollecting  f62e6b4d-7f9d-4139-bac4-59f084fb09cd\nexists skipping..\ncollecting  c59f438c-f00a-476a-938e-efd828e0d083\nexists skipping..\ncollecting  7acd0d51-ff30-42a3-9338-590432bd0e43\nexists skipping..\ncollecting  3b5bfd37-070c-4ee9-a470-c9338851e270\nexists skipping..\ncollecting  3b5bfd37-070c-4ee9-a470-c9338851e270\nexists skipping..\ncollecting  43be1328-02b0-4cc1-8e9b-75842908cee3\nexists skipping..\ncollecting  d674ee8e-49f1-44c9-890d-4e04997522a1\nexists skipping..\ncollecting  c89dc6ca-6d69-41ce-954d-b51f64aaacb1\nexists skipping..\ncollecting  74f8c8bc-2f60-4232-b447-43459d5d22f0\nexists skipping..\ncollecting  2f5c1968-2c34-4539-a9f4-38298d0de925\nexists skipping..\ncollecting  10162c55-772d-49d2-8b1b-b1f9c86254b2\nexists skipping..\ncollecting  c340219b-307b-412b-9368-b50639bd372d\nexists skipping..\ncollecting  02cf33c2-c8e2-48b9-bf72-92506e97e251\nexists skipping..\ncollecting  24cd85fa-6aee-4556-bb8a-b6696eb72a19\nexists skipping..\ncollecting  24cd85fa-6aee-4556-bb8a-b6696eb72a19\nexists skipping..\ncollecting  c89dc6ca-6d69-41ce-954d-b51f64aaacb1\nexists skipping..\ncollecting  bfda850c-3027-4e91-afcb-cca5e73e4a03\nexists skipping..\ncollecting  5e252b65-58dd-421f-a0db-3d4669bfb235\nexists skipping..\ncollecting  f78ea076-10a1-45dc-a848-c08e129c6a28\nexists skipping..\ncollecting  ce76ce00-c8b5-4597-8ca3-1ec9db795b50\nexists skipping..\ncollecting  a6861fc3-2315-451b-9b95-c06d1ea96b4b\nexists skipping..\ncollecting  9474e816-b673-4e6d-83e0-28c274945bef\nexists skipping..\ncollecting  2222b7b3-f48b-4cea-90bf-8e7245d002ea\nexists skipping..\ncollecting  ad44deb7-e56d-47bd-8d64-7147493e0aee\nexists skipping..\ncollecting  b99b0ffd-6fa9-482c-8511-f7b87e705d35\nexists skipping..\ncollecting  e833aad1-6da3-4413-b25e-b2ab5b2029c0\nexists skipping..\ncollecting  cdfc27f0-b990-45f7-bac6-7c674cd157ac\nexists skipping..\ncollecting  f46e7d90-a754-44a8-b262-63f5c401a0ab\nexists skipping..\ncollecting  0f46ad2b-4b1f-4232-8e46-be7122d53b86\nexists skipping..\ncollecting  cdfc27f0-b990-45f7-bac6-7c674cd157ac\nexists skipping..\ncollecting  8ca1aaab-07de-4532-a99f-4ab8bce2f862\nexists skipping..\ncollecting  8ca1aaab-07de-4532-a99f-4ab8bce2f862\nexists skipping..\ncollecting  2222b7b3-f48b-4cea-90bf-8e7245d002ea\nexists skipping..\ncollecting  2222b7b3-f48b-4cea-90bf-8e7245d002ea\nexists skipping..\ncollecting  2222b7b3-f48b-4cea-90bf-8e7245d002ea\nexists skipping..\ncollecting  8116acfb-8035-4d34-b9b9-b0af2c5697df\nexists skipping..\ncollecting  f62e6b4d-7f9d-4139-bac4-59f084fb09cd\nexists skipping..\ncollecting  c0e85162-6ff4-401b-b01e-cc6d7a51eac0\nexists skipping..\ncollecting  e4473542-1804-41c0-82b2-eaddc245845d\nexists skipping..\ncollecting  e4473542-1804-41c0-82b2-eaddc245845d\nexists skipping..\ncollecting  aa0d6340-c817-48c9-8727-8d3457606381\nexists skipping..\ncollecting  1135e377-22e6-4290-b4cd-e6739de7fd8a\nexists skipping..\ncollecting  f25cdbec-2f14-42c5-a6ef-a60f3a90caff\nexists skipping..\ncollecting  06ec1554-a0ea-41cf-85f8-43f4b48c7599\nexists skipping..\ncollecting  02c3ec4a-8de4-4284-9ec1-5a942d3d098e\nexists skipping..\ncollecting  c5a82752-3e4b-43ec-8011-9111b9bfcb89\nexists skipping..\ncollecting  679fe096-5475-4d4d-b0f8-81e32de889aa\nexists skipping..\ncollecting  990e5974-9c60-4c9a-ba23-ddce13971178\nexists skipping..\ncollecting  064d7f3e-8bbd-49cd-b360-5c4590a19b9e\nexists skipping..\ncollecting  875622b7-5253-43d2-8e0f-348767860eb9\nexists skipping..\ncollecting  eb1d889a-c427-49e1-95a1-fa6577002c9b\nexists skipping..\ncollecting  a2588440-600e-41da-b2b9-1f5632ecdef6\nexists skipping..\ncollecting  972ab3b1-7445-4f57-a1a1-c3be4c257869\nexists skipping..\ncollecting  09f879b9-4378-479e-949b-cdc3bec8f59f\nexists skipping..\ncollecting  e925f8e6-6eee-4fa7-9034-41eb9917df5e\nexists skipping..\ncollecting  d37ccc2e-7127-48ec-9425-2e77681c3635\nexists skipping..\ncollecting  ba4b2f3f-c8e3-4535-9781-426e4f77ba4c\nexists skipping..\ncollecting  38793f95-324b-4f01-b1a7-45e1c9353bc1\nexists skipping..\ncollecting  55d3e9a6-e153-43c3-a66c-cd60711ff4a9\nexists skipping..\ncollecting  ad44deb7-e56d-47bd-8d64-7147493e0aee\nexists skipping..\ncollecting  38793f95-324b-4f01-b1a7-45e1c9353bc1\nexists skipping..\ncollecting  38793f95-324b-4f01-b1a7-45e1c9353bc1\nexists skipping..\ncollecting  55d3e9a6-e153-43c3-a66c-cd60711ff4a9\nexists skipping..\ncollecting  38793f95-324b-4f01-b1a7-45e1c9353bc1\nexists skipping..\ncollecting  7b636fe2-1760-45c5-afce-505f2e927163\nexists skipping..\ncollecting  dc31c331-837b-4b59-b184-051321e9489c\nexists skipping..\ncollecting  12bde9ee-0e0a-49ac-ab19-b410adb61b3c\nexists skipping..\ncollecting  9f0599d8-81f3-4ab5-b275-48a6ddaaae5b\nexists skipping..\ncollecting  c0568d62-49c7-4d9f-beba-ac0fb3e064c5\nexists skipping..\ncollecting  a6861fc3-2315-451b-9b95-c06d1ea96b4b\nexists skipping..\ncollecting  a6861fc3-2315-451b-9b95-c06d1ea96b4b\nexists skipping..\ncollecting  e3473791-6153-49bc-a2ed-0b1e3e243942\nexists skipping..\ncollecting  e3473791-6153-49bc-a2ed-0b1e3e243942\nexists skipping..\ncollecting  e3473791-6153-49bc-a2ed-0b1e3e243942\nexists skipping..\ncollecting  47e625fa-e2df-43ce-84dd-8ac21fdda75a\nexists skipping..\ncollecting  674e34ce-8b77-422b-ab14-c6c3a0183e39\nexists skipping..\ncollecting  9813294e-a28e-45c0-976d-a6fa65d87927\nexists skipping..\ncollecting  548ff935-a421-4f4c-8eef-0bb19ed6c5f8\nexists skipping..\ncollecting  cad51334-b3af-4c23-85c3-451c3447560a\nexists skipping..\ncollecting  f9f7132d-56a2-43e2-baba-312f34dbaeed\nexists skipping..\ncollecting  a28a3caf-eea2-414f-8003-62ac82daaafa\nexists skipping..\ncollecting  f1f17cee-3fca-44bc-8974-b72d5f995a4a\nexists skipping..\ncollecting  14c19b34-6359-4d3f-865e-0b9852a0e958\nexists skipping..\ncollecting  55d3e9a6-e153-43c3-a66c-cd60711ff4a9\nexists skipping..\ncollecting  93b8483d-a510-42ff-865e-33d5a8784dc4\nexists skipping..\ncollecting  20b97bae-60d6-466d-aca9-334d9b2d63b6\nexists skipping..\ncollecting  0a820e12-033b-45d6-9ef9-d70f4c5e5b63\nexists skipping..\ncollecting  ad9f3d28-ef5a-4851-a5e4-5e2f7b63d17b\nexists skipping..\ncollecting  cfe58efd-ce2a-495a-90cd-6826f704ebee\nexists skipping..\ncollecting  9813294e-a28e-45c0-976d-a6fa65d87927\nexists skipping..\ncollecting  7bc3c413-4709-4ddd-a2ad-99f6cad9436c\nexists skipping..\ncollecting  ad9f3d28-ef5a-4851-a5e4-5e2f7b63d17b\nexists skipping..\ncollecting  ad9f3d28-ef5a-4851-a5e4-5e2f7b63d17b\nexists skipping..\ncollecting  9813294e-a28e-45c0-976d-a6fa65d87927\nexists skipping..\ncollecting  06ec1554-a0ea-41cf-85f8-43f4b48c7599\nexists skipping..\ncollecting  19b5e6ce-c1a0-4cce-85f5-248c9f1abb6e\nexists skipping..\ncollecting  d674ee8e-49f1-44c9-890d-4e04997522a1\nexists skipping..\ncollecting  a5080351-033f-4cfa-ad27-019fc84e052c\nexists skipping..\ncollecting  0efc68ba-5786-4c54-8028-e6f92efa6757\nexists skipping..\ncollecting  93b8483d-a510-42ff-865e-33d5a8784dc4\nexists skipping..\ncollecting  55d3e9a6-e153-43c3-a66c-cd60711ff4a9\nexists skipping..\ncollecting  ad44deb7-e56d-47bd-8d64-7147493e0aee\nexists skipping..\ncollecting  f9f7132d-56a2-43e2-baba-312f34dbaeed\nexists skipping..\ncollecting  8116acfb-8035-4d34-b9b9-b0af2c5697df\nexists skipping..\ncollecting  9c43edf0-541f-4dbb-9fe1-42cc83d453bd\nexists skipping..\ncollecting  c59f438c-f00a-476a-938e-efd828e0d083\nexists skipping..\ncollecting  2f266b81-aad3-4c26-ac69-1bd04a208bf7\nexists skipping..\ncollecting  76b55900-eb3d-4d25-a538-f74302ffe72d\nexists skipping..\ncollecting  dc31c331-837b-4b59-b184-051321e9489c\nexists skipping..\ncollecting  ad44deb7-e56d-47bd-8d64-7147493e0aee\nexists skipping..\ncollecting  875622b7-5253-43d2-8e0f-348767860eb9\nexists skipping..\ncollecting  cdfc27f0-b990-45f7-bac6-7c674cd157ac\nexists skipping..\ncollecting  ad44deb7-e56d-47bd-8d64-7147493e0aee\nexists skipping..\ncollecting  f6a782f0-4b17-4989-815c-2398b77b09dd\nexists skipping..\ncollecting  5308a803-69e6-43cd-89db-66e93f9f83af\nexists skipping..\ncollecting  147d5eb4-e574-47e4-994a-8a2908c06050\nexists skipping..\ncollecting  7b636fe2-1760-45c5-afce-505f2e927163\nexists skipping..\ncollecting  ba4b2f3f-c8e3-4535-9781-426e4f77ba4c\nexists skipping..\ncollecting  cacaa17b-0b1b-4fe2-a4c1-7728e6c154c1\nexists skipping..\ncollecting  e9759e79-461c-425e-af17-0a88be1a441f\nexists skipping..\ncollecting  0cda0c4a-405b-4e16-8922-964190929d80\nexists skipping..\ncollecting  76b55900-eb3d-4d25-a538-f74302ffe72d\nexists skipping..\ncollecting  c07ab5f6-14a9-4b0b-a9af-9f7db6e8c220\nexists skipping..\ncollecting  2ca6a37f-67f5-4905-864b-ddf98d956ebb\nexists skipping..\ncollecting  78ccacb3-4eb9-4d95-b244-f3a709e39fd1\nexists skipping..\ncollecting  cad51334-b3af-4c23-85c3-451c3447560a\nexists skipping..\ncollecting  36b98590-a7e6-4e00-8c7d-f0f3d25bafec\nexists skipping..\ncollecting  972ab3b1-7445-4f57-a1a1-c3be4c257869\nexists skipping..\ncollecting  0b9543d3-3cf9-4f28-b8eb-fd22c1956153\nexists skipping..\ncollecting  36b98590-a7e6-4e00-8c7d-f0f3d25bafec\nexists skipping..\ncollecting  4f13c5e6-14c0-44cf-a2b0-4ef9bb3704fd\nexists skipping..\ncollecting  674e34ce-8b77-422b-ab14-c6c3a0183e39\nexists skipping..\ncollecting  8116acfb-8035-4d34-b9b9-b0af2c5697df\nexists skipping..\ncollecting  c66f40ed-f72e-4012-991c-1f3726e5c8ad\nexists skipping..\ncollecting  af0463d4-f20f-4d13-bd0f-5834e2e8717b\nexists skipping..\ncollecting  5308a803-69e6-43cd-89db-66e93f9f83af\nexists skipping..\ncollecting  f9f7132d-56a2-43e2-baba-312f34dbaeed\nexists skipping..\ncollecting  c07ab5f6-14a9-4b0b-a9af-9f7db6e8c220\nexists skipping..\ncollecting  c5a82752-3e4b-43ec-8011-9111b9bfcb89\nexists skipping..\ncollecting  e776d9b6-2180-4f50-90bf-77f7b920fc3b\nexists skipping..\ncollecting  69d48a07-3007-4b3f-bec6-c097509a56d9\nexists skipping..\ncollecting  10a46ea0-13da-4cef-9aa6-ff48aa46881c\nexists skipping..\ncollecting  9813294e-a28e-45c0-976d-a6fa65d87927\nexists skipping..\ncollecting  7bc3c413-4709-4ddd-a2ad-99f6cad9436c\nexists skipping..\ncollecting  631ed3c9-7863-4e7c-86fa-4bfb043f2851\nexists skipping..\ncollecting  b59438b9-aadc-4899-9afb-fe71974c5c3a\nexists skipping..\ncollecting  b59438b9-aadc-4899-9afb-fe71974c5c3a\nexists skipping..\ncollecting  38793f95-324b-4f01-b1a7-45e1c9353bc1\nexists skipping..\ncollecting  cad51334-b3af-4c23-85c3-451c3447560a\nexists skipping..\ncollecting  03428fd9-01cc-4a57-ab6e-f4e8f265c094\nexists skipping..\ncollecting  f1f17cee-3fca-44bc-8974-b72d5f995a4a\nexists skipping..\ncollecting  c66f40ed-f72e-4012-991c-1f3726e5c8ad\nexists skipping..\ncollecting  7b636fe2-1760-45c5-afce-505f2e927163\nexists skipping..\ncollecting  d674ee8e-49f1-44c9-890d-4e04997522a1\nexists skipping..\ncollecting  dd7f64aa-3556-409b-bc86-71dc28b6fd45\nexists skipping..\ncollecting  990e5974-9c60-4c9a-ba23-ddce13971178\nexists skipping..\ncollecting  71f41513-6ac9-4d2e-97eb-6cd3b84f7043\nexists skipping..\ncollecting  d64197fc-0723-4c61-9ce8-ff2554e24154\nexists skipping..\ncollecting  89a7b0ef-1ec8-490f-9207-c93aa57a147f\nexists skipping..\ncollecting  b1936012-0d31-4b92-8d60-c24903b2e569\nexists skipping..\ncollecting  9813294e-a28e-45c0-976d-a6fa65d87927\nexists skipping..\ncollecting  4f13c5e6-14c0-44cf-a2b0-4ef9bb3704fd\nexists skipping..\ncollecting  333458b2-c1a9-47a3-8ae0-92053ad28ae3\nexists skipping..\ncollecting  ab89875f-3b86-4c6a-8d66-767017570dfc\nexists skipping..\ncollecting  6de38d5b-ccce-4ff2-90ed-1c7035491518\nexists skipping..\ncollecting  c89dc6ca-6d69-41ce-954d-b51f64aaacb1\nexists skipping..\ncollecting  6bc3e088-5139-43f2-9b2a-ade1cedeae47\nexists skipping..\ncollecting  517aefce-a617-4251-acb9-c5faf0b7fdf3\nexists skipping..\ncollecting  f46e7d90-a754-44a8-b262-63f5c401a0ab\nexists skipping..\ncollecting  7b636fe2-1760-45c5-afce-505f2e927163\nexists skipping..\ncollecting  e467a17f-a729-4938-87a1-ac25157eed63\nexists skipping..\ncollecting  eeb0a123-9482-4946-ab3f-9e63541cb655\nexists skipping..\ncollecting  a28a3caf-eea2-414f-8003-62ac82daaafa\nexists skipping..\ncollecting  c66f40ed-f72e-4012-991c-1f3726e5c8ad\nexists skipping..\ncollecting  42a21eb9-10fd-4986-825b-9ea55ce13935\nexists skipping..\ncollecting  bb65d7a1-a5d5-4c89-9ef9-f0f1db06cc58\nexists skipping..\ncollecting  c59f438c-f00a-476a-938e-efd828e0d083\nexists skipping..\ncollecting  6bc3e088-5139-43f2-9b2a-ade1cedeae47\nexists skipping..\ncollecting  692c41af-2210-4dd6-916d-c99e76807447\nexists skipping..\ncollecting  6662f7d0-4afc-4fed-b930-e0408ee10bc7\nexists skipping..\ncollecting  4f13c5e6-14c0-44cf-a2b0-4ef9bb3704fd\nexists skipping..\ncollecting  b1936012-0d31-4b92-8d60-c24903b2e569\nexists skipping..\ncollecting  fb32a838-cf3b-47a2-9e22-395a730f4f4f\nexists skipping..\ncollecting  fb32a838-cf3b-47a2-9e22-395a730f4f4f\nexists skipping..\ncollecting  ea185683-4427-44c3-84e1-706cf16781ce\nexists skipping..\ncollecting  ab89875f-3b86-4c6a-8d66-767017570dfc\nexists skipping..\ncollecting  55d3e9a6-e153-43c3-a66c-cd60711ff4a9\nexists skipping..\ncollecting  064d7f3e-8bbd-49cd-b360-5c4590a19b9e\nexists skipping..\ncollecting  064d7f3e-8bbd-49cd-b360-5c4590a19b9e\nexists skipping..\ncollecting  50d7ad3f-57f0-45e1-911d-b0efff9deb8f\nexists skipping..\ncollecting  8edd6091-10fa-4617-8dc8-e0ce1d5b84f7\nexists skipping..\ncollecting  0a820e12-033b-45d6-9ef9-d70f4c5e5b63\nexists skipping..\ncollecting  8edd6091-10fa-4617-8dc8-e0ce1d5b84f7\nexists skipping..\ncollecting  02c3ec4a-8de4-4284-9ec1-5a942d3d098e\nexists skipping..\ncollecting  05938de0-622b-4e0a-a82b-2a128e5be0b0\nexists skipping..\ncollecting  71f41513-6ac9-4d2e-97eb-6cd3b84f7043\nexists skipping..\ncollecting  e776d9b6-2180-4f50-90bf-77f7b920fc3b\nexists skipping..\ncollecting  a4339b9a-871e-44c2-9bb4-bcbfe9d590d7\nexists skipping..\ncollecting  4f13c5e6-14c0-44cf-a2b0-4ef9bb3704fd\nexists skipping..\ncollecting  440d7558-67fd-43b4-826b-26d02663f871\nexists skipping..\ncollecting  f9f7132d-56a2-43e2-baba-312f34dbaeed\nexists skipping..\ncollecting  99a2d4a9-63a0-43a7-976d-2a1ed822186d\nexists skipping..\ncollecting  99a2d4a9-63a0-43a7-976d-2a1ed822186d\nexists skipping..\ncollecting  be57eab6-a495-427f-8a36-9d118c03e7d8\nexists skipping..\ncollecting  1135e377-22e6-4290-b4cd-e6739de7fd8a\nexists skipping..\ncollecting  a5080351-033f-4cfa-ad27-019fc84e052c\nexists skipping..\ncollecting  9474e816-b673-4e6d-83e0-28c274945bef\nexists skipping..\ncollecting  df7e906a-07f3-4a46-b9a5-0200427c26f7\nexists skipping..\ncollecting  360f1bcc-aa60-4052-a18a-b33da5745ff4\nexists skipping..\ncollecting  e27143af-fdc0-4f6f-8a28-f57b78da75dc\nexists skipping..\ncollecting  36b98590-a7e6-4e00-8c7d-f0f3d25bafec\nexists skipping..\ncollecting  10a46ea0-13da-4cef-9aa6-ff48aa46881c\nexists skipping..\ncollecting  02cf33c2-c8e2-48b9-bf72-92506e97e251\nexists skipping..\ncollecting  51ebe834-adf4-474e-871e-28ebca2bd0cc\nexists skipping..\ncollecting  2ca6a37f-67f5-4905-864b-ddf98d956ebb\nexists skipping..\ncollecting  0623939d-b33f-41cb-ade2-3c4a776de49a\nexists skipping..\ncollecting  cfe58efd-ce2a-495a-90cd-6826f704ebee\nexists skipping..\ncollecting  4f13c5e6-14c0-44cf-a2b0-4ef9bb3704fd\nexists skipping..\ncollecting  a6861fc3-2315-451b-9b95-c06d1ea96b4b\nexists skipping..\ncollecting  cacaa17b-0b1b-4fe2-a4c1-7728e6c154c1\nexists skipping..\ncollecting  517aefce-a617-4251-acb9-c5faf0b7fdf3\nexists skipping..\ncollecting  9f0599d8-81f3-4ab5-b275-48a6ddaaae5b\nexists skipping..\ncollecting  36b98590-a7e6-4e00-8c7d-f0f3d25bafec\nexists skipping..\ncollecting  9813294e-a28e-45c0-976d-a6fa65d87927\nexists skipping..\ncollecting  05938de0-622b-4e0a-a82b-2a128e5be0b0\nexists skipping..\ncollecting  8116acfb-8035-4d34-b9b9-b0af2c5697df\nexists skipping..\ncollecting  695c7749-a3b8-4158-bd14-59d1f2c3e736\nexists skipping..\ncollecting  02c3ec4a-8de4-4284-9ec1-5a942d3d098e\nexists skipping..\ncollecting  ad44deb7-e56d-47bd-8d64-7147493e0aee\nexists skipping..\ncollecting  b59438b9-aadc-4899-9afb-fe71974c5c3a\nexists skipping..\ncollecting  02cf33c2-c8e2-48b9-bf72-92506e97e251\nexists skipping..\ncollecting  dca30f20-582e-40ef-be6d-aa7858be4baa\nexists skipping..\ncollecting  695bed09-0ad9-406e-b489-69408adeea06\nexists skipping..\ncollecting  962f6718-ce02-4d13-b28c-e159d1adc2d4\nexists skipping..\ncollecting  f6106ef5-e6fd-423b-9034-59bce18319da\nexists skipping..\ncollecting  631ed3c9-7863-4e7c-86fa-4bfb043f2851\nexists skipping..\ncollecting  d10a90c7-3db0-43c6-b04b-fe8b4c3f206e\nexists skipping..\ncollecting  b1077b69-4b02-458e-8a4b-e68695ac534f\nexists skipping..\ncollecting  86257c69-a8f1-43b1-9e07-73129e2c3fbc\nexists skipping..\ncollecting  e27143af-fdc0-4f6f-8a28-f57b78da75dc\nexists skipping..\ncollecting  e776d9b6-2180-4f50-90bf-77f7b920fc3b\nexists skipping..\ncollecting  10162c55-772d-49d2-8b1b-b1f9c86254b2\nexists skipping..\ncollecting  9813294e-a28e-45c0-976d-a6fa65d87927\nexists skipping..\ncollecting  875622b7-5253-43d2-8e0f-348767860eb9\nexists skipping..\ncollecting  65894307-d4eb-4b2e-a0fa-bd83a102dc30\nexists skipping..\ncollecting  bfda850c-3027-4e91-afcb-cca5e73e4a03\nexists skipping..\ncollecting  f46e7d90-a754-44a8-b262-63f5c401a0ab\nexists skipping..\ncollecting  a28a3caf-eea2-414f-8003-62ac82daaafa\nexists skipping..\ncollecting  d37ccc2e-7127-48ec-9425-2e77681c3635\nexists skipping..\ncollecting  71f41513-6ac9-4d2e-97eb-6cd3b84f7043\nexists skipping..\ncollecting  6bf06917-011b-4029-8fbe-a8dfea3bc598\nexists skipping..\ncollecting  75ced1b1-1fc2-42d3-a4f8-44aa1978c8ef\nexists skipping..\ncollecting  1135e377-22e6-4290-b4cd-e6739de7fd8a\nexists skipping..\ncollecting  f3e36cea-5eb2-495a-87f4-947395f325b0\nexists skipping..\ncollecting  a2588440-600e-41da-b2b9-1f5632ecdef6\nexists skipping..\ncollecting  f3332d55-ecc8-4644-9deb-180e42abb2eb\nexists skipping..\ncollecting  695c7749-a3b8-4158-bd14-59d1f2c3e736\nexists skipping..\ncollecting  9c43edf0-541f-4dbb-9fe1-42cc83d453bd\nexists skipping..\ncollecting  6bf06917-011b-4029-8fbe-a8dfea3bc598\nexists skipping..\ncollecting  631ed3c9-7863-4e7c-86fa-4bfb043f2851\nexists skipping..\ncollecting  9813294e-a28e-45c0-976d-a6fa65d87927\nexists skipping..\ncollecting  695bed09-0ad9-406e-b489-69408adeea06\nexists skipping..\ncollecting  42a21eb9-10fd-4986-825b-9ea55ce13935\nexists skipping..\ncollecting  491846d3-f81a-4777-b49f-0a0c74168395\nexists skipping..\ncollecting  d37ccc2e-7127-48ec-9425-2e77681c3635\nexists skipping..\ncollecting  a5080351-033f-4cfa-ad27-019fc84e052c\nexists skipping..\ncollecting  552a5638-8fd2-46de-8569-5f5512102264\nexists skipping..\ncollecting  6d0ff6eb-0411-4863-b4e7-90958db98115\nexists skipping..\ncollecting  d674ee8e-49f1-44c9-890d-4e04997522a1\nexists skipping..\ncollecting  df7e906a-07f3-4a46-b9a5-0200427c26f7\nexists skipping..\ncollecting  0b9543d3-3cf9-4f28-b8eb-fd22c1956153\nexists skipping..\ncollecting  c5a82752-3e4b-43ec-8011-9111b9bfcb89\nexists skipping..\ncollecting  55d3e9a6-e153-43c3-a66c-cd60711ff4a9\nexists skipping..\ncollecting  0aeaffd7-9089-49e7-85ad-2314f32cbf7c\nexists skipping..\ncollecting  b1077b69-4b02-458e-8a4b-e68695ac534f\nexists skipping..\ncollecting  c0568d62-49c7-4d9f-beba-ac0fb3e064c5\nexists skipping..\ncollecting  50d7ad3f-57f0-45e1-911d-b0efff9deb8f\nexists skipping..\ncollecting  e27143af-fdc0-4f6f-8a28-f57b78da75dc\nexists skipping..\ncollecting  3330a979-98df-4a38-ac3f-0b45374f8e3d\nexists skipping..\ncollecting  990e5974-9c60-4c9a-ba23-ddce13971178\nexists skipping..\ncollecting  a6861fc3-2315-451b-9b95-c06d1ea96b4b\nexists skipping..\ncollecting  50d7ad3f-57f0-45e1-911d-b0efff9deb8f\nexists skipping..\ncollecting  fe33672e-7ea7-4c5d-8639-96b2cc7edb0c\nexists skipping..\ncollecting  440d7558-67fd-43b4-826b-26d02663f871\nexists skipping..\ncollecting  59ac7ee6-8fa8-4888-bb77-2be6781dddaf\nexists skipping..\ncollecting  674e34ce-8b77-422b-ab14-c6c3a0183e39\nexists skipping..\ncollecting  dc237027-8dae-4da7-91ec-501701ecd943\nexists skipping..\ncollecting  b5d7b6b8-4e5d-4b5e-8976-c72e99f57769\nexists skipping..\ncollecting  018cf1a1-f945-4097-9c47-0c4690538bb5\nexists skipping..\ncollecting  018cf1a1-f945-4097-9c47-0c4690538bb5\nexists skipping..\ncollecting  a0c947fb-f00e-4331-ad3a-402908e08b57\nexists skipping..\ncollecting  19b5e6ce-c1a0-4cce-85f5-248c9f1abb6e\nexists skipping..\ncollecting  875622b7-5253-43d2-8e0f-348767860eb9\nexists skipping..\ncollecting  875622b7-5253-43d2-8e0f-348767860eb9\nexists skipping..\ncollecting  36b98590-a7e6-4e00-8c7d-f0f3d25bafec\nexists skipping..\ncollecting  a6861fc3-2315-451b-9b95-c06d1ea96b4b\nexists skipping..\ncollecting  cdfc27f0-b990-45f7-bac6-7c674cd157ac\nexists skipping..\ncollecting  df7e906a-07f3-4a46-b9a5-0200427c26f7\nexists skipping..\ncollecting  695bed09-0ad9-406e-b489-69408adeea06\nexists skipping..\ncollecting  e833aad1-6da3-4413-b25e-b2ab5b2029c0\nexists skipping..\ncollecting  dd7f64aa-3556-409b-bc86-71dc28b6fd45\nexists skipping..\ncollecting  50d7ad3f-57f0-45e1-911d-b0efff9deb8f\nexists skipping..\ncollecting  692c41af-2210-4dd6-916d-c99e76807447\nexists skipping..\ncollecting  89a7b0ef-1ec8-490f-9207-c93aa57a147f\nexists skipping..\ncollecting  408b4482-ff63-4a1f-9cf9-ca820cd51b39\nexists skipping..\ncollecting  f9f7132d-56a2-43e2-baba-312f34dbaeed\nexists skipping..\ncollecting  8c45801f-6377-42e1-ae0a-9b53593ff843\nexists skipping..\ncollecting  c7f13d88-b4af-4484-9547-52197f778c08\nexists skipping..\ncollecting  10a46ea0-13da-4cef-9aa6-ff48aa46881c\nexists skipping..\ncollecting  42a21eb9-10fd-4986-825b-9ea55ce13935\nexists skipping..\ncollecting  a5080351-033f-4cfa-ad27-019fc84e052c\nexists skipping..\ncollecting  ab89875f-3b86-4c6a-8d66-767017570dfc\nexists skipping..\ncollecting  20b97bae-60d6-466d-aca9-334d9b2d63b6\nexists skipping..\ncollecting  01be2cc7-ef77-4e4d-80ed-c4f8139162c3\nexists skipping..\ncollecting  3330a979-98df-4a38-ac3f-0b45374f8e3d\nexists skipping..\ncollecting  491846d3-f81a-4777-b49f-0a0c74168395\nexists skipping..\ncollecting  064d7f3e-8bbd-49cd-b360-5c4590a19b9e\nexists skipping..\ncollecting  4ddee9a9-feaf-4daa-9100-0d4188f7b827\nexists skipping..\ncollecting  b59438b9-aadc-4899-9afb-fe71974c5c3a\nexists skipping..\ncollecting  24cd85fa-6aee-4556-bb8a-b6696eb72a19\nexists skipping..\ncollecting  0adbba56-85f8-49e0-9b11-000622238d91\nexists skipping..\ncollecting  74f8c8bc-2f60-4232-b447-43459d5d22f0\nexists skipping..\ncollecting  cfd2c7fc-c29a-4a32-a11d-d04fa2dd660d\nexists skipping..\ncollecting  57e18a9f-8327-4d6c-b2b4-c2b337341e86\nexists skipping..\ncollecting  e467a17f-a729-4938-87a1-ac25157eed63\nexists skipping..\ncollecting  cdfc27f0-b990-45f7-bac6-7c674cd157ac\nexists skipping..\ncollecting  24cd85fa-6aee-4556-bb8a-b6696eb72a19\nexists skipping..\ncollecting  55d3e9a6-e153-43c3-a66c-cd60711ff4a9\nexists skipping..\ncollecting  10162c55-772d-49d2-8b1b-b1f9c86254b2\nexists skipping..\ncollecting  695bed09-0ad9-406e-b489-69408adeea06\nexists skipping..\ncollecting  b5d7b6b8-4e5d-4b5e-8976-c72e99f57769\nexists skipping..\ncollecting  678f1920-0bc3-4687-af71-35d61030b1a0\nexists skipping..\ncollecting  4f13c5e6-14c0-44cf-a2b0-4ef9bb3704fd\nexists skipping..\ncollecting  e27143af-fdc0-4f6f-8a28-f57b78da75dc\nexists skipping..\ncollecting  47e625fa-e2df-43ce-84dd-8ac21fdda75a\nexists skipping..\ncollecting  02cf33c2-c8e2-48b9-bf72-92506e97e251\nexists skipping..\ncollecting  d17b55c5-7848-4b79-a735-983aec995c52\nexists skipping..\ncollecting  0a820e12-033b-45d6-9ef9-d70f4c5e5b63\nexists skipping..\ncollecting  d37ccc2e-7127-48ec-9425-2e77681c3635\nexists skipping..\ncollecting  a6861fc3-2315-451b-9b95-c06d1ea96b4b\nexists skipping..\ncollecting  d674ee8e-49f1-44c9-890d-4e04997522a1\nexists skipping..\ncollecting  692c41af-2210-4dd6-916d-c99e76807447\nexists skipping..\ncollecting  f6a782f0-4b17-4989-815c-2398b77b09dd\nexists skipping..\ncollecting  fe33672e-7ea7-4c5d-8639-96b2cc7edb0c\nexists skipping..\ncollecting  3330a979-98df-4a38-ac3f-0b45374f8e3d\nexists skipping..\ncollecting  7b636fe2-1760-45c5-afce-505f2e927163\nexists skipping..\ncollecting  87d6c782-c43b-473f-84da-d2a519d8f1fc\nexists skipping..\ncollecting  b5d7b6b8-4e5d-4b5e-8976-c72e99f57769\nexists skipping..\ncollecting  253c2443-b820-4c13-bf6d-ba7a5426f52d\nexists skipping..\ncollecting  55d3e9a6-e153-43c3-a66c-cd60711ff4a9\nexists skipping..\ncollecting  830bc2b9-592d-4334-842a-213ba4c0a347\nexists skipping..\ncollecting  eeb0a123-9482-4946-ab3f-9e63541cb655\nexists skipping..\ncollecting  5c4dff48-4afa-4922-949e-f64db583f392\nexists skipping..\ncollecting  74f8c8bc-2f60-4232-b447-43459d5d22f0\nexists skipping..\ncollecting  36b98590-a7e6-4e00-8c7d-f0f3d25bafec\nexists skipping..\ncollecting  c0e85162-6ff4-401b-b01e-cc6d7a51eac0\nexists skipping..\ncollecting  9474e816-b673-4e6d-83e0-28c274945bef\nexists skipping..\ncollecting  50d7ad3f-57f0-45e1-911d-b0efff9deb8f\nexists skipping..\ncollecting  dc31c331-837b-4b59-b184-051321e9489c\nexists skipping..\ncollecting  0d0b742e-c324-4140-8f62-746210d79080\nexists skipping..\ncollecting  89a7b0ef-1ec8-490f-9207-c93aa57a147f\nexists skipping..\ncollecting  c07ab5f6-14a9-4b0b-a9af-9f7db6e8c220\nexists skipping..\ncollecting  6c94136d-5040-4c09-b1fd-c02dbff210e6\nexists skipping..\ncollecting  dca30f20-582e-40ef-be6d-aa7858be4baa\nexists skipping..\ncollecting  cfd2c7fc-c29a-4a32-a11d-d04fa2dd660d\nexists skipping..\ncollecting  e13f9c1b-dca0-4c63-a64c-76f6bc725156\nexists skipping..\ncollecting  d674ee8e-49f1-44c9-890d-4e04997522a1\nexists skipping..\ncollecting  0cda0c4a-405b-4e16-8922-964190929d80\nexists skipping..\ncollecting  e13f9c1b-dca0-4c63-a64c-76f6bc725156\nexists skipping..\ncollecting  99a2d4a9-63a0-43a7-976d-2a1ed822186d\nexists skipping..\ncollecting  e833aad1-6da3-4413-b25e-b2ab5b2029c0\nexists skipping..\ncollecting  679fe096-5475-4d4d-b0f8-81e32de889aa\nexists skipping..\ncollecting  cfd2c7fc-c29a-4a32-a11d-d04fa2dd660d\nexists skipping..\ncollecting  f9f7132d-56a2-43e2-baba-312f34dbaeed\nexists skipping..\ncollecting  d37ccc2e-7127-48ec-9425-2e77681c3635\nexists skipping..\ncollecting  2ca6a37f-67f5-4905-864b-ddf98d956ebb\nexists skipping..\ncollecting  e13f9c1b-dca0-4c63-a64c-76f6bc725156\nexists skipping..\ncollecting  89a7b0ef-1ec8-490f-9207-c93aa57a147f\nexists skipping..\ncollecting  3527e00e-1aee-46ce-ad9d-8122cff4c202\nexists skipping..\ncollecting  f46e7d90-a754-44a8-b262-63f5c401a0ab\nexists skipping..\ncollecting  c64f2bf3-90f0-4a96-b3a8-9f8db46dce92\nexists skipping..\ncollecting  360f1bcc-aa60-4052-a18a-b33da5745ff4\nexists skipping..\ncollecting  8116acfb-8035-4d34-b9b9-b0af2c5697df\nexists skipping..\ncollecting  692c41af-2210-4dd6-916d-c99e76807447\nexists skipping..\ncollecting  6bf06917-011b-4029-8fbe-a8dfea3bc598\nexists skipping..\ncollecting  94d9d95f-32b2-470d-95f8-dbd843d6def3\nexists skipping..\ncollecting  47e625fa-e2df-43ce-84dd-8ac21fdda75a\nexists skipping..\ncollecting  35aecf7e-5f0b-4533-995c-3cb4165d44b5\nexists skipping..\ncollecting  e776d9b6-2180-4f50-90bf-77f7b920fc3b\nexists skipping..\ncollecting  eeb0a123-9482-4946-ab3f-9e63541cb655\nexists skipping..\ncollecting  0a820e12-033b-45d6-9ef9-d70f4c5e5b63\nexists skipping..\ncollecting  ce76ce00-c8b5-4597-8ca3-1ec9db795b50\nexists skipping..\ncollecting  517aefce-a617-4251-acb9-c5faf0b7fdf3\nexists skipping..\ncollecting  9813294e-a28e-45c0-976d-a6fa65d87927\nexists skipping..\ncollecting  dca30f20-582e-40ef-be6d-aa7858be4baa\nexists skipping..\ncollecting  7b636fe2-1760-45c5-afce-505f2e927163\nexists skipping..\ncollecting  f46e7d90-a754-44a8-b262-63f5c401a0ab\nexists skipping..\ncollecting  5308a803-69e6-43cd-89db-66e93f9f83af\nexists skipping..\ncollecting  47e625fa-e2df-43ce-84dd-8ac21fdda75a\nexists skipping..\ncollecting  630bae26-a6cc-4a36-bbe5-40dc15b38dea\nexists skipping..\ncollecting  bb65d7a1-a5d5-4c89-9ef9-f0f1db06cc58\nexists skipping..\ncollecting  0bd47ec1-0e3c-43bf-a491-534d06beb19f\nexists skipping..\ncollecting  0a0ea690-5b73-4459-91d5-a6948d132a48\nexists skipping..\ncollecting  6afdc499-9686-4451-b207-13df777df662\nexists skipping..\ncollecting  02cf33c2-c8e2-48b9-bf72-92506e97e251\nexists skipping..\ncollecting  ea185683-4427-44c3-84e1-706cf16781ce\nexists skipping..\ncollecting  b98777af-0c7c-44f7-9c03-85d6d412856c\nexists skipping..\ncollecting  7610b45e-5652-4604-ab5b-99344f71616b\nexists skipping..\ncollecting  ad9f3d28-ef5a-4851-a5e4-5e2f7b63d17b\nexists skipping..\ncollecting  e3473791-6153-49bc-a2ed-0b1e3e243942\nexists skipping..\ncollecting  d64197fc-0723-4c61-9ce8-ff2554e24154\nexists skipping..\ncollecting  9f0599d8-81f3-4ab5-b275-48a6ddaaae5b\nexists skipping..\ncollecting  a28a3caf-eea2-414f-8003-62ac82daaafa\nexists skipping..\ncollecting  93b8483d-a510-42ff-865e-33d5a8784dc4\nexists skipping..\ncollecting  f6106ef5-e6fd-423b-9034-59bce18319da\nexists skipping..\ncollecting  a6861fc3-2315-451b-9b95-c06d1ea96b4b\nexists skipping..\ncollecting  cacaa17b-0b1b-4fe2-a4c1-7728e6c154c1\nexists skipping..\ncollecting  dc31c331-837b-4b59-b184-051321e9489c\nexists skipping..\ncollecting  ea185683-4427-44c3-84e1-706cf16781ce\nexists skipping..\ncollecting  df7e906a-07f3-4a46-b9a5-0200427c26f7\nexists skipping..\ncollecting  3b5bfd37-070c-4ee9-a470-c9338851e270\nexists skipping..\ncollecting  8116acfb-8035-4d34-b9b9-b0af2c5697df\nexists skipping..\ncollecting  a6861fc3-2315-451b-9b95-c06d1ea96b4b\nexists skipping..\ncollecting  bfda850c-3027-4e91-afcb-cca5e73e4a03\nexists skipping..\ncollecting  cfd2c7fc-c29a-4a32-a11d-d04fa2dd660d\nexists skipping..\ncollecting  c07ab5f6-14a9-4b0b-a9af-9f7db6e8c220\nexists skipping..\ncollecting  0d0b742e-c324-4140-8f62-746210d79080\nexists skipping..\ncollecting  35eee1cd-f92a-4ba5-af03-fb5347490f41\nexists skipping..\ncollecting  6bf06917-011b-4029-8fbe-a8dfea3bc598\nexists skipping..\ncollecting  ad9f3d28-ef5a-4851-a5e4-5e2f7b63d17b\nexists skipping..\ncollecting  a6861fc3-2315-451b-9b95-c06d1ea96b4b\nexists skipping..\ncollecting  6afdc499-9686-4451-b207-13df777df662\nexists skipping..\ncollecting  5e252b65-58dd-421f-a0db-3d4669bfb235\nexists skipping..\ncollecting  5308a803-69e6-43cd-89db-66e93f9f83af\nexists skipping..\ncollecting  b1077b69-4b02-458e-8a4b-e68695ac534f\nexists skipping..\ncollecting  cdfc27f0-b990-45f7-bac6-7c674cd157ac\nexists skipping..\ncollecting  ce76ce00-c8b5-4597-8ca3-1ec9db795b50\nexists skipping..\ncollecting  02c3ec4a-8de4-4284-9ec1-5a942d3d098e\nexists skipping..\ncollecting  b1077b69-4b02-458e-8a4b-e68695ac534f\nexists skipping..\ncollecting  e467a17f-a729-4938-87a1-ac25157eed63\nexists skipping..\ncollecting  43be1328-02b0-4cc1-8e9b-75842908cee3\nexists skipping..\ncollecting  0a0ea690-5b73-4459-91d5-a6948d132a48\nexists skipping..\ncollecting  1135e377-22e6-4290-b4cd-e6739de7fd8a\nexists skipping..\ncollecting  6bf06917-011b-4029-8fbe-a8dfea3bc598\nexists skipping..\ncollecting  85f0acd8-4008-472d-bf40-e35e0e2934e4\nexists skipping..\ncollecting  7bc3c413-4709-4ddd-a2ad-99f6cad9436c\nexists skipping..\ncollecting  491846d3-f81a-4777-b49f-0a0c74168395\nexists skipping..\ncollecting  df7e906a-07f3-4a46-b9a5-0200427c26f7\nexists skipping..\ncollecting  a6a9febf-ea16-4223-83d4-8e459e2af85a\nexists skipping..\ncollecting  6bf06917-011b-4029-8fbe-a8dfea3bc598\nexists skipping..\ncollecting  01be2cc7-ef77-4e4d-80ed-c4f8139162c3\nexists skipping..\ncollecting  efada0af-09bf-4013-a1c6-0837f8ff59c5\nexists skipping..\ncollecting  cdfc27f0-b990-45f7-bac6-7c674cd157ac\nexists skipping..\ncollecting  962f6718-ce02-4d13-b28c-e159d1adc2d4\nexists skipping..\ncollecting  df7e906a-07f3-4a46-b9a5-0200427c26f7\nexists skipping..\ncollecting  ce9da6bf-cf6e-4edb-b579-5a0853b2ed17\nexists skipping..\ncollecting  517aefce-a617-4251-acb9-c5faf0b7fdf3\nexists skipping..\ncollecting  da6ce150-5daf-4a91-9fdd-a85854462b08\nexists skipping..\ncollecting  f6106ef5-e6fd-423b-9034-59bce18319da\nexists skipping..\ncollecting  de9c541b-ce5e-4cc6-9ddd-03f85dc5b3d5\nexists skipping..\ncollecting  d37ccc2e-7127-48ec-9425-2e77681c3635\nexists skipping..\ncollecting  c0568d62-49c7-4d9f-beba-ac0fb3e064c5\nexists skipping..\ncollecting  bfda850c-3027-4e91-afcb-cca5e73e4a03\nexists skipping..\ncollecting  f3332d55-ecc8-4644-9deb-180e42abb2eb\nexists skipping..\ncollecting  8c45801f-6377-42e1-ae0a-9b53593ff843\nexists skipping..\ncollecting  0a0ea690-5b73-4459-91d5-a6948d132a48\nexists skipping..\ncollecting  cfe58efd-ce2a-495a-90cd-6826f704ebee\nexists skipping..\ncollecting  003fdfbd-c766-4312-b029-bd4cfba6ebef\nexists skipping..\ncollecting  02c3ec4a-8de4-4284-9ec1-5a942d3d098e\nexists skipping..\ncollecting  ea185683-4427-44c3-84e1-706cf16781ce\nexists skipping..\ncollecting  b5d7b6b8-4e5d-4b5e-8976-c72e99f57769\nexists skipping..\ncollecting  cdfc27f0-b990-45f7-bac6-7c674cd157ac\nexists skipping..\ncollecting  af0463d4-f20f-4d13-bd0f-5834e2e8717b\nexists skipping..\ncollecting  333458b2-c1a9-47a3-8ae0-92053ad28ae3\nexists skipping..\ncollecting  f6106ef5-e6fd-423b-9034-59bce18319da\nexists skipping..\ncollecting  5e252b65-58dd-421f-a0db-3d4669bfb235\nexists skipping..\ncollecting  875622b7-5253-43d2-8e0f-348767860eb9\nexists skipping..\ncollecting  c07ab5f6-14a9-4b0b-a9af-9f7db6e8c220\nexists skipping..\ncollecting  eeb0a123-9482-4946-ab3f-9e63541cb655\nexists skipping..\ncollecting  fe33672e-7ea7-4c5d-8639-96b2cc7edb0c\nexists skipping..\ncollecting  40c4f8cd-b0ca-4d37-b91e-b69e5dff7f9a\nexists skipping..\ncollecting  47e625fa-e2df-43ce-84dd-8ac21fdda75a\nexists skipping..\ncollecting  02c3ec4a-8de4-4284-9ec1-5a942d3d098e\nexists skipping..\ncollecting  692c41af-2210-4dd6-916d-c99e76807447\nexists skipping..\ncollecting  eeb0a123-9482-4946-ab3f-9e63541cb655\nexists skipping..\ncollecting  695bed09-0ad9-406e-b489-69408adeea06\nexists skipping..\ncollecting  2222b7b3-f48b-4cea-90bf-8e7245d002ea\nexists skipping..\ncollecting  f78ea076-10a1-45dc-a848-c08e129c6a28\nexists skipping..\ncollecting  02cf33c2-c8e2-48b9-bf72-92506e97e251\nexists skipping..\ncollecting  990e5974-9c60-4c9a-ba23-ddce13971178\nexists skipping..\ncollecting  d64197fc-0723-4c61-9ce8-ff2554e24154\nexists skipping..\ncollecting  36b98590-a7e6-4e00-8c7d-f0f3d25bafec\nexists skipping..\ncollecting  551e2612-8a22-4c44-8290-78dc0e4af85d\nexists skipping..\ncollecting  6d0ff6eb-0411-4863-b4e7-90958db98115\nexists skipping..\ncollecting  50d7ad3f-57f0-45e1-911d-b0efff9deb8f\nexists skipping..\ncollecting  f6106ef5-e6fd-423b-9034-59bce18319da\nexists skipping..\ncollecting  cfd2c7fc-c29a-4a32-a11d-d04fa2dd660d\nexists skipping..\ncollecting  491846d3-f81a-4777-b49f-0a0c74168395\nexists skipping..\ncollecting  f9f7132d-56a2-43e2-baba-312f34dbaeed\nexists skipping..\ncollecting  0c31f316-6718-4a43-a9f1-ed552e45bd0f\nexists skipping..\ncollecting  3789f7a5-5743-4005-844d-602dadb33030\nexists skipping..\ncollecting  6d0ff6eb-0411-4863-b4e7-90958db98115\nexists skipping..\ncollecting  f62e6b4d-7f9d-4139-bac4-59f084fb09cd\nexists skipping..\ncollecting  93b8483d-a510-42ff-865e-33d5a8784dc4\nexists skipping..\ncollecting  695c7749-a3b8-4158-bd14-59d1f2c3e736\nexists skipping..\ncollecting  dca30f20-582e-40ef-be6d-aa7858be4baa\nexists skipping..\ncollecting  f6106ef5-e6fd-423b-9034-59bce18319da\nexists skipping..\ncollecting  38793f95-324b-4f01-b1a7-45e1c9353bc1\nexists skipping..\ncollecting  4f13c5e6-14c0-44cf-a2b0-4ef9bb3704fd\nexists skipping..\ncollecting  8116acfb-8035-4d34-b9b9-b0af2c5697df\nexists skipping..\ncollecting  9c43edf0-541f-4dbb-9fe1-42cc83d453bd\nexists skipping..\ncollecting  c66f40ed-f72e-4012-991c-1f3726e5c8ad\nexists skipping..\ncollecting  2ca6a37f-67f5-4905-864b-ddf98d956ebb\nexists skipping..\ncollecting  b1936012-0d31-4b92-8d60-c24903b2e569\nexists skipping..\ncollecting  8116acfb-8035-4d34-b9b9-b0af2c5697df\nexists skipping..\ncollecting  a2588440-600e-41da-b2b9-1f5632ecdef6\nexists skipping..\ncollecting  e776d9b6-2180-4f50-90bf-77f7b920fc3b\nexists skipping..\ncollecting  bb65d7a1-a5d5-4c89-9ef9-f0f1db06cc58\nexists skipping..\ncollecting  0a820e12-033b-45d6-9ef9-d70f4c5e5b63\nexists skipping..\ncollecting  ad44deb7-e56d-47bd-8d64-7147493e0aee\nexists skipping..\ncollecting  551e2612-8a22-4c44-8290-78dc0e4af85d\nexists skipping..\ncollecting  8c45801f-6377-42e1-ae0a-9b53593ff843\nexists skipping..\ncollecting  5308a803-69e6-43cd-89db-66e93f9f83af\nexists skipping..\ncollecting  ab89875f-3b86-4c6a-8d66-767017570dfc\nexists skipping..\ncollecting  631ed3c9-7863-4e7c-86fa-4bfb043f2851\nexists skipping..\ncollecting  3789f7a5-5743-4005-844d-602dadb33030\nexists skipping..\ncollecting  99a2d4a9-63a0-43a7-976d-2a1ed822186d\nexists skipping..\ncollecting  0aeaffd7-9089-49e7-85ad-2314f32cbf7c\nexists skipping..\ncollecting  692c41af-2210-4dd6-916d-c99e76807447\nexists skipping..\ncollecting  f3332d55-ecc8-4644-9deb-180e42abb2eb\nexists skipping..\ncollecting  10162c55-772d-49d2-8b1b-b1f9c86254b2\nexists skipping..\ncollecting  360f1bcc-aa60-4052-a18a-b33da5745ff4\nexists skipping..\ncollecting  360f1bcc-aa60-4052-a18a-b33da5745ff4\nexists skipping..\ncollecting  89a7b0ef-1ec8-490f-9207-c93aa57a147f\nexists skipping..\ncollecting  1135e377-22e6-4290-b4cd-e6739de7fd8a\nexists skipping..\ncollecting  0d9f0708-5e8d-4eb8-b946-6441ef955516\nexists skipping..\ncollecting  9e5bc091-13c7-46ec-8c17-8e315b7e535c\nexists skipping..\ncollecting  93b8483d-a510-42ff-865e-33d5a8784dc4\nexists skipping..\ncollecting  ad44deb7-e56d-47bd-8d64-7147493e0aee\nexists skipping..\ncollecting  e6d48180-814d-494b-99cc-0be5cd1a0eaf\nexists skipping..\ncollecting  360f1bcc-aa60-4052-a18a-b33da5745ff4\nexists skipping..\ncollecting  8e7f826f-8dc9-490a-9282-98d899a07cc7\nexists skipping..\ncollecting  02cf33c2-c8e2-48b9-bf72-92506e97e251\nexists skipping..\ncollecting  830bc2b9-592d-4334-842a-213ba4c0a347\nexists skipping..\ncollecting  9ea23099-dd30-4b26-9de7-5d42d5dae87b\nexists skipping..\ncollecting  2f5c1968-2c34-4539-a9f4-38298d0de925\nexists skipping..\ncollecting  eab40c22-0c15-4291-a6ce-e085a7f0f1e4\nexists skipping..\ncollecting  ab89875f-3b86-4c6a-8d66-767017570dfc\nexists skipping..\ncollecting  9c43edf0-541f-4dbb-9fe1-42cc83d453bd\nexists skipping..\ncollecting  9c43edf0-541f-4dbb-9fe1-42cc83d453bd\nexists skipping..\ncollecting  990e5974-9c60-4c9a-ba23-ddce13971178\nexists skipping..\ncollecting  b1936012-0d31-4b92-8d60-c24903b2e569\nexists skipping..\ncollecting  e13f9c1b-dca0-4c63-a64c-76f6bc725156\nexists skipping..\ncollecting  af0463d4-f20f-4d13-bd0f-5834e2e8717b\nexists skipping..\ncollecting  c0e85162-6ff4-401b-b01e-cc6d7a51eac0\nexists skipping..\ncollecting  e467a17f-a729-4938-87a1-ac25157eed63\nexists skipping..\ncollecting  4f13c5e6-14c0-44cf-a2b0-4ef9bb3704fd\nexists skipping..\ncollecting  7f215a89-2a17-42f0-a2fb-f18fbc888cef\nexists skipping..\ncollecting  a5366d95-7b9d-4b1b-a16f-99e56fab08f5\nexists skipping..\ncollecting  7a266524-6e76-4d06-963f-6f977e356574\nexists skipping..\ncollecting  fde3221a-9ce3-45a9-857f-bd196b07aa05\nexists skipping..\ncollecting  2f266b81-aad3-4c26-ac69-1bd04a208bf7\nexists skipping..\ncollecting  cdb446bc-e801-404f-9911-9ba5c687f6af\nexists skipping..\ncollecting  0a0ea690-5b73-4459-91d5-a6948d132a48\nexists skipping..\ncollecting  10162c55-772d-49d2-8b1b-b1f9c86254b2\nexists skipping..\ncollecting  9448e70e-32ff-4c47-b6e7-ccb1df91743b\nexists skipping..\ncollecting  47e625fa-e2df-43ce-84dd-8ac21fdda75a\nexists skipping..\ncollecting  da6ce150-5daf-4a91-9fdd-a85854462b08\nexists skipping..\ncollecting  e776d9b6-2180-4f50-90bf-77f7b920fc3b\nexists skipping..\ncollecting  ab89875f-3b86-4c6a-8d66-767017570dfc\nexists skipping..\ncollecting  f78ea076-10a1-45dc-a848-c08e129c6a28\nexists skipping..\ncollecting  2f5c1968-2c34-4539-a9f4-38298d0de925\nexists skipping..\ncollecting  f78ea076-10a1-45dc-a848-c08e129c6a28\nexists skipping..\ncollecting  cde149fe-708b-4a35-bea8-959eb9da4e0b\nexists skipping..\ncollecting  064d7f3e-8bbd-49cd-b360-5c4590a19b9e\nexists skipping..\ncollecting  cde149fe-708b-4a35-bea8-959eb9da4e0b\nexists skipping..\ncollecting  e6d48180-814d-494b-99cc-0be5cd1a0eaf\nexists skipping..\n",
  "history_begin_time" : 1644830745894,
  "history_end_time" : 1644830748970,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "fMJ5O65ixCQ5",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n\n      viirs = ee.ImageCollection(product_name) \\\n          \t.filterDate('2013-01-01','2021-12-31') \\\n            .filterBounds(poi) \\\n          \t.filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')) \\\n      \t\t.select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "Running",
  "history_begin_time" : 1644792801735,
  "history_end_time" : 1645392721806,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : null,
  "indicator" : "Stopped"
},{
  "history_id" : "H1NGx1PKxz07",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n\n      viirs = ee.ImageCollection(product_name) \\\n          \t.filterDate('2013-01-01','2021-12-31') \\\n            .filterBounds(poi) \\\n          \t.filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')) \\\n      \t\t.select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "/Users/joe\nTraceback (most recent call last):\n  File \"/Users/joe/gw-workspace/rhqY9wNzIGXFO45qVRfDWTBpqm/data_gee_sentinel1_station_only.py\", line 42, in <module>\n    for ind in station_cell_mapper_df.index:\nNameError: name 'station_cell_mapper_df' is not defined\n",
  "history_begin_time" : 1644792766866,
  "history_end_time" : 1644792769635,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : null,
  "indicator" : "Done"
},]
