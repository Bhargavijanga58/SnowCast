[{
  "history_id" : "jsdz3fde6am",
  "history_input" : "# Data Preparation for Sentinel 2\n\nprint(\"Not ready yet..Prepare sentinel 2 into .csv\")\n\n",
  "history_output" : "Not ready yet..Prepare sentinel 2 into .csv\n",
  "history_begin_time" : 1657574453166,
  "history_end_time" : 1657574453280,
  "history_notes" : null,
  "history_process" : "78vedq",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "v98djziuelc",
  "history_input" : "# Create LSTM model\n\nprint(\"Create LSTM\")\n\n",
  "history_output" : "Create LSTM\n",
  "history_begin_time" : 1657574447357,
  "history_end_time" : 1657574448086,
  "history_notes" : null,
  "history_process" : "mxpyqt",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "tj2kym7ci05",
  "history_input" : "from sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom base_hole import BaseHole\nfrom sklearn.model_selection import train_test_split\nfrom datetime import datetime\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n\nclass RandomForestHole(BaseHole):\n  \n  all_ready_file = f\"{github_dir}/data/ready_for_training/all_ready.csv\"\n  \n\n  def preprocessing(self):\n    all_ready_pd = pd.read_csv(self.all_ready_file, header=0, index_col=0)\n    all_ready_pd = all_ready_pd.fillna(10000) # replace all nan with 10000\n    train, test = train_test_split(all_ready_pd, test_size=0.2)\n    self.train_x, self.train_y = train[['year','m','doy','ndsi','grd','eto','pr','rmax','rmin','tmmn','tmmx','vpd','vs','lat','lon','elevation','aspect','curvature','slope','eastness','northness']].to_numpy().astype('float'), train['swe'].to_numpy().astype('float')\n    self.test_x, self.test_y = test[['year','m','doy','ndsi','grd','eto','pr','rmax','rmin','tmmn','tmmx','vpd','vs','lat','lon','elevation','aspect','curvature','slope','eastness','northness']].to_numpy().astype('float'), test['swe'].to_numpy().astype('float')\n  \n  def get_model(self):\n    rfc_pipeline = Pipeline(steps = [\n      ('data_scaling', StandardScaler()),\n      ('model', RandomForestRegressor(max_depth = 15,\n                                       min_samples_leaf = 0.004,\n                                       min_samples_split = 0.008,\n                                       n_estimators = 25))])\n    return rfc_pipeline\n\n  def evaluate(self):\n    mae = metrics.mean_absolute_error(self.test_y, self.test_y_results)\n    mse = metrics.mean_squared_error(self.test_y, self.test_y_results)\n    r2 = metrics.r2_score(self.test_y, self.test_y_results)\n    rmse = math.sqrt(mse)\n\n    print(\"The random forest model performance for testing set\")\n    print(\"--------------------------------------\")\n    print('MAE is {}'.format(mae))\n    print('MSE is {}'.format(mse))\n    print('R2 score is {}'.format(r2))\n    print('RMSE is {}'.format(rmse))\n    return {\"mae\":mae, \"mse\": mse, \"r2\": r2, \"rmse\": rmse}\n  \n",
  "history_output" : "",
  "history_begin_time" : 1657574450123,
  "history_end_time" : 1657574453059,
  "history_notes" : null,
  "history_process" : "c2xkhz",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "0awcme1ndgh",
  "history_input" : "# 2020.06.09-Changed for building GhostNet\n#            Huawei Technologies Co., Ltd. <foss@huawei.com>\n\"\"\"\nCreates a GhostNet Model as defined in:\nhttps://arxiv.org/abs/1911.11907\n\"\"\"\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nimport math\nimport pandas as pd\nimport json\nimport geojson\nimport geopandas as gpd\nimport os.path\nfrom datetime import datetime\n\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n\n__all__ = ['ghostnet']\n\nall_ready_file = f\"{github_dir}/data/ready_for_training/all_ready.csv\"\n\n\ndef preprocessing(self):\n    all_ready_pd = pd.read_csv(self.all_ready_file, header=0, index_col=0)\n    all_ready_pd = all_ready_pd.fillna(10000)  # replace all nan with 10000\n\n'''custom torch dataset here'''\n\ntrain, test = train_test_split(all_ready_pd, test_size=0.2)\ntrain_x, train_y = train[\n                                 ['year', 'm', 'doy', 'ndsi', 'grd', 'eto', 'pr', 'rmax', 'rmin', 'tmmn', 'tmmx', 'vpd',\n                                  'vs', 'lat', 'lon', 'elevation', 'aspect', 'curvature', 'slope', 'eastness',\n                                  'northness']].to_numpy().astype('float'), train['swe'].to_numpy().astype('float')\ntest_x, test_y = test[['year', 'm', 'doy', 'ndsi', 'grd', 'eto', 'pr', 'rmax', 'rmin', 'tmmn', 'tmmx', 'vpd',\n                                 'vs', 'lat', 'lon', 'elevation', 'aspect', 'curvature', 'slope', 'eastness',\n                                 'northness']].to_numpy().astype('float'), test['swe'].to_numpy().astype('float')\n\n\ndef _make_divisible(v, divisor, min_value=None):\n    \"\"\"\n    This function is taken from the original tf repo.\n    It ensures that all layers have a channel number that is divisible by 8\n    It can be seen here:\n    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n    \"\"\"\n    if min_value is None:\n        min_value = divisor\n    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n    # Make sure that round down does not go down by more than 10%.\n    if new_v < 0.9 * v:\n        new_v += divisor\n    return new_v\n\n\ndef hard_sigmoid(x, inplace: bool = False):\n    if inplace:\n        return x.add_(3.).clamp_(0., 6.).div_(6.)\n    else:\n        return F.relu6(x + 3.) / 6.\n\n\nclass SqueezeExcite(nn.Module):\n    def __init__(self, in_chs, se_ratio=0.25, reduced_base_chs=None,\n                 act_layer=nn.ReLU, gate_fn=hard_sigmoid, divisor=4, **_):\n        super(SqueezeExcite, self).__init__()\n        self.gate_fn = gate_fn\n        reduced_chs = _make_divisible((reduced_base_chs or in_chs) * se_ratio, divisor)\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.conv_reduce = nn.Conv2d(in_chs, reduced_chs, 1, bias=True)\n        self.act1 = act_layer(inplace=True)\n        self.conv_expand = nn.Conv2d(reduced_chs, in_chs, 1, bias=True)\n\n    def forward(self, x):\n        x_se = self.avg_pool(x)\n        x_se = self.conv_reduce(x_se)\n        x_se = self.act1(x_se)\n        x_se = self.conv_expand(x_se)\n        x = x * self.gate_fn(x_se)\n        return x\n\n\nclass ConvBnAct(nn.Module):\n    def __init__(self, in_chs, out_chs, kernel_size,\n                 stride=1, act_layer=nn.ReLU):\n        super(ConvBnAct, self).__init__()\n        self.conv = nn.Conv2d(in_chs, out_chs, kernel_size, stride, kernel_size // 2, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_chs)\n        self.act1 = act_layer(inplace=True)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn1(x)\n        x = self.act1(x)\n        return x\n\n\nclass GhostModule(nn.Module):\n    def __init__(self, inp, oup, kernel_size=1, ratio=2, dw_size=3, stride=1, relu=True):\n        super(GhostModule, self).__init__()\n        self.oup = oup\n        init_channels = math.ceil(oup / ratio)\n        new_channels = init_channels * (ratio - 1)\n\n        self.primary_conv = nn.Sequential(\n            nn.Conv2d(inp, init_channels, kernel_size, stride, kernel_size // 2, bias=False),\n            nn.BatchNorm2d(init_channels),\n            nn.ReLU(inplace=True) if relu else nn.Sequential(),\n        )\n\n        self.cheap_operation = nn.Sequential(\n            nn.Conv2d(init_channels, new_channels, dw_size, 1, dw_size // 2, groups=init_channels, bias=False),\n            nn.BatchNorm2d(new_channels),\n            nn.ReLU(inplace=True) if relu else nn.Sequential(),\n        )\n\n    def forward(self, x):\n        x1 = self.primary_conv(x)\n        x2 = self.cheap_operation(x1)\n        out = torch.cat([x1, x2], dim=1)\n        return out[:, :self.oup, :, :]\n\n\nclass GhostBottleneck(nn.Module):\n    \"\"\" Ghost bottleneck w/ optional SE\"\"\"\n\n    def __init__(self, in_chs, mid_chs, out_chs, dw_kernel_size=3,\n                 stride=1, act_layer=nn.ReLU, se_ratio=0.):\n        super(GhostBottleneck, self).__init__()\n        has_se = se_ratio is not None and se_ratio > 0.\n        self.stride = stride\n\n        # Point-wise expansion\n        self.ghost1 = GhostModule(in_chs, mid_chs, relu=True)\n\n        # Depth-wise convolution\n        if self.stride > 1:\n            self.conv_dw = nn.Conv2d(mid_chs, mid_chs, dw_kernel_size, stride=stride,\n                                     padding=(dw_kernel_size - 1) // 2,\n                                     groups=mid_chs, bias=False)\n            self.bn_dw = nn.BatchNorm2d(mid_chs)\n\n        # Squeeze-and-excitation\n        if has_se:\n            self.se = SqueezeExcite(mid_chs, se_ratio=se_ratio)\n        else:\n            self.se = None\n\n        # Point-wise linear projection\n        self.ghost2 = GhostModule(mid_chs, out_chs, relu=False)\n\n        # shortcut\n        if (in_chs == out_chs and self.stride == 1):\n            self.shortcut = nn.Sequential()\n        else:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_chs, in_chs, dw_kernel_size, stride=stride,\n                          padding=(dw_kernel_size - 1) // 2, groups=in_chs, bias=False),\n                nn.BatchNorm2d(in_chs),\n                nn.Conv2d(in_chs, out_chs, 1, stride=1, padding=0, bias=False),\n                nn.BatchNorm2d(out_chs),\n            )\n\n    def forward(self, x):\n        residual = x\n\n        # 1st ghost bottleneck\n        x = self.ghost1(x)\n\n        # Depth-wise convolution\n        if self.stride > 1:\n            x = self.conv_dw(x)\n            x = self.bn_dw(x)\n\n        # Squeeze-and-excitation\n        if self.se is not None:\n            x = self.se(x)\n\n        # 2nd ghost bottleneck\n        x = self.ghost2(x)\n\n        x += self.shortcut(residual)\n        return x\n\n\nclass GhostNet(nn.Module):\n    def __init__(self, cfgs, num_classes=1000, width=1.0, dropout=0.2):\n        super(GhostNet, self).__init__()\n        # setting of inverted residual blocks\n        self.cfgs = cfgs\n        self.dropout = dropout\n\n        # building first layer\n        output_channel = _make_divisible(16 * width, 4)\n        self.conv_stem = nn.Conv2d(21, output_channel, 3, 2, 1, bias=False)\n        self.bn1 = nn.BatchNorm2d(output_channel)\n        self.act1 = nn.ReLU(inplace=True)\n        input_channel = output_channel\n\n        # building inverted residual blocks\n        stages = []\n        block = GhostBottleneck\n        for cfg in self.cfgs:\n            layers = []\n            for k, exp_size, c, se_ratio, s in cfg:\n                output_channel = _make_divisible(c * width, 4)\n                hidden_channel = _make_divisible(exp_size * width, 4)\n                layers.append(block(input_channel, hidden_channel, output_channel, k, s,\n                                    se_ratio=se_ratio))\n                input_channel = output_channel\n            stages.append(nn.Sequential(*layers))\n\n        output_channel = _make_divisible(exp_size * width, 4)\n        stages.append(nn.Sequential(ConvBnAct(input_channel, output_channel, 1)))\n        input_channel = output_channel\n\n        self.blocks = nn.Sequential(*stages)\n\n        # building last several layers\n        output_channel = 1280\n        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n        self.conv_head = nn.Conv2d(input_channel, output_channel, 1, 1, 0, bias=True)\n        self.act2 = nn.ReLU(inplace=True)\n        self.classifier = nn.Linear(output_channel, num_classes)\n\n    def forward(self, x):\n        x = self.conv_stem(x)\n        x = self.bn1(x)\n        x = self.act1(x)\n        x = self.blocks(x)\n        x = self.global_pool(x)\n        x = self.conv_head(x)\n        x = self.act2(x)\n        x = x.view(x.size(0), -1)\n        if self.dropout > 0.:\n            x = F.dropout(x, p=self.dropout, training=self.training)\n        x = self.classifier(x)\n        return x\n\n\ndef ghostnet(**kwargs):\n    \"\"\"\n    Constructs a GhostNet model\n    \"\"\"\n    cfgs = [\n        # k, t, c, SE, s\n        # stage1\n        [[3, 16, 16, 0, 1]],\n        # stage2\n        [[3, 48, 24, 0, 2]],\n        [[3, 72, 24, 0, 1]],\n        # stage3\n        [[5, 72, 40, 0.25, 2]],\n        [[5, 120, 40, 0.25, 1]],\n        # stage4\n        [[3, 240, 80, 0, 2]],\n        [[3, 200, 80, 0, 1],\n         [3, 184, 80, 0, 1],\n         [3, 184, 80, 0, 1],\n         [3, 480, 112, 0.25, 1],\n         [3, 672, 112, 0.25, 1]\n         ],\n        # stage5\n        [[5, 672, 160, 0.25, 2]],\n        [[5, 960, 160, 0, 1],\n         [5, 960, 160, 0.25, 1],\n         [5, 960, 160, 0, 1],\n         [5, 960, 160, 0.25, 1]\n         ]\n    ]\n    return GhostNet(cfgs, **kwargs)\n\n\nif __name__ == '__main__':\n    model = ghostnet()\n    model.eval()\n    print(model)\n    input = torch.randn(32, 3, 320, 256)\n    y = model(input)\n    print(y.size())",
  "history_output" : "",
  "history_begin_time" : 1657574447357,
  "history_end_time" : 1657574448091,
  "history_notes" : null,
  "history_process" : "rauqsh",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "6z0h5s5ovxh",
  "history_input" : "# Integrate all the datasets into one training dataset\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nimport math\nfrom datetime import datetime\n\n\nprint(\"integrating datasets into one dataset\")\n#pd.set_option('display.max_columns', None)\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\ngridcells_file = f\"{github_dir}/data/snowcast_provided/grid_cells.geojson\"\nmodel_dir = f\"{github_dir}/model/\"\ntraining_feature_file = f\"{github_dir}/data/snowcast_provided/ground_measures_train_features.csv\"\ntesting_feature_file = f\"{github_dir}/data/snowcast_provided/ground_measures_test_features.csv\"\ntrain_labels_file = f\"{github_dir}/data/snowcast_provided/train_labels.csv\"\nground_measure_metadata_file = f\"{github_dir}/data/snowcast_provided/ground_measures_metadata.csv\"\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\n\n#example_mod_file = f\"{github_dir}/data/modis/mod10a1_ndsi_f191fe19-0e81-4bc9-9980-29738a05a49b.csv\"\n\n\ntraining_feature_pd = pd.read_csv(training_feature_file, header=0, index_col=0)\ntesting_feature_pd = pd.read_csv(testing_feature_file, header=0, index_col=0)\ntrain_labels_pd = pd.read_csv(train_labels_file, header=0, index_col=0)\n#print(training_feature_pd.head())\n\nstation_cell_mapper_pd = pd.read_csv(station_cell_mapper_file, header=0, index_col=0)\n#print(station_cell_mapper_pd.head())\n\n#example_mod_pd = pd.read_csv(example_mod_file, header=0, index_col=0)\n#print(example_mod_pd.shape)\ndef getDateStr(x):\n  return x.split(\" \")[0]\n\ndef integrate_modis():\n  \"\"\"\n  Integrate all MODIS data into mod_all.csv\n  \"\"\"\n  all_mod_file = f\"{github_dir}/data/ready_for_training/modis_all.csv\"\n  if os.path.isfile(all_mod_file):\n    return\n  dates = pd.date_range(start='1/1/2013', end='12/31/2021', freq='D').astype(str)\n  mod_all_df = pd.DataFrame(columns=[\"date\"])\n  mod_all_df['date'] = dates\n  \n  #print(mod_all_df.head())\n  for ind in station_cell_mapper_pd.index:\n    current_cell_id = station_cell_mapper_pd[\"cell_id\"][ind]\n    print(current_cell_id)\n    mod_single_file = f\"{github_dir}/data/sat_training/modis/mod10a1_ndsi_{current_cell_id}.csv\"\n    if os.path.isfile(mod_single_file):\n      mod_single_pd = pd.read_csv(mod_single_file, header=0)\n      mod_single_pd = mod_single_pd[[\"date\", \"mod10a1_ndsi\"]]\n      mod_single_pd = mod_single_pd.rename(columns={\"mod10a1_ndsi\": current_cell_id})\n      mod_single_pd['date'] = pd.to_datetime(mod_single_pd['date']).astype(str)\n      print(mod_all_df.shape)\n      mod_all_df = pd.merge(mod_all_df, mod_single_pd, how='left', on=\"date\")\n  mod_all_df.to_csv(all_mod_file)\n\n  \ndef integrate_sentinel1():\n  \"\"\"\n  Integrate all Sentinel 1 data into sentinel1_all.csv\n  \"\"\"\n  all_sentinel1_file = f\"{github_dir}/data/ready_for_training/sentinel1_all.csv\"\n  if os.path.isfile(all_sentinel1_file):\n    return\n  dates = pd.date_range(start='1/1/2013', end='12/31/2021', freq='D').astype(str)\n  sentinel1_all_df = pd.DataFrame(columns=[\"date\"])\n  sentinel1_all_df['date'] = dates\n  #print(mod_all_df.head())\n  \n  for ind in station_cell_mapper_pd.index:\n    current_cell_id = station_cell_mapper_pd[\"cell_id\"][ind]\n    print(current_cell_id)\n    sentinel1_single_file = f\"{github_dir}/data/sat_training/sentinel1/s1_grd_vv_{current_cell_id}.csv\"\n    if os.path.isfile(sentinel1_single_file) and current_cell_id not in sentinel1_all_df :\n      sentinel1_single_pd = pd.read_csv(sentinel1_single_file, header=0)\n      sentinel1_single_pd = sentinel1_single_pd[[\"date\", \"s1_grd_vv\"]]\n      sentinel1_single_pd = sentinel1_single_pd.rename(columns={\"s1_grd_vv\": current_cell_id})\n      #sentinel1_single_pd['date'] = sentinel1_single_pd['date'].astype('datetime64[ns]')\n      sentinel1_single_pd['date'] = pd.to_datetime(sentinel1_single_pd['date']).dt.round(\"D\").astype(str)\n      print(\"sentinel1_single_pd: \", sentinel1_single_pd.head())\n      print(\"sentinel1_single_pd check value: \", sentinel1_single_pd[sentinel1_single_pd[\"date\"]==\"2015-04-01\"])\n      sentinel1_single_pd = sentinel1_single_pd.drop_duplicates(subset=['date'], keep='first') # this will remove all the other values of the same day\n      \n      sentinel1_all_df = pd.merge(sentinel1_all_df, sentinel1_single_pd, how='left', on=\"date\")\n      print(\"sentinel1_all_df check value: \", sentinel1_all_df[sentinel1_all_df[\"date\"]==\"2015-04-01\"])\n      print(\"sentinel1_all_df: \", sentinel1_all_df.shape)\n      \n\n  print(sentinel1_all_df.shape)\n  sentinel1_all_df.to_csv(all_sentinel1_file)\n\ndef integrate_gridmet():\n  \"\"\"\n  Integrate all gridMET data into gridmet_all.csv\n  \"\"\"\n  \n  \n  dates = pd.date_range(start='1/1/2013', end='12/31/2021', freq='D').astype(str)\n  \n  #print(mod_all_df.head())\n  var_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n  \n  for var in var_list:\n    gridmet_all_df = pd.DataFrame(columns=[\"date\"])\n    gridmet_all_df['date'] = dates\n    all_gridmet_file = f\"{github_dir}/data/ready_for_training/gridmet_{var}_all.csv\"\n    if os.path.isfile(all_gridmet_file):\n      return\n    for ind in station_cell_mapper_pd.index:\n      current_cell_id = station_cell_mapper_pd[\"cell_id\"][ind]\n      print(current_cell_id)\n      gridmet_single_file = f\"{github_dir}/data/sim_training/gridmet/{var}_{current_cell_id}.csv\"\n      if os.path.isfile(gridmet_single_file) and current_cell_id not in gridmet_all_df :\n        gridmet_single_pd = pd.read_csv(gridmet_single_file, header=0)\n        gridmet_single_pd = gridmet_single_pd[[\"date\", var]]\n        gridmet_single_pd = gridmet_single_pd.rename(columns={var: current_cell_id})\n        #sentinel1_single_pd['date'] = sentinel1_single_pd['date'].astype('datetime64[ns]')\n        gridmet_single_pd['date'] = pd.to_datetime(gridmet_single_pd['date']).dt.round(\"D\").astype(str)\n        print(\"gridmet_single_pd: \", gridmet_single_pd.head())\n        print(\"gridmet_single_pd check value: \", gridmet_single_pd[gridmet_single_pd[\"date\"]==\"2015-04-01\"])\n        gridmet_single_pd = gridmet_single_pd.drop_duplicates(subset=['date'], keep='first') # this will remove all the other values of the same day\n\n        gridmet_all_df = pd.merge(gridmet_all_df, gridmet_single_pd, how='left', on=\"date\")\n        print(\"gridmet_all_df check value: \", gridmet_all_df[gridmet_all_df[\"date\"]==\"2015-04-01\"])\n        print(\"gridmet_all_df: \", gridmet_all_df.shape)\n      \n    print(gridmet_all_df.shape)\n    gridmet_all_df.to_csv(all_gridmet_file)\n  \n  \ndef prepare_training_csv():\n  \"\"\"\n  MOD model:\n    input columns: [m, doy, ndsi]\n    output column: [swe]\n  Sentinel1 model:\n    input columns: [m, doy, grd]\n    output column: [swe]\n  gridMET model:\n    input columns: [m, doy, tmmn, tmmx, pr, vpd, eto, rmax, rmin, vs]\n    output column: [swe]\n  \"\"\"\n  all_ready_file = f\"{github_dir}/data/ready_for_training/all_ready.csv\"\n  if os.path.isfile(all_ready_file):\n      return\n  \n  all_mod_file = f\"{github_dir}/data/ready_for_training/modis_all.csv\"\n  modis_all_pd = pd.read_csv(all_mod_file, header=0)\n  all_sentinel1_file = f\"{github_dir}/data/ready_for_training/sentinel1_all.csv\"\n  sentinel1_all_pd = pd.read_csv(all_sentinel1_file, header=0)\n  all_gridmet_eto_file = f\"{github_dir}/data/ready_for_training/gridmet_eto_all.csv\"\n  gridmet_eto_all_pd = pd.read_csv(all_gridmet_eto_file, header=0, index_col = 0)\n  all_gridmet_pr_file = f\"{github_dir}/data/ready_for_training/gridmet_pr_all.csv\"\n  gridmet_pr_all_pd = pd.read_csv(all_gridmet_pr_file, header=0, index_col = 0)\n  all_gridmet_rmax_file = f\"{github_dir}/data/ready_for_training/gridmet_rmax_all.csv\"\n  gridmet_rmax_all_pd = pd.read_csv(all_gridmet_rmax_file, header=0, index_col = 0)\n  all_gridmet_rmin_file = f\"{github_dir}/data/ready_for_training/gridmet_rmin_all.csv\"\n  gridmet_rmin_all_pd = pd.read_csv(all_gridmet_rmin_file, header=0, index_col = 0)\n  all_gridmet_tmmn_file = f\"{github_dir}/data/ready_for_training/gridmet_tmmn_all.csv\"\n  gridmet_tmmn_all_pd = pd.read_csv(all_gridmet_tmmn_file, header=0, index_col = 0)\n  all_gridmet_tmmx_file = f\"{github_dir}/data/ready_for_training/gridmet_tmmx_all.csv\"\n  gridmet_tmmx_all_pd = pd.read_csv(all_gridmet_tmmx_file, header=0, index_col = 0)\n  all_gridmet_vpd_file = f\"{github_dir}/data/ready_for_training/gridmet_vpd_all.csv\"\n  gridmet_vpd_all_pd = pd.read_csv(all_gridmet_vpd_file, header=0, index_col = 0)\n  all_gridmet_vs_file = f\"{github_dir}/data/ready_for_training/gridmet_vs_all.csv\"\n  gridmet_vs_all_pd = pd.read_csv(all_gridmet_vs_file, header=0, index_col = 0)\n  \n  grid_terrain_file = f\"{github_dir}/data/terrain/gridcells_terrainData.csv\"\n  grid_terrain_pd = pd.read_csv(grid_terrain_file, header=0, index_col = 1)\n  \n  print(\"modis_all_size: \", modis_all_pd.shape)\n  print(\"station size: \", station_cell_mapper_pd.shape)\n  print(\"training_feature_pd size: \", training_feature_pd.shape)\n  print(\"testing_feature_pd size: \", testing_feature_pd.shape)\n  \n  all_training_pd = pd.DataFrame(columns=[\"cell_id\", \"year\", \"m\", \"doy\", \"ndsi\", \"grd\", \"eto\", \"pr\", \"rmax\", \"rmin\", \"tmmn\", \"tmmx\", \"vpd\", \"vs\", \"lat\", \"lon\", \"elevation\", \"aspect\", \"curvature\", \"slope\", \"eastness\", \"northness\", \"swe\"])\n  all_training_pd = all_training_pd.reset_index()\n  for index, row in modis_all_pd.iterrows():\n    dt = datetime.strptime(row['date'], '%Y-%m-%d')\n    month = dt.month\n    year = dt.year\n    doy = dt.timetuple().tm_yday\n    print(f\"Dealing {year} {doy}\")\n    for i in range(3,len(row.index)):\n      cell_id = row.index[i][:-2]\n      if cell_id in train_labels_pd.index and row['date'] in train_labels_pd:\n        ndsi = row.values[i]\n        swe = train_labels_pd.loc[cell_id, row['date']]\n        grd = sentinel1_all_pd.loc[index, cell_id]\n        eto = gridmet_eto_all_pd.loc[index, cell_id]\n        pr = gridmet_pr_all_pd.loc[index, cell_id]\n        rmax = gridmet_rmax_all_pd.loc[index, cell_id]\n        rmin = gridmet_rmin_all_pd.loc[index, cell_id]\n        tmmn = gridmet_tmmn_all_pd.loc[index, cell_id]\n        tmmx = gridmet_tmmx_all_pd.loc[index, cell_id]\n        vpd = gridmet_vpd_all_pd.loc[index, cell_id]\n        vs = gridmet_vs_all_pd.loc[index, cell_id]\n        lat = grid_terrain_pd.loc[cell_id, \"Longitude [deg]\"]\n        lon = grid_terrain_pd.loc[cell_id, \"Latitude [deg]\"]\n        elevation = grid_terrain_pd.loc[cell_id, \"Elevation [m]\"]\n        aspect = grid_terrain_pd.loc[cell_id, \"Aspect [deg]\"]\n        curvature = grid_terrain_pd.loc[cell_id, \"Curvature [ratio]\"]\n        slope = grid_terrain_pd.loc[cell_id, \"Slope [deg]\"]\n        eastness = grid_terrain_pd.loc[cell_id, \"Eastness [unitCirc.]\"]\n        northness = grid_terrain_pd.loc[cell_id, \"Northness [unitCirc.]\"]\n        \n        if not np.isnan(swe):\n          json_kv = {\"cell_id\": cell_id, \"year\":year, \"m\":month, \"doy\": doy, \"ndsi\":ndsi, \"grd\":grd, \"eto\":eto, \"pr\":pr, \"rmax\":rmax, \"rmin\":rmin, \"tmmn\":tmmn, \"tmmx\":tmmx, \"vpd\":vpd, \"vs\":vs, \"lat\":lat, \"lon\":lon, \"elevation\":elevation, \"aspect\":aspect, \"curvature\":curvature, \"slope\":slope, \"eastness\":eastness, \"northness\":northness, \"swe\":swe}\n          # print(json_kv)\n          all_training_pd = all_training_pd.append(json_kv, ignore_index = True)\n  \n  print(all_training_pd.shape)\n  all_training_pd.to_csv(all_ready_file)\n  \n  \"\"\"\n  grd_all_pd = pd.DataFrame(columns=[\"year\", \"m\", \"doy\", \"grd\", \"swe\"])\n  grd_all_pd = grd_all_pd.reset_index()\n  for index, row in sentinel1_all_pd.iterrows():\n    dt = datetime.strptime(row['date'], '%Y-%m-%d')\n    year = dt.year\n    month = dt.month\n    doy = dt.timetuple().tm_yday\n    for i in range(3,len(row.index)):\n      cell_id = row.index[i]\n      grd = row.values[i]\n      if not np.isnan(grd) and cell_id in train_labels_pd.index and row['date'] in train_labels_pd:\n        swe = train_labels_pd.loc[cell_id, row['date']]\n        if not np.isnan(swe):\n          print([month, doy, grd, swe])\n          grd_all_pd = grd_all_pd.append({\"year\": year, \"m\":month, \"doy\": doy, \"grd\": grd, \"swe\": swe}, ignore_index = True)\n  \n  print(grd_all_pd.shape)\n  grd_all_pd.to_csv(f\"{github_dir}/data/ready_for_training/sentinel1_ready.csv\")\n  \"\"\"\n  \n#exit() # done already\n\n#integrate_modis()\n#integrate_sentinel1()\n#integrate_gridmet()\n#prepare_training_csv()\n\n\n  \n  \n  \n",
  "history_output" : "integrating datasets into one dataset\nC:\\Users\\BLi\n",
  "history_begin_time" : 1657576256152,
  "history_end_time" : 1657576258892,
  "history_notes" : null,
  "history_process" : "u7xh2p",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "krywk611iys",
  "history_input" : "from model_creation_rf import RandomForestHole\nfrom model_creation_xgboost import XGBoostHole\n\nprint(\"Train Models\")\n\nworm_holes = [RandomForestHole(), XGBoostHole()]\n\nfor hole in worm_holes:\n  hole.preprocessing()\n  print(hole.train_x.dtype)\n  print(hole.train_y.dtype)\n  print(hole.train_x.shape)\n  print(hole.train_y.shape)\n  hole.train()\n  hole.test()\n  hole.evaluate()\n  hole.save()\n  \nprint(\"Finished training and validating all the models.\")\n",
  "history_output" : "C:\\Users\\BLi\\anaconda3\\envs\\snowcast\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:396: FutureWarning: Criterion 'mse' was deprecated in v1.0 and will be removed in version 1.2. Use `criterion='squared_error'` which is equivalent.\n  warn(\nTrain Models\nfloat64\nfloat64\n(45389, 21)\n(45389,)\nThe random forest model performance for testing set\n--------------------------------------\nMAE is 4.13161949244986\nMSE is 48.60448200593561\nR2 score is 0.6771655026307917\nRMSE is 6.971691473805737\nSaving model to C:\\Users\\BLi/Documents/GitHub/SnowCast/model/wormhole_20221107165108.joblib\nfloat64\nfloat64\n(45389, 21)\n(45389,)\nThe random forest model performance for testing set\n--------------------------------------\nMAE is 0.44766619668664986\nMSE is 2.6316546247796975\nR2 score is 0.9831274320413487\nRMSE is 1.6222375364846227\nSaving model to C:\\Users\\BLi/Documents/GitHub/SnowCast/model/wormhole_20221107165110.joblib\nFinished training and validating all the models.\n",
  "history_begin_time" : 1657576259102,
  "history_end_time" : 1657576270765,
  "history_notes" : null,
  "history_process" : "e8k4wq",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "qnuluanu4rl",
  "history_input" : "# Load dependencies\nimport geopandas as gpd\nimport json\nimport geojson\nfrom pystac_client import Client\nimport planetary_computer\nimport xarray\nimport rioxarray\nimport xrspatial\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom pyproj import Proj, transform\nimport os\nimport sys, traceback\nimport requests\n\nhome_dir = os.path.expanduser('~')\nsnowcast_github_dir = f\"{home_dir}/Documents/GitHub/SnowCast/\"\n\n#exit() # this process no longer need to execute, we need to make Geoweaver to specify which process doesn't need to run\n\n# user-defined paths for data-access\ndata_dir = f'{snowcast_github_dir}data/'\ngridcells_file = data_dir+'snowcast_provided/grid_cells_eval.geojson'\nstations_file = data_dir+'snowcast_provided/ground_measures_metadata.csv'\ngridcells_outfile = data_dir+'terrain/gridcells_terrainData_eval.csv'\nstations_outfile = data_dir+'terrain/station_terrainData_eval.csv'\n\nrequests.get('https://planetarycomputer.microsoft.com/api/stac/v1')\n\n# setup client for handshaking and data-access\nprint(\"setup planetary computer client\")\nclient = Client.open(\"https://planetarycomputer.microsoft.com/api/stac/v1\",ignore_conformance=True)\n\n# Load metadata\ngridcellsGPD = gpd.read_file(gridcells_file)\ngridcells = geojson.load(open(gridcells_file))\nstations = pd.read_csv(stations_file)\n\n# instantiate output panda dataframes\ndf_gridcells = df = pd.DataFrame(columns=(\"Longitude [deg]\",\"Latitude [deg]\",\n                                            \"Elevation [m]\",\"Aspect [deg]\",\n                                            \"Curvature [ratio]\",\"Slope [deg]\",\n                                            \"Eastness [unitCirc.]\",\"Northness [unitCirc.]\"))\ndf_station = pd.DataFrame(columns=(\"Longitude [deg]\",\"Latitude [deg]\",\n                                   \"Elevation [m]\",\"Elevation_30 [m]\",\"Elevation_1000 [m]\",\n                                   \"Aspect_30 [deg]\",\"Aspect_1000 [deg]\",\n                                   \"Curvature_30 [ratio]\",\"Curvature_1000 [ratio]\",\n                                   \"Slope_30 [deg]\",\"Slope_1000 [deg]\",\n                                   \"Eastness_30 [unitCirc.]\",\"Northness_30 [unitCirc.]\",\n                                   \"Eastness_1000 [unitCirc.]\",\"Northness_1000 [unitCirc.]\"))\n\ndef prepareGridCellTerrain():\n  # instantiate output panda dataframes\n  # Calculate gridcell characteristics using Copernicus DEM data\n  print(\"Prepare GridCell Terrain data\")\n  for idx,cell in enumerate(gridcells['features']):\n      print(\"Processing grid \", idx)\n      search = client.search(\n          collections=[\"cop-dem-glo-30\"],\n          intersects={\"type\":\"Polygon\", \"coordinates\":cell['geometry']['coordinates']},\n      )\n      items = list(search.get_items())\n      print(\"==> Searched items: \", len(items))\n\n      cropped_data = None\n      try:\n          signed_asset = planetary_computer.sign(items[0].assets[\"data\"])\n          data = (\n              #xarray.open_rasterio(signed_asset.href)\n              xarray.open_rasterio(signed_asset.href)\n              .squeeze()\n              .drop(\"band\")\n              .coarsen({\"y\": 1, \"x\": 1})\n              .mean()\n          )\n          cropped_data = data.rio.clip(gridcellsGPD['geometry'][idx:idx+1])\n      except:\n          signed_asset = planetary_computer.sign(items[1].assets[\"data\"])\n          data = (\n              xarray.open_rasterio(signed_asset.href)\n              .squeeze()\n              .drop(\"band\")\n              .coarsen({\"y\": 1, \"x\": 1})\n              .mean()\n          )\n          cropped_data = data.rio.clip(gridcellsGPD['geometry'][idx:idx+1])\n\n      # calculate lat/long of center of gridcell\n      longitude = np.unique(np.ravel(cell['geometry']['coordinates'])[0::2]).mean()\n      latitude = np.unique(np.ravel(cell['geometry']['coordinates'])[1::2]).mean()\n\n      print(\"reproject data to EPSG:32612\")\n      # reproject the cropped dem data\n      cropped_data = cropped_data.rio.reproject(\"EPSG:32612\")\n\n      # Mean elevation of gridcell\n      mean_elev = cropped_data.mean().values\n      print(\"Elevation: \", mean_elev)\n\n      # Calculate directional components\n      aspect = xrspatial.aspect(cropped_data)\n      aspect_xcomp = np.nansum(np.cos(aspect.values*(np.pi/180)))\n      aspect_ycomp = np.nansum(np.sin(aspect.values*(np.pi/180)))\n      mean_aspect = np.arctan2(aspect_ycomp,aspect_xcomp)*(180/np.pi)\n      if mean_aspect < 0:\n          mean_aspect = 360 + mean_aspect\n      print(\"Aspect: \", mean_aspect)\n      mean_eastness = np.cos(mean_aspect*(np.pi/180))\n      mean_northness = np.sin(mean_aspect*(np.pi/180))\n      print(\"Eastness: \", mean_eastness)\n      print(\"Northness: \", mean_northness)\n\n      # Positive curvature = upward convex\n      curvature = xrspatial.curvature(cropped_data)\n      mean_curvature = curvature.mean().values\n      print(\"Curvature: \", mean_curvature)\n\n      # Calculate mean slope\n      slope = xrspatial.slope(cropped_data)\n      mean_slope = slope.mean().values\n      print(\"Slope: \", mean_slope)\n\n      # Fill pandas dataframe\n      df_gridcells.loc[idx] = [longitude,latitude,\n                               mean_elev,mean_aspect,\n                               mean_curvature,mean_slope,\n                               mean_eastness,mean_northness]\n\n      # Comment out for debugging/filling purposes\n      # if idx % 250 == 0:\n      #     df_gridcells.set_index(gridcellsGPD['cell_id'][0:idx+1],inplace=True)\n      #     df_gridcells.to_csv(gridcells_outfile)\n\n  # Save output data into csv format\n  df_gridcells.set_index(gridcellsGPD['cell_id'][0:idx+1],inplace=True)\n  df_gridcells.to_csv(gridcells_outfile)\n\ndef prepareStationTerrain():\n  # Calculate terrain characteristics of stations, and surrounding regions using COP 30\n  for idx,station in stations.iterrows():\n      search = client.search(\n          collections=[\"cop-dem-glo-30\"],\n          intersects={\"type\":\"Point\", \"coordinates\":[station['longitude'],station['latitude']]},\n      )\n      items = list(search.get_items())\n      print(f\"Returned {len(items)} items\")\n\n      try:\n          signed_asset = planetary_computer.sign(items[0].assets[\"data\"])\n          data = (\n              xarray.open_rasterio(signed_asset.href)\n              .squeeze()\n              .drop(\"band\")\n              .coarsen({\"y\": 1, \"x\": 1})\n              .mean()\n          )\n          xdiff = np.abs(data.x-station['longitude'])\n          ydiff = np.abs(data.y-station['latitude'])\n          xdiff = np.where(xdiff == xdiff.min())[0][0]\n          ydiff = np.where(ydiff == ydiff.min())[0][0]\n          data = data[ydiff-33:ydiff+33,xdiff-33:xdiff+33].rio.reproject(\"EPSG:32612\")\n      except:\n          traceback.print_exc(file=sys.stdout)\n          signed_asset = planetary_computer.sign(items[1].assets[\"data\"])\n          data = (\n              xarray.open_rasterio(signed_asset.href)\n              .squeeze()\n              .drop(\"band\")\n              .coarsen({\"y\": 1, \"x\": 1})\n              .mean()\n          )\n          xdiff = np.abs(data.x-station['longitude'])\n          ydiff = np.abs(data.y-station['latitude'])\n          xdiff = np.where(xdiff == xdiff.min())[0][0]\n          ydiff = np.where(ydiff == ydiff.min())[0][0]\n          data = data[ydiff-33:ydiff+33,xdiff-33:xdiff+33].rio.reproject(\"EPSG:32612\")\n\n      # Reproject the station data to better include only 1000m surrounding area\n      inProj = Proj(init='epsg:4326')\n      outProj = Proj(init='epsg:32612')\n      new_x,new_y = transform(inProj,outProj,station['longitude'],station['latitude'])\n\n      # Calculate elevation of station and surroundings\n      mean_elevation = data.mean().values\n      elevation = data.sel(x=new_x,y=new_y,method='nearest')\n      print(elevation.values)\n\n      # Calcuate directional components\n      aspect = xrspatial.aspect(data)\n      aspect_xcomp = np.nansum(np.cos(aspect.values*(np.pi/180)))\n      aspect_ycomp = np.nansum(np.sin(aspect.values*(np.pi/180)))\n      mean_aspect = np.arctan2(aspect_ycomp,aspect_xcomp)*(180/np.pi)\n      if mean_aspect < 0:\n          mean_aspect = 360 + mean_aspect\n      print(mean_aspect)\n      aspect = aspect.sel(x=new_x,y=new_y,method='nearest')\n      print(aspect.values)\n      eastness = np.cos(aspect*(np.pi/180))\n      northness = np.sin(aspect*(np.pi/180))\n      mean_eastness = np.cos(mean_aspect*(np.pi/180))\n      mean_northness = np.sin(mean_aspect*(np.pi/180))\n\n      # Positive curvature = upward convex\n      curvature = xrspatial.curvature(data)\n      mean_curvature = curvature.mean().values\n      curvature = curvature.sel(x=new_x,y=new_y,method='nearest')\n      print(curvature.values)\n\n      # Calculate slope\n      slope = xrspatial.slope(data)\n      mean_slope = slope.mean().values\n      slope = slope.sel(x=new_x,y=new_y,method='nearest')\n      print(slope.values)\n\n      # Fill pandas dataframe\n      df_station.loc[idx] = [station['longitude'],station['latitude'],\n                             station['elevation_m'],elevation.values,mean_elevation,\n                             aspect.values,mean_aspect,\n                             curvature.values,mean_curvature,\n                             slope.values,mean_slope,\n                             eastness.values,northness.values,\n                             mean_eastness,mean_northness]\n\n      # Comment out for debugging/filling purposes\n      # if idx % 250 == 0:\n      #     df_station.set_index(stations['station_id'][0:idx+1],inplace=True)\n      #     df_station.to_csv(stations_outfile)\n\n  # Save output data into CSV format\n  df_station.set_index(stations['station_id'][0:idx+1],inplace=True)\n  df_station.to_csv(stations_outfile)\n\ntry:\n  prepareGridCellTerrain()\n  #prepareStationTerrain()\nexcept:\n  traceback.print_exc(file=sys.stdout)\n",
  "history_output" : "C:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nWarning 1: +init=epsg:XXXX syntax is deprecated. It might return a CRS with a non-EPSG compliant axis order.\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nsetup planetary computer client\nPrepare GridCell Terrain data\nProcessing grid  0\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  2120.6938\nAspect:  217.68011324563136\nEastness:  -0.7914357398210251\nNorthness:  -0.6112523781008519\nCurvature:  -0.046748288\nSlope:  5.0336185\nProcessing grid  1\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  3471.9036\nAspect:  155.19289454725342\nEastness:  -0.9077254538127077\nNorthness:  0.419564655923868\nCurvature:  0.11717822\nSlope:  24.953482\nProcessing grid  2\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  1914.814\nAspect:  173.44081042445302\nEastness:  -0.9934543806113693\nNorthness:  0.11422956554272874\nCurvature:  0.00942702\nSlope:  17.614595\nProcessing grid  3\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  1804.6176\nAspect:  192.3811198806608\nEastness:  -0.976742984945351\nNorthness:  -0.21441348222545586\nCurvature:  -0.05555519\nSlope:  12.841655\nProcessing grid  4\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  3686.457\nAspect:  6.489669662054943\nEastness:  0.9935922498866476\nNorthness:  0.11302407250311532\nCurvature:  -0.04161675\nSlope:  18.612993\nProcessing grid  5\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  3786.2173\nAspect:  95.48403652116228\nEastness:  -0.09556841622735353\nNorthness:  0.9954228638221021\nCurvature:  -0.007121049\nSlope:  26.77771\nProcessing grid  6\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  1345.8301\nAspect:  299.3707398323038\nEastness:  0.490458772692443\nNorthness:  -0.8714643953077043\nCurvature:  0.016378662\nSlope:  11.267566\nProcessing grid  7\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  2900.79\nAspect:  274.22071289313124\nEastness:  0.07359872967839165\nNorthness:  -0.9972879358488836\nCurvature:  -0.06548714\nSlope:  32.67105\nProcessing grid  8\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  1255.2838\nAspect:  276.4685486395499\nEastness:  0.11265779554573373\nNorthness:  -0.9936338465968113\nCurvature:  -0.11243193\nSlope:  26.328371\nProcessing grid  9\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  1731.1326\nAspect:  278.4567142541031\nEastness:  0.14706218851683012\nNorthness:  -0.9891272479861427\nCurvature:  0.022968741\nSlope:  12.057334\nProcessing grid  10\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  2094.1812\nAspect:  89.0112916409838\nEastness:  0.017255359802198025\nNorthness:  0.9998511151957059\nCurvature:  0.024416748\nSlope:  10.076949\nProcessing grid  11\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  331.3498\nAspect:  262.609650851298\nEastness:  -0.1286285585226733\nNorthness:  -0.9916928425336039\nCurvature:  -0.05768589\nSlope:  16.0718\nProcessing grid  12\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  3240.3425\nAspect:  88.11662565217134\nEastness:  0.0328651641582254\nNorthness:  0.9994597945814794\nCurvature:  0.022669673\nSlope:  22.973846\nProcessing grid  13\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  3304.085\nAspect:  261.02517673744927\nEastness:  -0.15600044294003665\nNorthness:  -0.9877569851955046\nCurvature:  -0.1317374\nSlope:  16.328588\nProcessing grid  14\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  1823.0842\nAspect:  5.145508923963943\nEastness:  0.9959701442141216\nNorthness:  0.08968540479978811\nCurvature:  0.018122088\nSlope:  6.2928886\nProcessing grid  15\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  3576.177\nAspect:  98.09900859584751\nEastness:  -0.1408841012731224\nNorthness:  0.990026095619941\nCurvature:  0.063626304\nSlope:  26.524445\nProcessing grid  16\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  2606.6792\nAspect:  14.783046288616744\nEastness:  0.9668989321882762\nNorthness:  0.25515966556877945\nCurvature:  -0.091937326\nSlope:  27.238976\nProcessing grid  17\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  2962.6672\nAspect:  349.9972289416514\nEastness:  0.9847993535240053\nNorthness:  -0.17369580679654084\nCurvature:  0.04339221\nSlope:  21.421736\nProcessing grid  18\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  3078.287\nAspect:  190.79842844618545\nEastness:  -0.9822923900016164\nNorthness:  -0.18735437156605736\nCurvature:  0.028371405\nSlope:  29.53541\nProcessing grid  19\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  3916.1743\nAspect:  213.64696850300885\nEastness:  -0.83246731539834\nNorthness:  -0.5540741545979931\nCurvature:  0.09668792\nSlope:  30.096178\nProcessing grid  20\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  3086.3892\nAspect:  91.78479240630503\nEastness:  -0.031145466363551245\nNorthness:  0.9995148622831963\nCurvature:  -0.043670613\nSlope:  10.518907\nProcessing grid  21\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  1700.8246\nAspect:  73.26606635870361\nEastness:  0.28792774340008004\nNorthness:  0.9576521365195911\nCurvature:  -0.050066065\nSlope:  6.3208604\nProcessing grid  22\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  3571.585\nAspect:  347.47937447300086\nEastness:  0.9762180292048681\nNorthness:  -0.21679105021970635\nCurvature:  0.12000399\nSlope:  31.807535\nProcessing grid  23\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  1841.9855\nAspect:  325.00696695735456\nEastness:  0.8192217830310204\nNorthness:  -0.5734768262166098\nCurvature:  -0.118008785\nSlope:  31.354729\nProcessing grid  24\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  2246.6226\nAspect:  216.25855963405493\nEastness:  -0.8063562572749055\nNorthness:  -0.5914301195860814\nCurvature:  0.0962\nSlope:  13.658678\nProcessing grid  25\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  1824.9602\nAspect:  222.0443309177027\nEastness:  -0.7426268830395489\nNorthness:  -0.6697053923830718\nCurvature:  0.008862758\nSlope:  4.7009864\nProcessing grid  26\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  1552.4861\nAspect:  74.8364497922946\nEastness:  0.26157521215744645\nNorthness:  0.9651830957827571\nCurvature:  -0.026613291\nSlope:  5.799249\nProcessing grid  27\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  1927.4338\nAspect:  252.67507923181194\nEastness:  -0.297790118627167\nNorthness:  -0.9546313661555532\nCurvature:  0.028582398\nSlope:  33.38909\nProcessing grid  28\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  1856.8232\nAspect:  89.03064156690245\nEastness:  0.01691768918865546\nNorthness:  0.9998568856554002\nCurvature:  -0.04536924\nSlope:  13.987566\nProcessing grid  29\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  2150.4192\nAspect:  229.4796475274219\nEastness:  -0.6497181169767423\nNorthness:  -0.7601752222166914\nCurvature:  -0.042451322\nSlope:  15.870835\nProcessing grid  30\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  3140.689\nAspect:  33.404822815320735\nEastness:  0.8348015241364743\nNorthness:  0.550551010624283\nCurvature:  -0.07062238\nSlope:  7.5268574\nProcessing grid  31\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  932.2599\nAspect:  199.79041346964226\nEastness:  -0.9409374322335965\nNorthness:  -0.33858049060990797\nCurvature:  -0.0379878\nSlope:  13.717633\nProcessing grid  32\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  1147.3716\nAspect:  159.53446331203702\nEastness:  -0.9368826689242585\nNorthness:  0.34964391124307903\nCurvature:  -0.033276845\nSlope:  6.527311\nProcessing grid  33\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  3541.9214\nAspect:  66.30279095271315\nEastness:  0.40190317305090373\nNorthness:  0.9156821716576201\nCurvature:  0.03434372\nSlope:  26.642073\nProcessing grid  34\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  450.58377\nAspect:  291.0896067467161\nEastness:  0.35982756770182556\nNorthness:  C:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\n-0.9330188216331909\nCurvature:  -0.029498136\nSlope:  9.801241\nProcessing grid  35\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  2636.9148\nAspect:  202.85996878453767\nEastness:  -0.9214570524705654\nNorthness:  -0.3884802446100157\nCurvature:  -0.0072893742\nSlope:  4.8913393\nProcessing grid  36\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  2670.7993\nAspect:  95.034070488831\nEastness:  -0.08774810671837718\nNorthness:  0.9961426954846079\nCurvature:  -0.05702252\nSlope:  17.121742\nProcessing grid  37\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  2047.4597\nAspect:  51.33676048113719\nEastness:  0.6247418102213355\nNorthness:  0.7808313970130613\nCurvature:  -0.03535638\nSlope:  8.105335\nProcessing grid  38\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  1335.297\nAspect:  227.0967174694095\nEastness:  -0.6807628359324939\nNorthness:  -0.7325038984286353\nCurvature:  -0.16417512\nSlope:  34.03324\nProcessing grid  39\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  2656.8367\nAspect:  298.4444159166883\nEastness:  0.47630597317129564\nNorthness:  -0.8792796028120663\nCurvature:  0.049409624\nSlope:  15.122141\nProcessing grid  40\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  1370.5\nAspect:  358.99999990102464\nEastness:  0.9998476951262432\nNorthness:  -0.017452408164466204\nCurvature:  0.0\nSlope:  0.0\nProcessing grid  41\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  1796.4607\nAspect:  89.02310786824792\nEastness:  0.017049158070608767\nNorthness:  0.9998546525415999\nCurvature:  0.0030294585\nSlope:  13.352342\nProcessing grid  42\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  624.0497\nAspect:  255.15704020260034\nEastness:  -0.2561706004861175\nNorthness:  -0.9666315862036488\nCurvature:  0.10417056\nSlope:  24.366879\nProcessing grid  43\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  2582.33\nAspect:  324.7078012566134\nEastness:  0.8162162622299647\nNorthness:  -0.5777464956807141\nCurvature:  -0.055021193\nSlope:  19.426573\nProcessing grid  44\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  1182.033\nAspect:  338.3857912394138\nEastness:  0.9296851662183213\nNorthness:  -0.3683551163125228\nCurvature:  -0.009666364\nSlope:  31.644169\nProcessing grid  45\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  1461.4144\nAspect:  246.16008963161693\nEastness:  -0.4041825294160679\nNorthness:  -0.914678349429366\nCurvature:  0.07091493\nSlope:  18.25022\nProcessing grid  46\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  3564.192\nAspect:  9.558416880194196\nEastness:  0.9861168118607218\nNorthness:  0.1660531040530282\nCurvature:  -0.07069282\nSlope:  12.903219\nProcessing grid  47\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  4016.3552\nAspect:  93.42753486396313\nEastness:  -0.059786094851299\nNorthness:  0.9982112115491548\nCurvature:  0.056302153\nSlope:  23.411781\nProcessing grid  48\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  2785.0195\nAspect:  285.39921905482754\nEastness:  0.26554297677956273\nNorthness:  -0.9640990236915753\nCurvature:  -0.018986339\nSlope:  9.606698\nProcessing grid  49\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  1494.3625\nAspect:  251.78016735618934\nEastness:  -0.31266372780721147\nNorthness:  -0.9498638814660225\nCurvature:  0.00067853194\nSlope:  0.3170457\nProcessing grid  50\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  1879.8671\nAspect:  278.3383607361651\nEastness:  0.14501867704085275\nNorthness:  -0.9894289177648493\nCurvature:  0.055334818\nSlope:  15.146703\nProcessing grid  51\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  3467.8894\nAspect:  208.28759226886666\nEastness:  -0.880579999395633\nNorthness:  -0.4738975254887779\nCurvature:  -0.041695688\nSlope:  21.773903\nProcessing grid  52\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  3011.0647\nAspect:  17.738124217928174\nEastness:  0.9524589688647312\nNorthness:  0.30466688797624997\nCurvature:  -0.17876619\nSlope:  20.173325\nProcessing grid  53\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  1879.2822\nAspect:  201.57587956019694\nEastness:  -0.9299313769698505\nNorthness:  -0.3677331017558221\nCurvature:  -0.05887728\nSlope:  40.198074\nProcessing grid  54\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  2949.5845\nAspect:  323.620841537003\nEastness:  0.8051096022632402\nNorthness:  -0.5931260644614492\nCurvature:  0.028107414\nSlope:  12.044895\nProcessing grid  55\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  1650.6384\nAspect:  23.732866846779768\nEastness:  0.9154318715110453\nNorthness:  0.40247296632418056\nCurvature:  -0.015231282\nSlope:  11.813165\nProcessing grid  56\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  2997.2664\nAspect:  157.2610758279333\nEastness:  -0.9222757094056708\nNorthness:  0.38653268405177144\nCurvature:  0.031822767\nSlope:  9.759972\nProcessing grid  57\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  1456.6067\nAspect:  210.98977902906378\nEastness:  -0.8572591644967683\nNorthness:  -0.5148851569877527\nCurvature:  -0.059273798\nSlope:  13.639825\nProcessing grid  58\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  1957.9369\nAspect:  64.93767519424856\nEastness:  0.4236038687149948\nNorthness:  0.905847538170574\nCurvature:  0.0017555926\nSlope:  20.64168\nProcessing grid  59\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  2039.3713\nAspect:  221.71387270527913\nEastness:  -0.7464770919120662\nNorthness:  -0.6654111144627091\nCurvature:  0.024431117\nSlope:  12.890226\nProcessing grid  60\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  3474.9958\nAspect:  182.76314801977233\nEastness:  -0.9988373503453954\nNorthness:  -0.04820733922329438\nCurvature:  -0.061601233\nSlope:  13.283986\nProcessing grid  61\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  2177.3674\nAspect:  52.18949593863494\nEastness:  0.6130519028306993\nNorthness:  0.7900426345683242\nCurvature:  0.003008141\nSlope:  13.148756\nProcessing grid  62\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  1836.9568\nAspect:  210.23751565425692\nEastness:  -0.8639452534892584\nNorthness:  -0.5035857414317655\nCurvature:  -0.010830705\nSlope:  6.414713\nProcessing grid  63\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  1214.8872\nAspect:  247.49405289727707\nEastness:  -0.38277932578703494\nNorthness:  -0.9238398063246803\nCurvature:  0.039931994\nSlope:  12.966995\nProcessing grid  64\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  2650.213\nAspect:  254.7245799451118\nEastness:  -0.26345922962600316\nNorthness:  -0.964670531489831\nCurvature:  0.008411927\nSlope:  4.0186095\nProcessing grid  65\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  2272.7756\nAspect:  265.89377655896936\nEastness:  -0.07160578546651786\nNorthness:  -0.9974330110276695\nCurvature:  0.037764423\nSlope:  14.1827755\nProcessing grid  66\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  2944.019\nAspect:  266.4631889395058\nEastness:  -0.061689802754012625\nNorthness:  -0.9980953703109593\nCurvature:  -0.083527185\nSlope:  31.036201\nProcessing grid  67\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  3036.9316\nAspect:  96.15234321069134\nEastness:  -0.10717241559831002\nNorthness:  0.9942404504619711\nCurvature:  -0.010428555\nSlope:  8.107492\nProcessing grid  68\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  2307.4607\nAspect:  344.35345899839547\nEastness:  0.9629438071840436\nNorthness:  -0.26970210270945133\nCurvature:  0.041438825\nSlope:  14.322107\nProcessing grid  69\n==> Searched items:  1\nreproject data to EPSG:32612\nElevation:  2036.9033\nAspect:  253.74011745928118\nEastness:  C:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\nC:\\Users\\BLi\\gw-workspace\\qnuluanu4rl\\data_terrainFeatures.py:72: DeprecationWarning: open_rasterio is Deprecated in favor of rioxarray. For information about transitioning, see: https://corteva.github.io/rioxarray/stable/getting_started/getting_started.html\n  xarray.open_rasterio(signed_asset.href)\n",
  "history_begin_time" : 1657574453069,
  "history_end_time" : 1657576255997,
  "history_notes" : null,
  "history_process" : "urd0nk",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "tg6r2mzw3fa",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\nexit() # done, uncomment if you want to download new files.\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\n\norg_name = 'modis'\nproduct_name = f'MODIS/006/MOD10A1'\nvar_name = 'NDSI'\ncolumn_name = 'mod10a1_ndsi'\n\n#org_name = 'sentinel1'\n#product_name = 'COPERNICUS/S1_GRD'\n#var_name = 'VV'\n#column_name = 's1_grd_vv'\n\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n    \n    try:\n      \n  \t  print(station_cell_mapper_df['station_id'][ind], station_cell_mapper_df['cell_id'][ind])\n  \t  current_cell_id = station_cell_mapper_df['cell_id'][ind]\n  \t  print(\"collecting \", current_cell_id)\n  \t  single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/modis/{column_name}_{current_cell_id}.csv\"\n\n  \t  if os.path.exists(single_csv_file):\n  \t    print(\"exists skipping..\")\n  \t    continue\n\n  \t  longitude = station_cell_mapper_df['lon'][ind]\n  \t  latitude = station_cell_mapper_df['lat'][ind]\n\n  \t  # identify a 500 meter buffer around our Point Of Interest (POI)\n  \t  poi = ee.Geometry.Point(longitude, latitude).buffer(30)\n\n  \t  def poi_mean(img):\n  \t      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=30)\n  \t      mean = reducer.get(var_name)\n  \t      return img.set('date', img.date().format()).set(column_name,mean)\n        \n  \t  viirs1 = ee.ImageCollection(product_name).filterDate('2013-01-01','2017-12-31')\n  \t  poi_reduced_imgs1 = viirs1.map(poi_mean)\n  \t  nested_list1 = poi_reduced_imgs1.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n  \t  # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n  \t  df1 = pd.DataFrame(nested_list1.getInfo(), columns=['date',column_name])\n      \n  \t  viirs2 = ee.ImageCollection(product_name).filterDate('2018-01-01','2021-12-31')\n  \t  poi_reduced_imgs2 = viirs2.map(poi_mean)\n  \t  nested_list2 = poi_reduced_imgs2.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n  \t  # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n  \t  df2 = pd.DataFrame(nested_list2.getInfo(), columns=['date',column_name])\n      \n\n  \t  df = pd.concat([df1, df2])\n  \t  df['date'] = pd.to_datetime(df['date'])\n  \t  df = df.set_index('date')\n  \t  df['cell_id'] = current_cell_id\n  \t  df['latitude'] = latitude\n  \t  df['longitude'] = longitude\n  \t  df.to_csv(single_csv_file)\n\n  \t  df_list = [all_cell_df, df]\n  \t  all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n  \t  print(e)\n  \t  pass\n    \n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "",
  "history_begin_time" : 1657574453406,
  "history_end_time" : 1657574456112,
  "history_notes" : null,
  "history_process" : "525l8q",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "svdgyo0vsmc",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\nexit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor ind in station_cell_mapper_df.index:\n  \n    try:\n  \t\n      current_cell_id = station_cell_mapper_df['cell_id'][ind]\n      print(\"collecting \", current_cell_id)\n      single_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}_{current_cell_id}.csv\"\n\n      if os.path.exists(single_csv_file):\n          print(\"exists skipping..\")\n          continue\n\n      longitude = station_cell_mapper_df['lon'][ind]\n      latitude = station_cell_mapper_df['lat'][ind]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(1)\n      viirs = ee.ImageCollection(product_name).filterDate('2013-01-01','2021-12-31').filterBounds(poi).filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')).select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      \n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n      df.to_csv(single_csv_file)\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      print(e)\n      pass\n    \nall_cell_df.to_csv(f\"{homedir}/Documents/GitHub/SnowCast/data/{org_name}/{column_name}.csv\")  \n\n\n",
  "history_output" : "",
  "history_begin_time" : 1657574456310,
  "history_end_time" : 1657574458872,
  "history_notes" : null,
  "history_process" : "7temiv",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "9k2lrhw47nl",
  "history_input" : "import json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nimport math\n\n#pd.set_option('display.max_columns', None)\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\ngridcells_file = f\"{github_dir}/data/snowcast_provided/grid_cells.geojson\"\nmodel_dir = f\"{github_dir}/model/\"\ntraining_feature_file = f\"{github_dir}/data/snowcast_provided/ground_measures_train_features.csv\"\ntesting_feature_file = f\"{github_dir}/data/snowcast_provided/ground_measures_test_features.csv\"\ntrain_labels_file = f\"{github_dir}/data/snowcast_provided/train_labels.csv\"\nground_measure_metadata_file = f\"{github_dir}/data/snowcast_provided/ground_measures_metadata.csv\"\n\nready_for_training_folder = f\"{github_dir}/data/ready_for_training/\"\n\nresult_mapping_file = f\"{ready_for_training_folder}station_cell_mapping.csv\"\n\n\nif os.path.exists(result_mapping_file):\n    exit()\n\n\ngridcells = geojson.load(open(gridcells_file))\ntraining_df = pd.read_csv(training_feature_file, header=0)\ntesting_df = pd.read_csv(testing_feature_file, header=0)\nground_measure_metadata_df = pd.read_csv(ground_measure_metadata_file, header=0)\ntrain_labels_df = pd.read_csv(train_labels_file, header=0)\n\nprint(\"training: \", training_df.head())\nprint(\"testing: \", testing_df.head())\nprint(\"ground measure metadata: \", ground_measure_metadata_df.head())\nprint(\"training labels: \", train_labels_df.head())\n\n\ndef calculateDistance(lat1, lon1, lat2, lon2):\n    lat1 = float(lat1)\n    lon1 = float(lon1)\n    lat2 = float(lat2)\n    lon2 = float(lon2)\n    return math.sqrt((lat1-lat2)**2 + (lon1-lon2)**2)\n  \n# prepare the training data\n\nstation_cell_mapper_df = pd.DataFrame(columns = [\"station_id\", \"cell_id\", \"lat\", \"lon\"])\n\nground_measure_metadata_df = ground_measure_metadata_df.reset_index()  # make sure indexes pair with number of rows\nfor index, row in ground_measure_metadata_df.iterrows():\n  \t\n    print(row['station_id'], row['name'], row['latitude'], row['longitude'])\n    station_lat = row['latitude']\n    station_lon = row['longitude']\n    \n    shortest_dis = 999\n    associated_cell_id = None\n    associated_lat = None\n    associated_lon = None\n    \n    for idx,cell in enumerate(gridcells['features']):\n    \n      current_cell_id = cell['properties']['cell_id']\n\n      #print(\"collecting \", current_cell_id)\n      cell_lon = np.unique(np.ravel(cell['geometry']['coordinates'])[0::2]).mean()\n      cell_lat = np.unique(np.ravel(cell['geometry']['coordinates'])[1::2]).mean()\n\n      dist = calculateDistance(station_lat, station_lon, cell_lat, cell_lon)\n\n      if dist < shortest_dis:\n        associated_cell_id = current_cell_id\n        shortest_dis = dist\n        associated_lat = cell_lat\n        associated_lon = cell_lon\n    \n    station_cell_mapper_df.loc[len(station_cell_mapper_df.index)] = [row['station_id'], associated_cell_id, associated_lat, associated_lon]\n    \nprint(station_cell_mapper_df.head())\nstation_cell_mapper_df.to_csv(f\"{ready_for_training_folder}station_cell_mapping.csv\")\n    \n\n\n      \n",
  "history_output" : "C:\\Users\\BLi\n",
  "history_begin_time" : 1657574447357,
  "history_end_time" : 1657574452379,
  "history_notes" : null,
  "history_process" : "rmxece",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "of9lzs8m18k",
  "history_input" : "# This script will download modis data for all the testing sites from Google Earth Engine.\n# The start date is the last stop date of the last run.\n\nfrom all_dependencies import *\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\n\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_df = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\norg_name = 'modis'\nproduct_name = f'MODIS/006/MOD10A1'\nvar_name = 'NDSI'\ncolumn_name = 'mod10a1_ndsi'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sat_testing/modis\", \"%Y-%m-%d\")\nend_date = test_end_date\n\nfinal_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/sat_testing/{org_name}/{column_name}_{start_date}_{end_date}.csv\"\nprint(f\"Results will be saved to {final_csv_file}\")\n\nif os.path.exists(final_csv_file):\n    #print(\"exists exiting..\")\n    #exit()\n    os.remove(final_csv_file)\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\nprint(\"start to traverse the cells in submission_format_eval.csv..\")\n\nfor current_cell_id in submission_format_df.index:\n    \n    try:\n      \n  \t  longitude = all_cell_coords_df['lon'][current_cell_id]\n  \t  latitude = all_cell_coords_df['lat'][current_cell_id]\n\n  \t  # identify a 500 meter buffer around our Point Of Interest (POI)\n  \t  poi = ee.Geometry.Point(longitude, latitude).buffer(30)\n\n  \t  def poi_mean(img):\n  \t      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=30)\n  \t      mean = reducer.get(var_name)\n  \t      return img.set('date', img.date().format()).set(column_name,mean)\n        \n  \t  viirs1 = ee.ImageCollection(product_name).filterDate(start_date, end_date)\n  \t  poi_reduced_imgs1 = viirs1.map(poi_mean)\n  \t  nested_list1 = poi_reduced_imgs1.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n  \t  # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n  \t  df = pd.DataFrame(nested_list1.getInfo(), columns=['date',column_name])\n      \n  \t  df['date'] = pd.to_datetime(df['date'])\n  \t  df = df.set_index('date')\n  \t  df['cell_id'] = current_cell_id\n  \t  df['latitude'] = latitude\n  \t  df['longitude'] = longitude\n  \t  #df.to_csv(single_csv_file)\n\n  \t  df_list = [all_cell_df, df]\n  \t  all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      print(traceback.format_exc())\n      print(\"failed\", e)\n      pass\n    \n    \nall_cell_df.to_csv(final_csv_file)  \n\nprint(f\"All points have been saved to {final_csv_file}\")\n\n\n",
  "history_output" : "Running",
  "history_begin_time" : 1657574459185,
  "history_end_time" : 1657574459153,
  "history_notes" : null,
  "history_process" : "illwc1",
  "host_id" : "100001",
  "indicator" : "Running"
},{
  "history_id" : "0enwijuq5aj",
  "history_input" : "\n\n# reminder that if you are installing libraries in a Google Colab instance you will be prompted to restart your kernal\n\nfrom all_dependencies import *\nfrom snowcast_utils import *\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\n\nprint(\"submission_format_df shape: \", submission_format_df.shape)\n\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_df = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sat_testing/sentinel1\",\"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n\norg_name = 'sentinel1'\nproduct_name = 'COPERNICUS/S1_GRD'\nvar_name = 'VV'\ncolumn_name = 's1_grd_vv'\n\nfinal_csv_file = f\"{homedir}/Documents/GitHub/SnowCast/data/sat_testing/{org_name}/{column_name}_{start_date}_{end_date}.csv\"\nprint(f\"Results will be saved to {final_csv_file}\")\n\n\nif os.path.exists(final_csv_file):\n    #print(\"exists skipping..\")\n    #exit()\n    os.remove(final_csv_file)\n\n\nall_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\nfor current_cell_id in submission_format_df.index:\n  \n    try:\n  \t\n      #print(\"collecting \", current_cell_id)\n      \n      longitude = all_cell_coords_df['lon'][current_cell_id]\n      latitude = all_cell_coords_df['lat'][current_cell_id]\n\n      # identify a 500 meter buffer around our Point Of Interest (POI)\n      poi = ee.Geometry.Point(longitude, latitude).buffer(10)\n\n      viirs = ee.ImageCollection(product_name) \\\n          \t.filterDate(start_date, end_date) \\\n            .filterBounds(poi) \\\n          \t.filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')) \\\n      \t\t.select('VV')\n      \n      def poi_mean(img):\n          reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi)\n          mean = reducer.get(var_name)\n          return img.set('date', img.date().format()).set(column_name,mean)\n\n      poi_reduced_imgs = viirs.map(poi_mean)\n\n      nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n      # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n      df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n      df['date'] = pd.to_datetime(df['date'])\n      df = df.set_index('date')\n\n      df['cell_id'] = current_cell_id\n      df['latitude'] = latitude\n      df['longitude'] = longitude\n\n      df_list = [all_cell_df, df]\n      all_cell_df = pd.concat(df_list) # merge into big dataframe\n      \n    except Exception as e:\n      \n      #print(e)\n      pass\n    \nall_cell_df.to_csv(final_csv_file)\n\n",
  "history_output" : "",
  "history_begin_time" : 1657574459888,
  "history_end_time" : 1657574463561,
  "history_notes" : null,
  "history_process" : "sjs5by",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "2ro7rqs949x",
  "history_input" : "'''\nThe wrapper for all the snowcast_wormhole predictors\n'''\nimport os\nimport joblib\nfrom datetime import datetime\nhomedir = os.path.expanduser('~')\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n\nclass BaseHole:\n  \n  def __init__(self):\n    self.classifier = self.get_model()\n    self.train_x = None\n    self.train_y = None\n    self.test_x = None\n    self.test_y = None\n    self.test_y_results = None\n    self.save_file = None\n    \n  def save(self):\n    now = datetime.now()\n    date_time = now.strftime(\"%Y%d%m%H%M%S\")\n    self.save_file = f\"{github_dir}/model/wormhole_{date_time}.joblib\"\n    print(f\"Saving model to {self.save_file}\")\n    joblib.dump(self.classifier, self.save_file)\n  \n  def preprocessing(self):\n    pass\n  \n  def train(self):\n    self.classifier.fit(self.train_x, self.train_y)\n  \n  def test(self):\n    self.test_y_results = self.classifier.predict(self.test_x)\n    return self.test_y_results\n  \n  def predict(self, input_x):\n    return self.classifier.predict(input_x)\n  \n  def evaluate(self):\n    pass\n  \n  def get_model(self):\n    pass\n  \n  def post_processing(self):\n    pass",
  "history_output" : "",
  "history_begin_time" : 1657574447355,
  "history_end_time" : 1657574449100,
  "history_notes" : null,
  "history_process" : "y7nb46",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "k6m0zfz6g47",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\nexit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nstation_cell_mapper_file = f\"{github_dir}/data/ready_for_training/station_cell_mapping.csv\"\nstation_cell_mapper_df = pd.read_csv(station_cell_mapper_file)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\nstart_date = '2013-01-01'\nend_date = '2021-12-31'\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\nfor var in var_list:\n\n    var_name = var\n    column_name = var\n\n    dfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_training/{org_name}/\"\n    if not os.path.exists(dfolder):\n        os.makedirs(dfolder)\n\n    all_cell_df = pd.DataFrame(columns = ['date', column_name, 'cell_id', 'latitude', 'longitude'])\n\n    for ind in station_cell_mapper_df.index:\n\n        try:\n\n          current_cell_id = station_cell_mapper_df['cell_id'][ind]\n          print(\"collecting \", current_cell_id)\n          single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n          if os.path.exists(single_csv_file):\n              print(\"exists skipping..\")\n              continue\n\n          longitude = station_cell_mapper_df['lon'][ind]\n          latitude = station_cell_mapper_df['lat'][ind]\n\n          # identify a 500 meter buffer around our Point Of Interest (POI)\n          poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n          viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_name)\n\n          def poi_mean(img):\n              reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n              mean = reducer.get(var_name)\n              return img.set('date', img.date().format()).set(column_name,mean)\n\n\n          poi_reduced_imgs = viirs.map(poi_mean)\n\n          nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(2), ['date',column_name]).values().get(0)\n\n          # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n          df = pd.DataFrame(nested_list.getInfo(), columns=['date',column_name])\n\n          df['date'] = pd.to_datetime(df['date'])\n          df = df.set_index('date')\n\n          df['cell_id'] = current_cell_id\n          df['latitude'] = latitude\n          df['longitude'] = longitude\n          df.to_csv(single_csv_file)\n\n          df_list = [all_cell_df, df]\n          all_cell_df = pd.concat(df_list) # merge into big dataframe\n\n        except Exception as e:\n\n          print(e)\n          pass\n    \n    all_cell_df.to_csv(f\"{dfolder}/{column_name}.csv\")  \n\n\n",
  "history_output" : "",
  "history_begin_time" : 1657574455080,
  "history_end_time" : 1657574456111,
  "history_notes" : null,
  "history_process" : "a8p3n7",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "f7taq7mq2j0",
  "history_input" : "\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nfrom datetime import date\nfrom snowcast_utils import *\nimport traceback\n\n\n# exit() # uncomment to download new files\n\ntry:\n    ee.Initialize()\nexcept Exception as e:\n    ee.Authenticate() # this must be run in terminal instead of Geoweaver. Geoweaver doesn't support prompt.\n    ee.Initialize()\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\n# read grid cell\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n# read grid cell\nsubmission_format_file = f\"{github_dir}/data/snowcast_provided/submission_format_eval.csv\"\nsubmission_format_df = pd.read_csv(submission_format_file, header=0, index_col=0)\nall_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\nall_cell_coords_pd = pd.read_csv(all_cell_coords_file, header=0, index_col=0)\n\nprint(submission_format_df.shape)\n\n#org_name = 'modis'\n#product_name = f'MODIS/006/MOD10A1'\n#var_name = 'NDSI'\n#column_name = 'mod10a1_ndsi'\n\norg_name = 'gridmet'\nproduct_name = 'IDAHO_EPSCOR/GRIDMET'\n#start_date = \"2022-04-20\"#test_start_date\nstart_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\nend_date = test_end_date\n#start_date = \"2022-04-06\"\n#end_date = \"2022-04-18\"\n\nvar_list = ['tmmn', 'tmmx', 'pr', 'vpd', 'eto', 'rmax', 'rmin', 'vs']\n\n\ndfolder = f\"{homedir}/Documents/GitHub/SnowCast/data/sim_testing/{org_name}/\"\nif not os.path.exists(dfolder):\n  os.makedirs(dfolder)\n  \ncolumn_list = ['date', 'cell_id', 'latitude', 'longitude']\ncolumn_list.extend(var_list)\nreduced_column_list = ['date']\nreduced_column_list.extend(var_list)\n\nall_cell_df = pd.DataFrame(columns = column_list)\n\ncount = 0\n\nfor current_cell_id in submission_format_df.index:\n\n  try:\n    count+=1\n    print(f\"=> Collected GridMet data for {count} cells\")\n    print(\"collecting \", current_cell_id)\n    #single_csv_file = f\"{dfolder}/{column_name}_{current_cell_id}.csv\"\n\n    #if os.path.exists(single_csv_file):\n    #  os.remove(single_csv_file)\n    #  print(\"exists skipping..\")\n    #  continue\n\n    longitude = all_cell_coords_pd['lon'][current_cell_id]\n    latitude = all_cell_coords_pd['lat'][current_cell_id]\n\n    # identify a 500 meter buffer around our Point Of Interest (POI)\n    poi = ee.Geometry.Point(longitude, latitude).buffer(1000)\n    viirs = ee.ImageCollection(product_name).filterDate(start_date, end_date).filterBounds(poi).select(var_list)\n\n    def poi_mean(img):\n      reducer = img.reduceRegion(reducer=ee.Reducer.mean(), geometry=poi, scale=1000)\n      img = img.set('date', img.date().format());\n      for var in var_list:\n        column_name = var\n        mean = reducer.get(column_name)\n        img = img.set(column_name,mean)\n      return img\n\n\n    poi_reduced_imgs = viirs.map(poi_mean)\n\n    nested_list = poi_reduced_imgs.reduceColumns(ee.Reducer.toList(9), reduced_column_list).values().get(0)\n\n    # dont forget we need to call the callback method \"getInfo\" to retrieve the data\n    df = pd.DataFrame(nested_list.getInfo(), columns=reduced_column_list)\n\n    df['date'] = pd.to_datetime(df['date'])\n    df = df.set_index('date')\n\n    df['cell_id'] = current_cell_id\n    df['latitude'] = latitude\n    df['longitude'] = longitude\n    #df.to_csv(single_csv_file)\n\n    #print(df.head())\n    \n    df_list = [all_cell_df, df]\n    all_cell_df = pd.concat(df_list) # merge into big dataframe\n    \n    #if count % 4 == 0:\n\n  except Exception as e:\n    print(traceback.format_exc())\n    print(\"Failed: \", e)\n    pass\n\nall_cell_df.to_csv(f\"{dfolder}/all_vars_{start_date}_{end_date}.csv\")  \n\n\n",
  "history_output" : "today date = 2022-07-11\nC:\\Users\\BLi\nC:\\Users\\BLi\n(20759, 25)\nTraceback (most recent call last):\n  File \"C:\\Users\\BLi\\gw-workspace\\f7taq7mq2j0\\data_gee_gridmet_real_time.py\", line 46, in <module>\n    start_date = findLastStopDate(f\"{github_dir}/data/sim_testing/{org_name}/\", \"%Y-%m-%d %H:%M:%S\")\n  File \"C:\\Users\\BLi\\gw-workspace\\f7taq7mq2j0\\snowcast_utils.py\", line 75, in findLastStopDate\n    latest_date = get_latest_date_from_an_array(date_list, data_format)\n  File \"C:\\Users\\BLi\\gw-workspace\\f7taq7mq2j0\\snowcast_utils.py\", line 64, in get_latest_date_from_an_array\n    return max(arr, key=lambda x: datetime.datetime.strptime(x, date_format))\nValueError: max() arg is an empty sequence\n",
  "history_begin_time" : 1657574459266,
  "history_end_time" : 1657574463554,
  "history_notes" : null,
  "history_process" : "smsdr0",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "fbk9sriuzc1",
  "history_input" : "from sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom base_hole import BaseHole\nfrom sklearn.model_selection import train_test_split\nfrom datetime import datetime\nfrom model_creation_rf import RandomForestHole\nfrom sklearn.ensemble import ExtraTreesRegressor\n\nclass XGBoostHole(RandomForestHole):\n\n  def get_model(self):\n    \"\"\"\n    rfc_pipeline = Pipeline(steps = [\n      ('data_scaling', StandardScaler()),\n      ('model', RandomForestRegressor(max_depth = 15,\n                                       min_samples_leaf = 0.004,\n                                       min_samples_split = 0.008,\n                                       n_estimators = 25))])\n    #return rfc_pipeline\n  \t\"\"\"\n    etmodel = ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='mse',\n                    max_depth=None, max_features='auto', max_leaf_nodes=None,\n                    max_samples=None, min_impurity_decrease=0.0,\n                    #min_impurity_split=None, \n                    min_samples_leaf=1,\n                    min_samples_split=2, min_weight_fraction_leaf=0.0,\n                    n_estimators=100, n_jobs=-1, oob_score=False,\n                    random_state=123, verbose=0, warm_start=False)\n    return etmodel\n\n\n",
  "history_output" : "",
  "history_begin_time" : 1657574453549,
  "history_end_time" : 1657574456235,
  "history_notes" : null,
  "history_process" : "4i0sop",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "wpug7s7qm50",
  "history_input" : "from datetime import date\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\nimport math\nimport datetime\n\ntoday = date.today()\n\n# dd/mm/YY\nd1 = today.strftime(\"%Y-%m-%d\")\nprint(\"today date =\", d1)\n\ntrain_start_date = \"\"\ntrain_end_date = \"\"\n\ntest_start_date = \"2022-01-01\"\ntest_end_date = d1\n\n# read the grid geometry file\nhomedir = os.path.expanduser('~')\nprint(homedir)\ngithub_dir = f\"{homedir}/Documents/GitHub/SnowCast\"\n\n\ndef calculateDistance(lat1, lon1, lat2, lon2):\n    lat1 = float(lat1)\n    lon1 = float(lon1)\n    lat2 = float(lat2)\n    lon2 = float(lon2)\n    return math.sqrt((lat1-lat2)**2 + (lon1-lon2)**2)\n\ndef create_cell_location_csv():\n  # read grid cell\n  gridcells_file = f\"{github_dir}/data/snowcast_provided/grid_cells_eval.geojson\"\n  all_cell_coords_file = f\"{github_dir}/data/snowcast_provided/all_cell_coords_file.csv\"\n  if os.path.exists(all_cell_coords_file):\n    os.remove(all_cell_coords_file)\n\n  grid_coords_df = pd.DataFrame(columns=[\"cell_id\", \"lat\", \"lon\"])\n  print(grid_coords_df.head())\n  gridcells = geojson.load(open(gridcells_file))\n  for idx,cell in enumerate(gridcells['features']):\n    \n    current_cell_id = cell['properties']['cell_id']\n    cell_lon = np.unique(np.ravel(cell['geometry']['coordinates'])[0::2]).mean()\n    cell_lat = np.unique(np.ravel(cell['geometry']['coordinates'])[1::2]).mean()\n    grid_coords_df.loc[len(grid_coords_df.index)] = [current_cell_id, cell_lat, cell_lon]\n    \n  #grid_coords_np = grid_coords_df.to_numpy()\n  #print(grid_coords_np.shape)\n  grid_coords_df.to_csv(all_cell_coords_file, index=False)\n  #np.savetxt(all_cell_coords_file, grid_coords_np[:, 1:], delimiter=\",\")\n  #print(grid_coords_np.shape)\n  \ndef get_latest_date_from_an_array(arr, date_format):\n  return max(arr, key=lambda x: datetime.datetime.strptime(x, date_format))\n  \n  \ndef findLastStopDate(target_testing_dir, data_format):\n  date_list = []\n  for filename in os.listdir(target_testing_dir):\n    f = os.path.join(target_testing_dir, filename)\n    # checking if it is a file\n    if os.path.isfile(f) and \".csv\" in f:\n        pdf = pd.read_csv(f,header=0, index_col=0)\n        date_list = np.concatenate((date_list, pdf.index.unique()))\n  latest_date = get_latest_date_from_an_array(date_list, data_format)\n  print(latest_date)\n  date_time_obj = datetime.datetime.strptime(latest_date, data_format)\n  return date_time_obj.strftime(\"%Y-%m-%d\")\n\n#create_cell_location_csv()\n#findLastStopDate(f\"{github_dir}/data/sim_testing/gridmet/\", \"%Y-%m-%d %H:%M:%S\")\n#findLastStopDate(f\"{github_dir}/data/sat_testing/sentinel1/\", \"%Y-%m-%d %H:%M:%S\")\n#findLastStopDate(f\"{github_dir}/data/sat_testing/modis/\", \"%Y-%m-%d\")\n\n\n\n      \n",
  "history_output" : "",
  "history_begin_time" : 1657574457123,
  "history_end_time" : 1657574458873,
  "history_notes" : null,
  "history_process" : "zh38b6",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "txtufej5bwf",
  "history_input" : "\nfrom base_hole import *\n\nclass KehanModel(BaseHole):\n\t\n  def preprocessing():\n    pass  \n  \n  def train():\n    pass\n  \n  def test():\n    pass",
  "history_output" : "",
  "history_begin_time" : 1657574450140,
  "history_end_time" : 1657574451047,
  "history_notes" : null,
  "history_process" : "wdh394",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "dfg92z10qm5",
  "history_input" : "from datetime import datetime\nfrom metloom.pointdata import SnotelPointData\n\n\n# Write first python in Geoweaver\nimport os\nimport urllib.request, urllib.error, urllib.parse\nimport sys\nprint(sys.path)\n\ntry:\n    from BeautifulSoup import BeautifulSoup\nexcept ImportError:\n    from bs4 import BeautifulSoup\n\nnohrsc_url_format_string = \"https://www.nohrsc.noaa.gov/nearest/index.html?city={lat}%2C{lon}&county=&l=5&u=e&y={year}&m={month}&d={day}\"\n\ntest_noaa_query_url = nohrsc_url_format_string.format(lat=40.05352381745094, lon=-106.04027196859343, year=2022, month=5, day=4)\n\nprint(test_noaa_query_url)\n\nresponse = urllib.request.urlopen(test_noaa_query_url)\nwebContent = response.read().decode('UTF-8')\n\nprint(webContent)\n\n\nparsed_html = BeautifulSoup(webContent)\nprint(parsed_html.body.find('div', attrs={'class':'container'}).text)\n\n\n\n#snotel_point = SnotelPointData(\"713:CO:SNTL\", \"MyStation\")\n#df = snotel_point.get_daily_data(\n#    datetime(2020, 1, 2), datetime(2020, 1, 20),\n#    [snotel_point.ALLOWED_VARIABLES.SWE]\n#)\n#print(df)",
  "history_output" : "['C:\\\\Users\\\\BLi\\\\gw-workspace\\\\dfg92z10qm5', 'C:\\\\Users\\\\BLi\\\\anaconda3\\\\envs\\\\snowcast\\\\python39.zip', 'C:\\\\Users\\\\BLi\\\\anaconda3\\\\envs\\\\snowcast\\\\DLLs', 'C:\\\\Users\\\\BLi\\\\anaconda3\\\\envs\\\\snowcast\\\\lib', 'C:\\\\Users\\\\BLi\\\\anaconda3\\\\envs\\\\snowcast', 'C:\\\\Users\\\\BLi\\\\anaconda3\\\\envs\\\\snowcast\\\\lib\\\\site-packages', 'C:\\\\Users\\\\BLi\\\\anaconda3\\\\envs\\\\snowcast\\\\lib\\\\site-packages\\\\win32', 'C:\\\\Users\\\\BLi\\\\anaconda3\\\\envs\\\\snowcast\\\\lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\BLi\\\\anaconda3\\\\envs\\\\snowcast\\\\lib\\\\site-packages\\\\Pythonwin']\nhttps://www.nohrsc.noaa.gov/nearest/index.html?city=40.05352381745094%2C-106.04027196859343&county=&l=5&u=e&y=2022&m=5&d=4\nTraceback (most recent call last):\n  File \"C:\\Users\\BLi\\anaconda3\\envs\\snowcast\\lib\\urllib\\request.py\", line 1346, in do_open\n    h.request(req.get_method(), req.selector, req.data, headers,\n  File \"C:\\Users\\BLi\\anaconda3\\envs\\snowcast\\lib\\http\\client.py\", line 1285, in request\n    self._send_request(method, url, body, headers, encode_chunked)\n  File \"C:\\Users\\BLi\\anaconda3\\envs\\snowcast\\lib\\http\\client.py\", line 1331, in _send_request\n    self.endheaders(body, encode_chunked=encode_chunked)\n  File \"C:\\Users\\BLi\\anaconda3\\envs\\snowcast\\lib\\http\\client.py\", line 1280, in endheaders\n    self._send_output(message_body, encode_chunked=encode_chunked)\n  File \"C:\\Users\\BLi\\anaconda3\\envs\\snowcast\\lib\\http\\client.py\", line 1040, in _send_output\n    self.send(msg)\n  File \"C:\\Users\\BLi\\anaconda3\\envs\\snowcast\\lib\\http\\client.py\", line 980, in send\n    self.connect()\n  File \"C:\\Users\\BLi\\anaconda3\\envs\\snowcast\\lib\\http\\client.py\", line 1454, in connect\n    self.sock = self._context.wrap_socket(self.sock,\n  File \"C:\\Users\\BLi\\anaconda3\\envs\\snowcast\\lib\\ssl.py\", line 500, in wrap_socket\n    return self.sslsocket_class._create(\n  File \"C:\\Users\\BLi\\anaconda3\\envs\\snowcast\\lib\\ssl.py\", line 1040, in _create\n    self.do_handshake()\n  File \"C:\\Users\\BLi\\anaconda3\\envs\\snowcast\\lib\\ssl.py\", line 1309, in do_handshake\n    self._sslobj.do_handshake()\nssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1129)\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"C:\\Users\\BLi\\gw-workspace\\dfg92z10qm5\\data_snotel_real_time.py\", line 22, in <module>\n    response = urllib.request.urlopen(test_noaa_query_url)\n  File \"C:\\Users\\BLi\\anaconda3\\envs\\snowcast\\lib\\urllib\\request.py\", line 214, in urlopen\n    return opener.open(url, data, timeout)\n  File \"C:\\Users\\BLi\\anaconda3\\envs\\snowcast\\lib\\urllib\\request.py\", line 517, in open\n    response = self._open(req, data)\n  File \"C:\\Users\\BLi\\anaconda3\\envs\\snowcast\\lib\\urllib\\request.py\", line 534, in _open\n    result = self._call_chain(self.handle_open, protocol, protocol +\n  File \"C:\\Users\\BLi\\anaconda3\\envs\\snowcast\\lib\\urllib\\request.py\", line 494, in _call_chain\n    result = func(*args)\n  File \"C:\\Users\\BLi\\anaconda3\\envs\\snowcast\\lib\\urllib\\request.py\", line 1389, in https_open\n    return self.do_open(http.client.HTTPSConnection, req,\n  File \"C:\\Users\\BLi\\anaconda3\\envs\\snowcast\\lib\\urllib\\request.py\", line 1349, in do_open\n    raise URLError(err)\nurllib.error.URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1129)>\n",
  "history_begin_time" : 1657574463921,
  "history_end_time" : 1657574465593,
  "history_notes" : null,
  "history_process" : "p87wh1",
  "host_id" : "100001",
  "indicator" : "Failed"
},{
  "history_id" : "m77rfi5tdhz",
  "history_input" : "from sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn import metrics \nfrom sklearn import tree\nimport joblib\nimport os\nfrom pathlib import Path\nimport json\nimport geopandas as gpd\nimport geojson\nimport os.path\nimport math\nfrom sklearn.model_selection import RandomizedSearchCV\n\nimport json\nimport pandas as pd\nimport ee\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport os\nimport geopandas as gpd\nimport geojson\nimport numpy as np\nimport os.path\n\n#pd.set_option('display.max_columns', None)\n",
  "history_output" : "",
  "history_begin_time" : 1657574447357,
  "history_end_time" : 1657574452526,
  "history_notes" : null,
  "history_process" : "ilbqzg",
  "host_id" : "100001",
  "indicator" : "Done"
}]
